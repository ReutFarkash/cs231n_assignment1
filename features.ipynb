{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image features exercise\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "We have seen that we can achieve reasonable performance on an image classification task by training a linear classifier on the pixels of the input image. In this exercise we will show that we can improve our classification performance by training linear classifiers not on raw pixels but on features that are computed from the raw pixels.\n",
    "\n",
    "All of your work for this exercise will be done in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Similar to previous exercises, we will load CIFAR-10 data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.features import color_histogram_hsv, hog_feature\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "For each image we will compute a Histogram of Oriented\n",
    "Gradients (HOG) as well as a color histogram using the hue channel in HSV\n",
    "color space. We form our final feature vector for each image by concatenating\n",
    "the HOG and color histogram feature vectors.\n",
    "\n",
    "Roughly speaking, HOG should capture the texture of the image while ignoring\n",
    "color information, and the color histogram represents the color of the input\n",
    "image while ignoring texture. As a result, we expect that using both together\n",
    "ought to work better than using either alone. Verifying this assumption would\n",
    "be a good thing to try for the bonus section.\n",
    "\n",
    "The `hog_feature` and `color_histogram_hsv` functions both operate on a single\n",
    "image and return a feature vector for that image. The extract_features\n",
    "function takes a set of images and a list of feature functions and evaluates\n",
    "each feature function on each image, storing the results in a matrix where\n",
    "each column is the concatenation of all feature vectors for a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting features for 1000 / 49000 images\n",
      "Done extracting features for 2000 / 49000 images\n",
      "Done extracting features for 3000 / 49000 images\n",
      "Done extracting features for 4000 / 49000 images\n",
      "Done extracting features for 5000 / 49000 images\n",
      "Done extracting features for 6000 / 49000 images\n",
      "Done extracting features for 7000 / 49000 images\n",
      "Done extracting features for 8000 / 49000 images\n",
      "Done extracting features for 9000 / 49000 images\n",
      "Done extracting features for 10000 / 49000 images\n",
      "Done extracting features for 11000 / 49000 images\n",
      "Done extracting features for 12000 / 49000 images\n",
      "Done extracting features for 13000 / 49000 images\n",
      "Done extracting features for 14000 / 49000 images\n",
      "Done extracting features for 15000 / 49000 images\n",
      "Done extracting features for 16000 / 49000 images\n",
      "Done extracting features for 17000 / 49000 images\n",
      "Done extracting features for 18000 / 49000 images\n",
      "Done extracting features for 19000 / 49000 images\n",
      "Done extracting features for 20000 / 49000 images\n",
      "Done extracting features for 21000 / 49000 images\n",
      "Done extracting features for 22000 / 49000 images\n",
      "Done extracting features for 23000 / 49000 images\n",
      "Done extracting features for 24000 / 49000 images\n",
      "Done extracting features for 25000 / 49000 images\n",
      "Done extracting features for 26000 / 49000 images\n",
      "Done extracting features for 27000 / 49000 images\n",
      "Done extracting features for 28000 / 49000 images\n",
      "Done extracting features for 29000 / 49000 images\n",
      "Done extracting features for 30000 / 49000 images\n",
      "Done extracting features for 31000 / 49000 images\n",
      "Done extracting features for 32000 / 49000 images\n",
      "Done extracting features for 33000 / 49000 images\n",
      "Done extracting features for 34000 / 49000 images\n",
      "Done extracting features for 35000 / 49000 images\n",
      "Done extracting features for 36000 / 49000 images\n",
      "Done extracting features for 37000 / 49000 images\n",
      "Done extracting features for 38000 / 49000 images\n",
      "Done extracting features for 39000 / 49000 images\n",
      "Done extracting features for 40000 / 49000 images\n",
      "Done extracting features for 41000 / 49000 images\n",
      "Done extracting features for 42000 / 49000 images\n",
      "Done extracting features for 43000 / 49000 images\n",
      "Done extracting features for 44000 / 49000 images\n",
      "Done extracting features for 45000 / 49000 images\n",
      "Done extracting features for 46000 / 49000 images\n",
      "Done extracting features for 47000 / 49000 images\n",
      "Done extracting features for 48000 / 49000 images\n"
     ]
    }
   ],
   "source": [
    "from cs231n.features import *\n",
    "\n",
    "num_color_bins = 10 # Number of bins in the color histogram\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
    "X_val_feats = extract_features(X_val, feature_fns)\n",
    "X_test_feats = extract_features(X_test, feature_fns)\n",
    "\n",
    "# Preprocessing: Subtract the mean feature\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
    "# has roughly the same scale.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Preprocessing: Add a bias dimension\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on features\n",
    "Using the multiclass SVM code developed earlier in the assignment, train SVMs on top of the features extracted above; this should achieve better results than training SVMs directly on top of raw pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2500: loss 9.761693\n",
      "iteration 100 / 2500: loss 9.751579\n",
      "iteration 200 / 2500: loss 9.757708\n",
      "iteration 300 / 2500: loss 9.767196\n",
      "iteration 400 / 2500: loss 9.759911\n",
      "iteration 500 / 2500: loss 9.767023\n",
      "iteration 600 / 2500: loss 9.770343\n",
      "iteration 700 / 2500: loss 9.756061\n",
      "iteration 800 / 2500: loss 9.755806\n",
      "iteration 900 / 2500: loss 9.758766\n",
      "iteration 1000 / 2500: loss 9.762486\n",
      "iteration 1100 / 2500: loss 9.768146\n",
      "iteration 1200 / 2500: loss 9.759896\n",
      "iteration 1300 / 2500: loss 9.770678\n",
      "iteration 1400 / 2500: loss 9.759041\n",
      "iteration 1500 / 2500: loss 9.748595\n",
      "iteration 1600 / 2500: loss 9.762822\n",
      "iteration 1700 / 2500: loss 9.757975\n",
      "iteration 1800 / 2500: loss 9.754313\n",
      "iteration 1900 / 2500: loss 9.753009\n",
      "iteration 2000 / 2500: loss 9.751641\n",
      "iteration 2100 / 2500: loss 9.757024\n",
      "iteration 2200 / 2500: loss 9.753275\n",
      "iteration 2300 / 2500: loss 9.749764\n",
      "iteration 2400 / 2500: loss 9.754004\n",
      "iteration 0 / 2500: loss 16.554248\n",
      "iteration 100 / 2500: loss 16.543943\n",
      "iteration 200 / 2500: loss 16.521057\n",
      "iteration 300 / 2500: loss 16.505366\n",
      "iteration 400 / 2500: loss 16.508213\n",
      "iteration 500 / 2500: loss 16.470056\n",
      "iteration 600 / 2500: loss 16.459466\n",
      "iteration 700 / 2500: loss 16.434203\n",
      "iteration 800 / 2500: loss 16.447439\n",
      "iteration 900 / 2500: loss 16.426921\n",
      "iteration 1000 / 2500: loss 16.398230\n",
      "iteration 1100 / 2500: loss 16.389440\n",
      "iteration 1200 / 2500: loss 16.374916\n",
      "iteration 1300 / 2500: loss 16.361909\n",
      "iteration 1400 / 2500: loss 16.342789\n",
      "iteration 1500 / 2500: loss 16.315602\n",
      "iteration 1600 / 2500: loss 16.320689\n",
      "iteration 1700 / 2500: loss 16.304939\n",
      "iteration 1800 / 2500: loss 16.288379\n",
      "iteration 1900 / 2500: loss 16.274801\n",
      "iteration 2000 / 2500: loss 16.254929\n",
      "iteration 2100 / 2500: loss 16.258659\n",
      "iteration 2200 / 2500: loss 16.243406\n",
      "iteration 2300 / 2500: loss 16.220992\n",
      "iteration 2400 / 2500: loss 16.208433\n",
      "iteration 0 / 2500: loss 87.817798\n",
      "iteration 100 / 2500: loss 86.242096\n",
      "iteration 200 / 2500: loss 84.736299\n",
      "iteration 300 / 2500: loss 83.225157\n",
      "iteration 400 / 2500: loss 81.768205\n",
      "iteration 500 / 2500: loss 80.323295\n",
      "iteration 600 / 2500: loss 78.914223\n",
      "iteration 700 / 2500: loss 77.510364\n",
      "iteration 800 / 2500: loss 76.157846\n",
      "iteration 900 / 2500: loss 74.835577\n",
      "iteration 1000 / 2500: loss 73.519391\n",
      "iteration 1100 / 2500: loss 72.245748\n",
      "iteration 1200 / 2500: loss 70.999781\n",
      "iteration 1300 / 2500: loss 69.777157\n",
      "iteration 1400 / 2500: loss 68.576532\n",
      "iteration 1500 / 2500: loss 67.376982\n",
      "iteration 1600 / 2500: loss 66.224762\n",
      "iteration 1700 / 2500: loss 65.091948\n",
      "iteration 1800 / 2500: loss 63.992570\n",
      "iteration 1900 / 2500: loss 62.897729\n",
      "iteration 2000 / 2500: loss 61.833338\n",
      "iteration 2100 / 2500: loss 60.793174\n",
      "iteration 2200 / 2500: loss 59.760721\n",
      "iteration 2300 / 2500: loss 58.758314\n",
      "iteration 2400 / 2500: loss 57.772335\n",
      "iteration 0 / 2500: loss 809.283473\n",
      "iteration 100 / 2500: loss 664.171674\n",
      "iteration 200 / 2500: loss 545.342172\n",
      "iteration 300 / 2500: loss 448.074794\n",
      "iteration 400 / 2500: loss 368.450404\n",
      "iteration 500 / 2500: loss 303.260302\n",
      "iteration 600 / 2500: loss 249.896254\n",
      "iteration 700 / 2500: loss 206.213322\n",
      "iteration 800 / 2500: loss 170.453167\n",
      "iteration 900 / 2500: loss 141.174297\n",
      "iteration 1000 / 2500: loss 117.197542\n",
      "iteration 1100 / 2500: loss 97.578150\n",
      "iteration 1200 / 2500: loss 81.512956\n",
      "iteration 1300 / 2500: loss 68.362990\n",
      "iteration 1400 / 2500: loss 57.597684\n",
      "iteration 1500 / 2500: loss 48.788851\n",
      "iteration 1600 / 2500: loss 41.566841\n",
      "iteration 1700 / 2500: loss 35.665010\n",
      "iteration 1800 / 2500: loss 30.826442\n",
      "iteration 1900 / 2500: loss 26.868505\n",
      "iteration 2000 / 2500: loss 23.627745\n",
      "iteration 2100 / 2500: loss 20.978106\n",
      "iteration 2200 / 2500: loss 18.804091\n",
      "iteration 2300 / 2500: loss 17.025947\n",
      "iteration 2400 / 2500: loss 15.570935\n",
      "iteration 0 / 2500: loss 7482.221629\n",
      "iteration 100 / 2500: loss 1010.259139\n",
      "iteration 200 / 2500: loss 143.148560\n",
      "iteration 300 / 2500: loss 26.973428\n",
      "iteration 400 / 2500: loss 11.408106\n",
      "iteration 500 / 2500: loss 9.322597\n",
      "iteration 600 / 2500: loss 9.043239\n",
      "iteration 700 / 2500: loss 9.005792\n",
      "iteration 800 / 2500: loss 9.000773\n",
      "iteration 900 / 2500: loss 9.000098\n",
      "iteration 1000 / 2500: loss 9.000010\n",
      "iteration 1100 / 2500: loss 8.999997\n",
      "iteration 1200 / 2500: loss 8.999996\n",
      "iteration 1300 / 2500: loss 8.999997\n",
      "iteration 1400 / 2500: loss 8.999996\n",
      "iteration 1500 / 2500: loss 8.999996\n",
      "iteration 1600 / 2500: loss 8.999997\n",
      "iteration 1700 / 2500: loss 8.999996\n",
      "iteration 1800 / 2500: loss 8.999996\n",
      "iteration 1900 / 2500: loss 8.999996\n",
      "iteration 2000 / 2500: loss 8.999997\n",
      "iteration 2100 / 2500: loss 8.999997\n",
      "iteration 2200 / 2500: loss 8.999997\n",
      "iteration 2300 / 2500: loss 8.999997\n",
      "iteration 2400 / 2500: loss 8.999997\n",
      "iteration 0 / 2500: loss 9.835408\n",
      "iteration 100 / 2500: loss 9.818000\n",
      "iteration 200 / 2500: loss 9.813934\n",
      "iteration 300 / 2500: loss 9.823199\n",
      "iteration 400 / 2500: loss 9.821434\n",
      "iteration 500 / 2500: loss 9.810233\n",
      "iteration 600 / 2500: loss 9.824064\n",
      "iteration 700 / 2500: loss 9.808342\n",
      "iteration 800 / 2500: loss 9.806808\n",
      "iteration 900 / 2500: loss 9.811276\n",
      "iteration 1000 / 2500: loss 9.830621\n",
      "iteration 1100 / 2500: loss 9.810898\n",
      "iteration 1200 / 2500: loss 9.797718\n",
      "iteration 1300 / 2500: loss 9.815452\n",
      "iteration 1400 / 2500: loss 9.811630\n",
      "iteration 1500 / 2500: loss 9.802906\n",
      "iteration 1600 / 2500: loss 9.778366\n",
      "iteration 1700 / 2500: loss 9.796517\n",
      "iteration 1800 / 2500: loss 9.788306\n",
      "iteration 1900 / 2500: loss 9.786633\n",
      "iteration 2000 / 2500: loss 9.787641\n",
      "iteration 2100 / 2500: loss 9.777824\n",
      "iteration 2200 / 2500: loss 9.787369\n",
      "iteration 2300 / 2500: loss 9.798076\n",
      "iteration 2400 / 2500: loss 9.796615\n",
      "iteration 0 / 2500: loss 16.722577\n",
      "iteration 100 / 2500: loss 16.573654\n",
      "iteration 200 / 2500: loss 16.417707\n",
      "iteration 300 / 2500: loss 16.262362\n",
      "iteration 400 / 2500: loss 16.125985\n",
      "iteration 500 / 2500: loss 15.978694\n",
      "iteration 600 / 2500: loss 15.835789\n",
      "iteration 700 / 2500: loss 15.702219\n",
      "iteration 800 / 2500: loss 15.564023\n",
      "iteration 900 / 2500: loss 15.449102\n",
      "iteration 1000 / 2500: loss 15.327800\n",
      "iteration 1100 / 2500: loss 15.192748\n",
      "iteration 1200 / 2500: loss 15.072904\n",
      "iteration 1300 / 2500: loss 14.961466\n",
      "iteration 1400 / 2500: loss 14.842652\n",
      "iteration 1500 / 2500: loss 14.710643\n",
      "iteration 1600 / 2500: loss 14.598367\n",
      "iteration 1700 / 2500: loss 14.500116\n",
      "iteration 1800 / 2500: loss 14.386215\n",
      "iteration 1900 / 2500: loss 14.275353\n",
      "iteration 2000 / 2500: loss 14.169624\n",
      "iteration 2100 / 2500: loss 14.072797\n",
      "iteration 2200 / 2500: loss 13.980074\n",
      "iteration 2300 / 2500: loss 13.872317\n",
      "iteration 2400 / 2500: loss 13.781560\n",
      "iteration 0 / 2500: loss 88.562591\n",
      "iteration 100 / 2500: loss 74.145217\n",
      "iteration 200 / 2500: loss 62.330654\n",
      "iteration 300 / 2500: loss 52.657905\n",
      "iteration 400 / 2500: loss 44.748288\n",
      "iteration 500 / 2500: loss 38.260106\n",
      "iteration 600 / 2500: loss 32.948899\n",
      "iteration 700 / 2500: loss 28.603795\n",
      "iteration 800 / 2500: loss 25.053871\n",
      "iteration 900 / 2500: loss 22.140520\n",
      "iteration 1000 / 2500: loss 19.758114\n",
      "iteration 1100 / 2500: loss 17.807963\n",
      "iteration 1200 / 2500: loss 16.209873\n",
      "iteration 1300 / 2500: loss 14.905808\n",
      "iteration 1400 / 2500: loss 13.834507\n",
      "iteration 1500 / 2500: loss 12.956141\n",
      "iteration 1600 / 2500: loss 12.241187\n",
      "iteration 1700 / 2500: loss 11.652574\n",
      "iteration 1800 / 2500: loss 11.171010\n",
      "iteration 1900 / 2500: loss 10.777072\n",
      "iteration 2000 / 2500: loss 10.452940\n",
      "iteration 2100 / 2500: loss 10.190284\n",
      "iteration 2200 / 2500: loss 9.973310\n",
      "iteration 2300 / 2500: loss 9.797904\n",
      "iteration 2400 / 2500: loss 9.653665\n",
      "iteration 0 / 2500: loss 777.502941\n",
      "iteration 100 / 2500: loss 111.967865\n",
      "iteration 200 / 2500: loss 22.794272\n",
      "iteration 300 / 2500: loss 10.848326\n",
      "iteration 400 / 2500: loss 9.247555\n",
      "iteration 500 / 2500: loss 9.033237\n",
      "iteration 600 / 2500: loss 9.004410\n",
      "iteration 700 / 2500: loss 9.000563\n",
      "iteration 800 / 2500: loss 9.000042\n",
      "iteration 900 / 2500: loss 8.999980\n",
      "iteration 1000 / 2500: loss 8.999958\n",
      "iteration 1100 / 2500: loss 8.999962\n",
      "iteration 1200 / 2500: loss 8.999968\n",
      "iteration 1300 / 2500: loss 8.999960\n",
      "iteration 1400 / 2500: loss 8.999974\n",
      "iteration 1500 / 2500: loss 8.999960\n",
      "iteration 1600 / 2500: loss 8.999969\n",
      "iteration 1700 / 2500: loss 8.999965\n",
      "iteration 1800 / 2500: loss 8.999964\n",
      "iteration 1900 / 2500: loss 8.999963\n",
      "iteration 2000 / 2500: loss 8.999967\n",
      "iteration 2100 / 2500: loss 8.999959\n",
      "iteration 2200 / 2500: loss 8.999964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2300 / 2500: loss 8.999959\n",
      "iteration 2400 / 2500: loss 8.999964\n",
      "iteration 0 / 2500: loss 7645.847099\n",
      "iteration 100 / 2500: loss 9.000002\n",
      "iteration 200 / 2500: loss 8.999997\n",
      "iteration 300 / 2500: loss 8.999996\n",
      "iteration 400 / 2500: loss 8.999997\n",
      "iteration 500 / 2500: loss 8.999997\n",
      "iteration 600 / 2500: loss 8.999996\n",
      "iteration 700 / 2500: loss 8.999997\n",
      "iteration 800 / 2500: loss 8.999997\n",
      "iteration 900 / 2500: loss 8.999997\n",
      "iteration 1000 / 2500: loss 8.999996\n",
      "iteration 1100 / 2500: loss 8.999996\n",
      "iteration 1200 / 2500: loss 8.999997\n",
      "iteration 1300 / 2500: loss 8.999997\n",
      "iteration 1400 / 2500: loss 8.999996\n",
      "iteration 1500 / 2500: loss 8.999997\n",
      "iteration 1600 / 2500: loss 8.999997\n",
      "iteration 1700 / 2500: loss 8.999996\n",
      "iteration 1800 / 2500: loss 8.999996\n",
      "iteration 1900 / 2500: loss 8.999996\n",
      "iteration 2000 / 2500: loss 8.999997\n",
      "iteration 2100 / 2500: loss 8.999997\n",
      "iteration 2200 / 2500: loss 8.999997\n",
      "iteration 2300 / 2500: loss 8.999997\n",
      "iteration 2400 / 2500: loss 8.999998\n",
      "iteration 0 / 2500: loss 9.787974\n",
      "iteration 100 / 2500: loss 9.781665\n",
      "iteration 200 / 2500: loss 9.766691\n",
      "iteration 300 / 2500: loss 9.757787\n",
      "iteration 400 / 2500: loss 9.731611\n",
      "iteration 500 / 2500: loss 9.719611\n",
      "iteration 600 / 2500: loss 9.728572\n",
      "iteration 700 / 2500: loss 9.708250\n",
      "iteration 800 / 2500: loss 9.670711\n",
      "iteration 900 / 2500: loss 9.661113\n",
      "iteration 1000 / 2500: loss 9.652898\n",
      "iteration 1100 / 2500: loss 9.654474\n",
      "iteration 1200 / 2500: loss 9.619425\n",
      "iteration 1300 / 2500: loss 9.606736\n",
      "iteration 1400 / 2500: loss 9.602105\n",
      "iteration 1500 / 2500: loss 9.581681\n",
      "iteration 1600 / 2500: loss 9.580521\n",
      "iteration 1700 / 2500: loss 9.554687\n",
      "iteration 1800 / 2500: loss 9.556446\n",
      "iteration 1900 / 2500: loss 9.534854\n",
      "iteration 2000 / 2500: loss 9.528145\n",
      "iteration 2100 / 2500: loss 9.500882\n",
      "iteration 2200 / 2500: loss 9.510590\n",
      "iteration 2300 / 2500: loss 9.490809\n",
      "iteration 2400 / 2500: loss 9.484492\n",
      "iteration 0 / 2500: loss 16.489387\n",
      "iteration 100 / 2500: loss 15.139993\n",
      "iteration 200 / 2500: loss 14.016256\n",
      "iteration 300 / 2500: loss 13.110229\n",
      "iteration 400 / 2500: loss 12.363878\n",
      "iteration 500 / 2500: loss 11.751542\n",
      "iteration 600 / 2500: loss 11.254355\n",
      "iteration 700 / 2500: loss 10.848152\n",
      "iteration 800 / 2500: loss 10.503687\n",
      "iteration 900 / 2500: loss 10.237347\n",
      "iteration 1000 / 2500: loss 10.013231\n",
      "iteration 1100 / 2500: loss 9.827785\n",
      "iteration 1200 / 2500: loss 9.677732\n",
      "iteration 1300 / 2500: loss 9.552353\n",
      "iteration 1400 / 2500: loss 9.449680\n",
      "iteration 1500 / 2500: loss 9.371895\n",
      "iteration 1600 / 2500: loss 9.303724\n",
      "iteration 1700 / 2500: loss 9.245382\n",
      "iteration 1800 / 2500: loss 9.201809\n",
      "iteration 1900 / 2500: loss 9.163538\n",
      "iteration 2000 / 2500: loss 9.133638\n",
      "iteration 2100 / 2500: loss 9.108457\n",
      "iteration 2200 / 2500: loss 9.088154\n",
      "iteration 2300 / 2500: loss 9.071229\n",
      "iteration 2400 / 2500: loss 9.058916\n",
      "iteration 0 / 2500: loss 85.420535\n",
      "iteration 100 / 2500: loss 19.240435\n",
      "iteration 200 / 2500: loss 10.372400\n",
      "iteration 300 / 2500: loss 9.183006\n",
      "iteration 400 / 2500: loss 9.024116\n",
      "iteration 500 / 2500: loss 9.002869\n",
      "iteration 600 / 2500: loss 9.000144\n",
      "iteration 700 / 2500: loss 8.999724\n",
      "iteration 800 / 2500: loss 8.999733\n",
      "iteration 900 / 2500: loss 8.999638\n",
      "iteration 1000 / 2500: loss 8.999705\n",
      "iteration 1100 / 2500: loss 8.999703\n",
      "iteration 1200 / 2500: loss 8.999679\n",
      "iteration 1300 / 2500: loss 8.999588\n",
      "iteration 1400 / 2500: loss 8.999645\n",
      "iteration 1500 / 2500: loss 8.999668\n",
      "iteration 1600 / 2500: loss 8.999620\n",
      "iteration 1700 / 2500: loss 8.999628\n",
      "iteration 1800 / 2500: loss 8.999616\n",
      "iteration 1900 / 2500: loss 8.999686\n",
      "iteration 2000 / 2500: loss 8.999549\n",
      "iteration 2100 / 2500: loss 8.999661\n",
      "iteration 2200 / 2500: loss 8.999592\n",
      "iteration 2300 / 2500: loss 8.999631\n",
      "iteration 2400 / 2500: loss 8.999582\n",
      "iteration 0 / 2500: loss 781.318175\n",
      "iteration 100 / 2500: loss 8.999970\n",
      "iteration 200 / 2500: loss 8.999967\n",
      "iteration 300 / 2500: loss 8.999959\n",
      "iteration 400 / 2500: loss 8.999964\n",
      "iteration 500 / 2500: loss 8.999966\n",
      "iteration 600 / 2500: loss 8.999963\n",
      "iteration 700 / 2500: loss 8.999964\n",
      "iteration 800 / 2500: loss 8.999970\n",
      "iteration 900 / 2500: loss 8.999972\n",
      "iteration 1000 / 2500: loss 8.999968\n",
      "iteration 1100 / 2500: loss 8.999978\n",
      "iteration 1200 / 2500: loss 8.999975\n",
      "iteration 1300 / 2500: loss 8.999961\n",
      "iteration 1400 / 2500: loss 8.999968\n",
      "iteration 1500 / 2500: loss 8.999965\n",
      "iteration 1600 / 2500: loss 8.999971\n",
      "iteration 1700 / 2500: loss 8.999963\n",
      "iteration 1800 / 2500: loss 8.999963\n",
      "iteration 1900 / 2500: loss 8.999969\n",
      "iteration 2000 / 2500: loss 8.999973\n",
      "iteration 2100 / 2500: loss 8.999968\n",
      "iteration 2200 / 2500: loss 8.999967\n",
      "iteration 2300 / 2500: loss 8.999967\n",
      "iteration 2400 / 2500: loss 8.999968\n",
      "iteration 0 / 2500: loss 8265.715366\n",
      "iteration 100 / 2500: loss 9.000000\n",
      "iteration 200 / 2500: loss 9.000000\n",
      "iteration 300 / 2500: loss 9.000001\n",
      "iteration 400 / 2500: loss 8.999999\n",
      "iteration 500 / 2500: loss 9.000000\n",
      "iteration 600 / 2500: loss 9.000000\n",
      "iteration 700 / 2500: loss 8.999998\n",
      "iteration 800 / 2500: loss 8.999999\n",
      "iteration 900 / 2500: loss 8.999999\n",
      "iteration 1000 / 2500: loss 9.000000\n",
      "iteration 1100 / 2500: loss 8.999999\n",
      "iteration 1200 / 2500: loss 9.000001\n",
      "iteration 1300 / 2500: loss 8.999999\n",
      "iteration 1400 / 2500: loss 8.999999\n",
      "iteration 1500 / 2500: loss 9.000000\n",
      "iteration 1600 / 2500: loss 8.999999\n",
      "iteration 1700 / 2500: loss 8.999999\n",
      "iteration 1800 / 2500: loss 9.000000\n",
      "iteration 1900 / 2500: loss 9.000000\n",
      "iteration 2000 / 2500: loss 9.000000\n",
      "iteration 2100 / 2500: loss 9.000000\n",
      "iteration 2200 / 2500: loss 9.000000\n",
      "iteration 2300 / 2500: loss 8.999999\n",
      "iteration 2400 / 2500: loss 8.999999\n",
      "iteration 0 / 2500: loss 9.749916\n",
      "iteration 100 / 2500: loss 9.607418\n",
      "iteration 200 / 2500: loss 9.497328\n",
      "iteration 300 / 2500: loss 9.386803\n",
      "iteration 400 / 2500: loss 9.313992\n",
      "iteration 500 / 2500: loss 9.246633\n",
      "iteration 600 / 2500: loss 9.202525\n",
      "iteration 700 / 2500: loss 9.154874\n",
      "iteration 800 / 2500: loss 9.116782\n",
      "iteration 900 / 2500: loss 9.095781\n",
      "iteration 1000 / 2500: loss 9.076075\n",
      "iteration 1100 / 2500: loss 9.054090\n",
      "iteration 1200 / 2500: loss 9.031608\n",
      "iteration 1300 / 2500: loss 9.024097\n",
      "iteration 1400 / 2500: loss 9.013733\n",
      "iteration 1500 / 2500: loss 9.002608\n",
      "iteration 1600 / 2500: loss 8.994735\n",
      "iteration 1700 / 2500: loss 8.996663\n",
      "iteration 1800 / 2500: loss 8.986115\n",
      "iteration 1900 / 2500: loss 8.983003\n",
      "iteration 2000 / 2500: loss 8.979726\n",
      "iteration 2100 / 2500: loss 8.968680\n",
      "iteration 2200 / 2500: loss 8.977362\n",
      "iteration 2300 / 2500: loss 8.973897\n",
      "iteration 2400 / 2500: loss 8.971564\n",
      "iteration 0 / 2500: loss 16.764644\n",
      "iteration 100 / 2500: loss 10.036969\n",
      "iteration 200 / 2500: loss 9.137960\n",
      "iteration 300 / 2500: loss 9.015126\n",
      "iteration 400 / 2500: loss 8.999027\n",
      "iteration 500 / 2500: loss 8.997350\n",
      "iteration 600 / 2500: loss 8.996761\n",
      "iteration 700 / 2500: loss 8.997450\n",
      "iteration 800 / 2500: loss 8.996446\n",
      "iteration 900 / 2500: loss 8.996860\n",
      "iteration 1000 / 2500: loss 8.996482\n",
      "iteration 1100 / 2500: loss 8.996570\n",
      "iteration 1200 / 2500: loss 8.996349\n",
      "iteration 1300 / 2500: loss 8.997222\n",
      "iteration 1400 / 2500: loss 8.996246\n",
      "iteration 1500 / 2500: loss 8.996540\n",
      "iteration 1600 / 2500: loss 8.996247\n",
      "iteration 1700 / 2500: loss 8.996496\n",
      "iteration 1800 / 2500: loss 8.997245\n",
      "iteration 1900 / 2500: loss 8.995411\n",
      "iteration 2000 / 2500: loss 8.996626\n",
      "iteration 2100 / 2500: loss 8.995904\n",
      "iteration 2200 / 2500: loss 8.996310\n",
      "iteration 2300 / 2500: loss 8.995960\n",
      "iteration 2400 / 2500: loss 8.995937\n",
      "iteration 0 / 2500: loss 88.039684\n",
      "iteration 100 / 2500: loss 8.999652\n",
      "iteration 200 / 2500: loss 8.999667\n",
      "iteration 300 / 2500: loss 8.999625\n",
      "iteration 400 / 2500: loss 8.999615\n",
      "iteration 500 / 2500: loss 8.999651\n",
      "iteration 600 / 2500: loss 8.999679\n",
      "iteration 700 / 2500: loss 8.999695\n",
      "iteration 800 / 2500: loss 8.999651\n",
      "iteration 900 / 2500: loss 8.999727\n",
      "iteration 1000 / 2500: loss 8.999679\n",
      "iteration 1100 / 2500: loss 8.999725\n",
      "iteration 1200 / 2500: loss 8.999632\n",
      "iteration 1300 / 2500: loss 8.999652\n",
      "iteration 1400 / 2500: loss 8.999618\n",
      "iteration 1500 / 2500: loss 8.999676\n",
      "iteration 1600 / 2500: loss 8.999650\n",
      "iteration 1700 / 2500: loss 8.999695\n",
      "iteration 1800 / 2500: loss 8.999640\n",
      "iteration 1900 / 2500: loss 8.999712\n",
      "iteration 2000 / 2500: loss 8.999603\n",
      "iteration 2100 / 2500: loss 8.999650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2200 / 2500: loss 8.999713\n",
      "iteration 2300 / 2500: loss 8.999709\n",
      "iteration 2400 / 2500: loss 8.999643\n",
      "iteration 0 / 2500: loss 799.792335\n",
      "iteration 100 / 2500: loss 8.999991\n",
      "iteration 200 / 2500: loss 8.999999\n",
      "iteration 300 / 2500: loss 9.000000\n",
      "iteration 400 / 2500: loss 9.000008\n",
      "iteration 500 / 2500: loss 8.999999\n",
      "iteration 600 / 2500: loss 8.999996\n",
      "iteration 700 / 2500: loss 9.000006\n",
      "iteration 800 / 2500: loss 9.000001\n",
      "iteration 900 / 2500: loss 8.999995\n",
      "iteration 1000 / 2500: loss 9.000002\n",
      "iteration 1100 / 2500: loss 8.999991\n",
      "iteration 1200 / 2500: loss 8.999997\n",
      "iteration 1300 / 2500: loss 8.999996\n",
      "iteration 1400 / 2500: loss 8.999998\n",
      "iteration 1500 / 2500: loss 9.000008\n",
      "iteration 1600 / 2500: loss 9.000002\n",
      "iteration 1700 / 2500: loss 8.999994\n",
      "iteration 1800 / 2500: loss 9.000001\n",
      "iteration 1900 / 2500: loss 9.000000\n",
      "iteration 2000 / 2500: loss 9.000009\n",
      "iteration 2100 / 2500: loss 8.999998\n",
      "iteration 2200 / 2500: loss 9.000006\n",
      "iteration 2300 / 2500: loss 8.999991\n",
      "iteration 2400 / 2500: loss 9.000007\n",
      "iteration 0 / 2500: loss 7758.954396\n",
      "iteration 100 / 2500: loss 546765502966111313463219322144919994994343736364995240149555798320041026959769231366823423338425554713273609980263033609350531805777502111312970025386639338240615398794188068576993959168379453440.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_svm.py:86: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += reg * np.sum(W * W)\n",
      "/home/reut/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_svm.py:86: RuntimeWarning: overflow encountered in multiply\n",
      "  loss += reg * np.sum(W * W)\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_svm.py:106: RuntimeWarning: overflow encountered in multiply\n",
      "  dW += 2*reg*W\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_svm.py:84: RuntimeWarning: invalid value encountered in greater\n",
      "  loss = np.sum(margin[margin>0])\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_svm.py:102: RuntimeWarning: invalid value encountered in greater\n",
      "  mask[margin > 0] = 1\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/linear_classifier.py:79: RuntimeWarning: invalid value encountered in add\n",
      "  self.W += -learning_rate*grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 / 2500: loss inf\n",
      "iteration 300 / 2500: loss inf\n",
      "iteration 400 / 2500: loss nan\n",
      "iteration 500 / 2500: loss nan\n",
      "iteration 600 / 2500: loss nan\n",
      "iteration 700 / 2500: loss nan\n",
      "iteration 800 / 2500: loss nan\n",
      "iteration 900 / 2500: loss nan\n",
      "iteration 1000 / 2500: loss nan\n",
      "iteration 1100 / 2500: loss nan\n",
      "iteration 1200 / 2500: loss nan\n",
      "iteration 1300 / 2500: loss nan\n",
      "iteration 1400 / 2500: loss nan\n",
      "iteration 1500 / 2500: loss nan\n",
      "iteration 1600 / 2500: loss nan\n",
      "iteration 1700 / 2500: loss nan\n",
      "iteration 1800 / 2500: loss nan\n",
      "iteration 1900 / 2500: loss nan\n",
      "iteration 2000 / 2500: loss nan\n",
      "iteration 2100 / 2500: loss nan\n",
      "iteration 2200 / 2500: loss nan\n",
      "iteration 2300 / 2500: loss nan\n",
      "iteration 2400 / 2500: loss nan\n",
      "iteration 0 / 2500: loss 9.758278\n",
      "iteration 100 / 2500: loss 9.074668\n",
      "iteration 200 / 2500: loss 8.976624\n",
      "iteration 300 / 2500: loss 8.975605\n",
      "iteration 400 / 2500: loss 8.974990\n",
      "iteration 500 / 2500: loss 8.960620\n",
      "iteration 600 / 2500: loss 8.955450\n",
      "iteration 700 / 2500: loss 8.966024\n",
      "iteration 800 / 2500: loss 8.957734\n",
      "iteration 900 / 2500: loss 8.963129\n",
      "iteration 1000 / 2500: loss 8.969067\n",
      "iteration 1100 / 2500: loss 8.961383\n",
      "iteration 1200 / 2500: loss 8.966584\n",
      "iteration 1300 / 2500: loss 8.966258\n",
      "iteration 1400 / 2500: loss 8.969049\n",
      "iteration 1500 / 2500: loss 8.962745\n",
      "iteration 1600 / 2500: loss 8.967821\n",
      "iteration 1700 / 2500: loss 8.964799\n",
      "iteration 1800 / 2500: loss 8.969176\n",
      "iteration 1900 / 2500: loss 8.963051\n",
      "iteration 2000 / 2500: loss 8.961825\n",
      "iteration 2100 / 2500: loss 8.962144\n",
      "iteration 2200 / 2500: loss 8.972156\n",
      "iteration 2300 / 2500: loss 8.963634\n",
      "iteration 2400 / 2500: loss 8.966467\n",
      "iteration 0 / 2500: loss 16.580075\n",
      "iteration 100 / 2500: loss 8.995975\n",
      "iteration 200 / 2500: loss 8.997813\n",
      "iteration 300 / 2500: loss 8.996628\n",
      "iteration 400 / 2500: loss 8.996498\n",
      "iteration 500 / 2500: loss 8.997005\n",
      "iteration 600 / 2500: loss 8.995349\n",
      "iteration 700 / 2500: loss 8.996753\n",
      "iteration 800 / 2500: loss 8.997237\n",
      "iteration 900 / 2500: loss 8.996854\n",
      "iteration 1000 / 2500: loss 8.996099\n",
      "iteration 1100 / 2500: loss 8.995600\n",
      "iteration 1200 / 2500: loss 8.997415\n",
      "iteration 1300 / 2500: loss 8.996739\n",
      "iteration 1400 / 2500: loss 8.996160\n",
      "iteration 1500 / 2500: loss 8.996426\n",
      "iteration 1600 / 2500: loss 8.996355\n",
      "iteration 1700 / 2500: loss 8.996511\n",
      "iteration 1800 / 2500: loss 8.996538\n",
      "iteration 1900 / 2500: loss 8.996688\n",
      "iteration 2000 / 2500: loss 8.996937\n",
      "iteration 2100 / 2500: loss 8.996882\n",
      "iteration 2200 / 2500: loss 8.996042\n",
      "iteration 2300 / 2500: loss 8.997469\n",
      "iteration 2400 / 2500: loss 8.997960\n",
      "iteration 0 / 2500: loss 90.332487\n",
      "iteration 100 / 2500: loss 8.999973\n",
      "iteration 200 / 2500: loss 8.999989\n",
      "iteration 300 / 2500: loss 9.000080\n",
      "iteration 400 / 2500: loss 8.999963\n",
      "iteration 500 / 2500: loss 9.000057\n",
      "iteration 600 / 2500: loss 8.999942\n",
      "iteration 700 / 2500: loss 9.000019\n",
      "iteration 800 / 2500: loss 9.000111\n",
      "iteration 900 / 2500: loss 9.000018\n",
      "iteration 1000 / 2500: loss 8.999971\n",
      "iteration 1100 / 2500: loss 9.000009\n",
      "iteration 1200 / 2500: loss 9.000020\n",
      "iteration 1300 / 2500: loss 9.000084\n",
      "iteration 1400 / 2500: loss 9.000055\n",
      "iteration 1500 / 2500: loss 9.000013\n",
      "iteration 1600 / 2500: loss 8.999976\n",
      "iteration 1700 / 2500: loss 9.000042\n",
      "iteration 1800 / 2500: loss 9.000008\n",
      "iteration 1900 / 2500: loss 8.999968\n",
      "iteration 2000 / 2500: loss 8.999918\n",
      "iteration 2100 / 2500: loss 8.999998\n",
      "iteration 2200 / 2500: loss 9.000066\n",
      "iteration 2300 / 2500: loss 9.000123\n",
      "iteration 2400 / 2500: loss 9.000027\n",
      "iteration 0 / 2500: loss 824.560506\n",
      "iteration 100 / 2500: loss 57538473381748023753258378367206150160136618804337703220014450094277732533179179636332369495459363151710984628386268590387711613794108458324596642227058793908336986131126657900681097823815467008.000000\n",
      "iteration 200 / 2500: loss inf\n",
      "iteration 300 / 2500: loss inf\n",
      "iteration 400 / 2500: loss nan\n",
      "iteration 500 / 2500: loss nan\n",
      "iteration 600 / 2500: loss nan\n",
      "iteration 700 / 2500: loss nan\n",
      "iteration 800 / 2500: loss nan\n",
      "iteration 900 / 2500: loss nan\n",
      "iteration 1000 / 2500: loss nan\n",
      "iteration 1100 / 2500: loss nan\n",
      "iteration 1200 / 2500: loss nan\n",
      "iteration 1300 / 2500: loss nan\n",
      "iteration 1400 / 2500: loss nan\n",
      "iteration 1500 / 2500: loss nan\n",
      "iteration 1600 / 2500: loss nan\n",
      "iteration 1700 / 2500: loss nan\n",
      "iteration 1800 / 2500: loss nan\n",
      "iteration 1900 / 2500: loss nan\n",
      "iteration 2000 / 2500: loss nan\n",
      "iteration 2100 / 2500: loss nan\n",
      "iteration 2200 / 2500: loss nan\n",
      "iteration 2300 / 2500: loss nan\n",
      "iteration 2400 / 2500: loss nan\n",
      "iteration 0 / 2500: loss 7751.257441\n",
      "iteration 100 / 2500: loss inf\n",
      "iteration 200 / 2500: loss nan\n",
      "iteration 300 / 2500: loss nan\n",
      "iteration 400 / 2500: loss nan\n",
      "iteration 500 / 2500: loss nan\n",
      "iteration 600 / 2500: loss nan\n",
      "iteration 700 / 2500: loss nan\n",
      "iteration 800 / 2500: loss nan\n",
      "iteration 900 / 2500: loss nan\n",
      "iteration 1000 / 2500: loss nan\n",
      "iteration 1100 / 2500: loss nan\n",
      "iteration 1200 / 2500: loss nan\n",
      "iteration 1300 / 2500: loss nan\n",
      "iteration 1400 / 2500: loss nan\n",
      "iteration 1500 / 2500: loss nan\n",
      "iteration 1600 / 2500: loss nan\n",
      "iteration 1700 / 2500: loss nan\n",
      "iteration 1800 / 2500: loss nan\n",
      "iteration 1900 / 2500: loss nan\n",
      "iteration 2000 / 2500: loss nan\n",
      "iteration 2100 / 2500: loss nan\n",
      "iteration 2200 / 2500: loss nan\n",
      "iteration 2300 / 2500: loss nan\n",
      "iteration 2400 / 2500: loss nan\n",
      "lr 1.000000e-09 reg 5.000000e+02 train accuracy: 0.089122 val accuracy: 0.086000\n",
      "lr 1.000000e-09 reg 5.000000e+03 train accuracy: 0.095980 val accuracy: 0.117000\n",
      "lr 1.000000e-09 reg 5.000000e+04 train accuracy: 0.077469 val accuracy: 0.086000\n",
      "lr 1.000000e-09 reg 5.000000e+05 train accuracy: 0.111857 val accuracy: 0.118000\n",
      "lr 1.000000e-09 reg 5.000000e+06 train accuracy: 0.416163 val accuracy: 0.421000\n",
      "lr 1.000000e-08 reg 5.000000e+02 train accuracy: 0.104347 val accuracy: 0.097000\n",
      "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.113878 val accuracy: 0.099000\n",
      "lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.081000 val accuracy: 0.071000\n",
      "lr 1.000000e-08 reg 5.000000e+05 train accuracy: 0.416347 val accuracy: 0.421000\n",
      "lr 1.000000e-08 reg 5.000000e+06 train accuracy: 0.411388 val accuracy: 0.414000\n",
      "lr 1.000000e-07 reg 5.000000e+02 train accuracy: 0.121041 val accuracy: 0.139000\n",
      "lr 1.000000e-07 reg 5.000000e+03 train accuracy: 0.219122 val accuracy: 0.212000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.416633 val accuracy: 0.417000\n",
      "lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.395755 val accuracy: 0.404000\n",
      "lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.319224 val accuracy: 0.321000\n",
      "lr 1.000000e-06 reg 5.000000e+02 train accuracy: 0.404592 val accuracy: 0.400000\n",
      "lr 1.000000e-06 reg 5.000000e+03 train accuracy: 0.414796 val accuracy: 0.421000\n",
      "lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.401673 val accuracy: 0.410000\n",
      "lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.317694 val accuracy: 0.318000\n",
      "lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-05 reg 5.000000e+02 train accuracy: 0.416184 val accuracy: 0.418000\n",
      "lr 1.000000e-05 reg 5.000000e+03 train accuracy: 0.403980 val accuracy: 0.406000\n",
      "lr 1.000000e-05 reg 5.000000e+04 train accuracy: 0.324714 val accuracy: 0.314000\n",
      "lr 1.000000e-05 reg 5.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-05 reg 5.000000e+06 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "best validation accuracy achieved during cross-validation: 0.421000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune the learning rate and regularization strength\n",
    "\n",
    "from cs231n.classifiers.linear_classifier import LinearSVM\n",
    "\n",
    "learning_rates = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "regularization_strengths = [5e2, 5e3, 5e4, 5e5, 5e6]\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_svm = None\n",
    "\n",
    "pass\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained classifer in best_svm. You might also want to play          #\n",
    "# with different numbers of bins in the color histogram. If you are careful    #\n",
    "# you should be able to get accuracy of near 0.44 on the validation set.       #\n",
    "################################################################################\n",
    "num_iters = 2500 # tmp for development\n",
    "for rate in learning_rates:\n",
    "    for strength in regularization_strengths:\n",
    "        mySvm = LinearSVM()\n",
    "        mySvm.train(X_train_feats, y_train, learning_rate=rate, reg=strength,\n",
    "                      num_iters=num_iters, verbose=True)\n",
    "        y_train_pred = mySvm.predict(X_train_feats)\n",
    "        training_accuracy = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = mySvm.predict(X_val_feats)\n",
    "        validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "        results[(rate, strength)] = (training_accuracy,validation_accuracy)\n",
    "        if validation_accuracy > best_val:\n",
    "            best_val = validation_accuracy\n",
    "            best_svm = mySvm\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "\n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.419\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your trained SVM on the test set\n",
    "y_test_pred = best_svm.predict(X_test_feats)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEICAYAAACQzXX2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsvXmUZcdd5/n5xV3fvuRWWZm1qHapStYuW4uxZAkL24DdbhiW9hgDzWmWppvuw7QHpnuGPtBNw8DQh3YDcxiWphuDwWDA2G6wkTd5k2VtJZVqr8qqrNxevnz7e3eNmD/ek50WJdUrSZYtTn7PyXPy3bhx4xu/iPjFL36/iHvFGMMWtrCFLWzh1QX1jSawhS1sYQtbuHpsKe8tbGELW3gVYkt5b2ELW9jCqxBbynsLW9jCFl6F2FLeW9jCFrbwKsSW8t7CFrawhVchviHKW0TuEZHFb0TZ32wQkfMicv9lrr9eRE5c5bN+X0R+4eVj943FN1t9vhF8ROSgiDwmIh0R+RevUJmX7ZPfrBCRnxOR//EC6U+LyD2vIKWrhogYEdl3NXm2LO9vUhhjPmOMOfiN5jEuXm0D/lWEfwN80hhTMMb8+jeazKsRxpjDxphPvtTnfLP18S3l/TJAROx/yOX9Q8KrUHa7gKcvlyAi1ivMZWy8CuX8kvCNqO/XVXmPZqqfEZFjItIQkd8TEf8y9/3vInJmtDQ8JiL/aFPau0XkIRH5ldEzzonImzell0Tkd0RkWUQuicgvXG2nFpEdIvLnIlITkbqIvFdE9orIg6Pf6yLyhyJSfk7d3iMiTwK9l9h4tz1XRs91LV2uPBG5SUQeHcnt/cDfk+2LwdXKQ0T+O7AT+JCIdEXk37zIcp+3PiLy7SLyuIg0ReRzIvKaTWnbReTPRnzPbXYvjJbUHxCR/yEibeDdLxOfHxGR0yKyISJ/JSLbN6W9SUROiEhLRH5DRD4lIv/0RcjjQeBe4L0jub5PRH5TRD4iIj3g3lH//4NR3RdE5N+KiBrlt0TkV0ftdU5E/rkMl+fj9NUbReTJUR3e/+y4vUK9jYj8hIicAk7JEL8mImuj5zwpIkdG93oyHNMXRGRVRH5LRDJjyOQ9MhznnZGM7xsluSM5dGToJrl1U56vWMyb+sP7R/c+KiI3jFHu3+vjo/r+sIhcAB6Uy7iDn1O2JSI/K1/VdV8WkR2XKetuEbkoIve+ICljzNftDzgPPAXsAKrAZ4FfAO4BFjfd993AdoaTyfcAPWB2lPZuIAZ+BLCAHwOWABml/wXw/wI5YBp4GPhnV8HRAp4Afm30DB+4G9gHfCvgAVPAp4H//Jy6PT6qW+YVkNHXlAe4wALwrwAH+K6RnH7hJbbZS5HH/S+h3OetD3AzsAa8dsTvB0bleaM+82Xg/xw9Yw9wFnhg9NyfGz3n7aN7x2qrK/B5I7A+4uUB/wX49CjfJNAG3gHYwL8c5funL1Iun3w2L/D7QAu4a1QXH/gD4C+BArAbOAn88Oj+HwWOAfNABfg4YAB7jD75MMMxWQWeGT3rees9ymeAj43yZIAHRm1TBgS4lq+O6/8M/NXo3gLwIeAXr8DrIHAR2D76vRvYO2rjAHjLqH/8IvCFy/XNTf3hu0bt+tPAOcAZc6zev6lsM5J/blTfe9g0Zi+T538Djo7qIcANwMQm2e0byewicPsV+byUgT5mZX900++3AGcuV8nn5HsceNvo/3cDpzelZUcV3QbMACGbBiTwfcAnroLjHUBtjA79duCx59Tth14pGT23POBb2DSJja59jpeuvF+KPF6K8n7e+gC/Cfz8c+4/AbyBoUK/8Jy0nwF+b/T/z7FJwbxMfH4H+OVN1/MMFcJu4F3A5zelyWgwvlzK+w82pVmj/n/dpmv/jKGPHOBBNhkywP2Mr7zfuen3LwO/9UL1Hv02wBs3pb+R4WTyOkA9RyY9YO9z+t25K/Dax3ASv59NynbUxh/f9Ps6YHC5vjm6d7NiV8Ay8Pox2mLzc3aP6rtnU/o9vLDyPsFIr13m2WbUbxeA68fpG6+En+bipv8XGM7mXwMReRfwrxkKBIadYnLTLSvP/mOM6YvIs/dUGc6ey6NrMGyMzWVeCTuABWNM8hxO08CvA69naBkooPGcvFdTzgvhijK6zH3bgUtm1PKb8r5UvBR5vBS8UH12AT8gIj+5Kc0d5UmB7SLS3JRmAZ/Z9PvFtNML8dkOPPrsRWNMV0TqwNwo7eKmNPPcpfRLxOa6TPLVFcJmjnObeG6+/2rksLLp//7oWRM8f73PP7cMY8yDIvJe4L8CO0XkgwwtXZ+hEfblTeNWGLbb88IYc1pEfoqhAj4sIn/DUG9cjq8vIvZz+/FlOOpR+zzfmLsSrlbXnHmB9J9iODkfHedhr0TAcrNPZydDa+YrEJFdwG8D/5zhEqLM0I0gXBkXGVoek8aY8uivaIw5fBX8LjLsWM+dyH6R4Wz4GmNMEXjnZTi9XK9kfEEZPU95y8CcbOr9o7wvFS9WHi9VFi9Un4vAf9jUxmVjTNYY80ejtHPPSSsYY97yErm9EJ8lhhMKACKSY6jYLo3yzW9Kk82/XwZsrss6Q8t316ZrO0c8eC4XvrafvRi8UL0vxw9jzK8bY24BDgMHGLoO1oEBcHhTm5WMMfkrETDGvM8Yc/eIhwF+6UXU4ytyGMUH5nn+Mfc1xV/hWo/hpPTssy2GLsZncZGhm+f58N3A20cT1BXxSijvnxCReRGpAj8LvP856TmGAqgBiMgPAkfGebAxZhn4W+BXRaQoIkqGgbU3XAW/hxl28v8kIjkZBgvvYmhddoGmiMwx7HRfL1xJRpfD54EE+BcyDF6+A7j9ZeDyYuWxytDf/GLxQvX5beBHReS1oyBYTkTeKiKFEd/2KJCVGQWFjojIbS+By5X4vA/4QRG5UUQ84D8CXzTGnAc+DFwvIm8fTYA/wdDF97LDGJMCfwL8BxEpjAyhfw08u+f5T4B/KSJzMgwuv+clFvlC9f57EJHbRm3mMFRsAZAaYzTDNv210YqOEccHXqhwGe55f+Oo7IDhBJC+iHrcIiLvGLXPTzE0AL8wRr4r9fGTDC3+t47q/G8Zxgaexf8H/LyI7B/149eIyMSm9CXgPoZ97sevROaVUN7vY6hgz47+vuaQgzHmGPCrDAfLKnA9w6DduHgXw6XjMYbL+A8As+NmHg2A72DoT7sALDIMmv57hoGZFsMB+edXwelq8YIyuhyMMRHDoNi7Gdb7e3gZOL4Eefwi8G9luBvkp19Euc9bH2PMIwwD1u8dpZ0e3beZ740MA0/rDAdJ6Wo5XAWfvwP+HfBnDCe6vcD3jtLWGVpQvwzUGfpfH2GoIL4e+EmGivEs8BDDvvS7o7TfZtivngQeAz7CcEJ6MQrvBev9PCiOODQYunPqwK+M0t7DsB2/IMNdQB9nGMh7IXjAf2LYxisMNyj87Iuoyl8ybM8G8L8C7zDGxGPk+0ofZxjw/BoYY1rAjzPsf5cYtstml9n/w3BC/VuGQe3fYRjo3PyMCwwV+HvkCjuUnt2x8XWBiJxnGGz5+NetkC1s4ZsYo2X5IvBPjDGf+AZzeTPwW8aYXVe8+R8oROTngH3GmHd+o7m8VGwd0tnCFl5miMgDIlIeLe9/lmFsYJxl+cvNIyMibxm5feaA/wv44CvNYwtfH2wp7y1s4eXHHQx3FawzdOm83Rgz+AbwEIburgZDt8kzDPfDb+EfAL6ubpMtbGELW9jC1wdblvcWtrCFLbwK8Yq+TOXcZ/7C+LZgWQrbtsnl8hgSxBFs28YASikwGhGFsRVigFRjAJ0koA0m1cRRSBRGJElCvd6l3mxx5/f95Dh7w/nRB95lYsfDdjP0OgMajR6RStl3/U76bpcUhesqtm2vUKs3abdbzE9O4xrYWFol0Sm5aoG+jlisr1MsVMFY1BstAP7u/R8Yi8dv/PW/Mhk/Q6lcYhD0WV/fAKMAhcQxyrKwlCJIY4IwwFKCY9tksnmMgbXVNWwbHDskClzKxVlslUXsLmuNi/y7d//xWDzuvuN+4yQxBa/E9t0Oxy/G9II+23fYPHOiyfz8BPfevY9P/vUzNHsRszvKzB+o8MQXFuj2m7z+3pv4zCeOEnQtZmY9arUVds5vp9HpcM3e/fzpH71vLB7ze/MmIEVZzvCCpCgZWhiVTJWMl6XZb7Jzv83OXbNMluZ54oQFRmPidWq1M4DBdRxc8blvV5nb9uzkuDrA+/78z3js4RNj8fib//lHRqewWqvTiUJynsWBHXM0Om0Gqabo5fC9DPlCGcdxyXtZuu06jmPwMx7aGKIoQKNxHI9CoYCI0O20UbbF3kNvGIvH7fccMqnW5HM5lIIwDAjDEK011dIMohRxHBMEPQpFn16vjxKPKEyo1Ws4jkMcDzdRhIMEow2O49Fp9kmimG4nGIvH29+137z1W/aSd1zOnb9IlHRpdUKu3VPh3GIAuscb7n0tFi28zE7WujHNxRVmd7yWW187R21VWF48h58XPvPFk6Sxz9y2Ert37uLiguEHfuhnxuLx87//XhNicBwbZdsocXAcF8vxcJ0stmOTkiIiWEqwjMFoQUSRkuB5OfL5EtXqBJVqCQTCOGCj2SIMe7xj/2vG4uFN7TGlg/uZO3wD11//Or7vzd+CnXc42+iz2ohJYqjkilgqRWuNpSxsV7DRlHMurtH4to1SFlGYIFqTiiGIU3zH5Tv25sfi8Yoqb6UUSglKKYwxpGmCWIAxhGGIKIUowbIsjE4Qy0YZiOMIy7awbRudJOgkRUyKpUBsRca3Keav+E6br8DPZUgSiOMYARzLoR8ldHsDAkKU6+I4Fl7BJxdlSaKIaLVHa6XByqkFygcmmJmbpFIskZsqEYQpvW7I7sk5SqXi2DxyuSz93oB8kse2LHzfx1IOoLBFo7Ue3hhBGqZI7LB8tk0mq1BK0W7D0aef4PCN81QmCvT6TQoZi6mJEhutlRcsezOqUxmcjsPaygqT89ewvL6C51hsLGskhG69RxKFOJbFZLmMMopjRy+Qotm/d4ZjDy9iBnlMGrK8uMYgiDjZXWByxxTpVbjlHM+AUhjbgBJyTh6RFCTEJkAcIWMpwrTPcm2ZQq6CZecIwgaYdZCAbq+H59pUts+RZm0evXCJ/Xffyq5dVzz/8RWsrNbI5/K4voejUtIkotsfoC2PL3/pKVxsisUKmUwR27Ip5EsoP2JxZRHbgtnJAhlPYYmh04tx/SyV6hTlnGJ5bZm9h8Y7huDaHjYaEUiVoLCwsRnEAVEaoYyF41qEoVBb26BYLGIMdHttRBRhGCMIjutQma0iKBqNFkkcodOrcJeqlOPnlrjt2nl27yyzVovZNTfFWqNJJiconSdKUnZOzZHqEp67SLvdpDK4RNBzubTYJxo0KE9s4547DrK81GMwaLFw4SRpOv65MmPAiCY1MTrViDLo1GArjbJBJ4IAaZrgui6IYLQ1yhthHKHbDomCHlFaplgq4zkuu+bmiZNobB43PfAA3/a2f8Q1B/dQzU+R8RWfeuwJFlsDOt2Ym48coerGrEUBZy8s41iCW56k6JZY73bRcY9CNoOOYyYzHhNZDxuDFyeQGIaHx6+MV1R5x0mMjcK2PYwxxHGCq+zhTGlZWLaNNnp41l8JGlB81SqPo4g4ioj6fRwlpElMmmowGscZ/0WCiYbWRhNtBNvy0GgyuSzaCIVSmURSLMcCbHRsYGCYcCc4XV9FD4RcuYCbcwnTkE6/QxBpYgNRNyVOxt/O22q2EFE0Gk2CcICybJRrk8tlSeI+aZySpilxELJ7bhcFZ5r3/9dfo1yt4Ps+a7UaC5fOceDQXhzXQlkpg7CF6xQo5sbf5nz4xm2c/MQFMuIQ9IabgMVYhEFK1ockjHjskYskqZAGEVGQMuhHVKZcXnfbfv7kD5+m2+2QpH3SJMSYhL5JWVlqsnNej83DcUFjUL5glMHRMUpp8DRZF4zu4QnYDjSbLZ5++hgh8yR6A5J18gWLUrlMuZQDFbLQWCQZGLylp8kVxtnGO8Sdt95MLxjQ6XXp9tqU8mVqjR6PH1/AsSewbZtWL2JyokipUCJOYrQaXusHLYyK2D4zgZDSTUIunLxAPzjKnh076A+6vHVcItpw722v5eLyBZYa60xNTFHI5sgWcjx28jQT1QoHDx7iox/9KFobXNfDGE2pVCSvFYNBQK/XQ2vDxsY6GEWn0wNhqNzGhO9pllYadHdOUcp75LIWB/ZsJ78GOT9Pu+fRaiiCKpRKs5StPuK3GZhVmuuawaCEbRniqEWpXObShQVcz2LnzE2cv3AV29+NQkixcEDbuJk8KI2olNT00UYQZWGUJsYQm6GuUcpCtIMGMCmRDtjorNIcNHGVy/zcXixnfA/ynttuY37XPjrNDhePLzK/d54vPfEUjW7M7Udupiwpk17AH3zgAzT6IXGSoHIVDu89TK+3QbO5zLUHDnDTkevJOjaWZRCjyWR9knQsoxt4hZW36yiUNqRJhJdxcV2N7WqMWENr22iUbZGk8VcsAyUGTEocpoiJaTc7FHIlkmhAFBksBGVb2FdhSKRxyPbJCpZlE8UJx0+fJ3UylAZZ2ufr7N45y5Fdh5jKZ1hqG5pFj0Ff0HmPXtWDySwtHeBnfawwg6MVYRDRWN3Asi73KoXLo9sd4PsecZhyw7X3Yehx5vxRGoMlOlEf3y8RJSHV0iz9JCUKa5w7uwYL69iuRbfTRZRm7VKbvTfPkfEtHC0EYYhlvCsTGOHTf3eKbGKhlUXtQo1sFJMGCZ0koTpRZr3W4nSzhmcJN994hB3zBS4+8STXXTPBjkIJJTUcK0GMJp/z6PVSHGWjY411Fe3iZxS2pQDB912yBSiXsriW4bY7riGTi4kjF1C0GjG1eptOt04QhJg0w6F9O5ndPk25nCefUaR6aLX2wgFz14//XYtTZ5+hOlGlWMiybaLCSl1oBXDtwdvotTdIE02sE2xHM7e9zORklUYrZvtklcXlkxw/f4GziwvUNlroKKBUyFPI5fj0l57BcZyxeRRKGc6tnmXP7Cy3vOZ6nvz840z5RXzX53se+HZy5SKf+txnKVbK2IMBnW6XXDaLbVtkPJdc3qVUyRBHMd32gDCIcF0XJUKsx2+YC5c6zJQtPvX509y4P08qFl8+fpK5a3byhjf+BCtrG7R7KTPVAu32Bo1LC9xw012c/+KDnGwElPf0CAeGC+e6OMVjlGdzDAYeWT8l42SvTGAE2whi5cEYlG1hieB4LsYyDM8eCdJPcYsFurUGhWqZOO0Dgudl0CZBEKK4R9gIcV2fyHI4mUZoHXHr4fFWRH/ziYcwkuFi4xLnzp+FKCbxXHKFEh958M/5UJiyfft+zi+usrK+hlEJiWieOXMU3/NRYcyjX36cv3T/nG+95y40in6/x//xg9/NTDk3vjzGvvNlgEljHDuD42VRtoWWPkYUURCRzeVQtkVjEPHYo8dotbpYluLQwR3MTFfIegVWLp7jkc89zF133omb8YYWeZh81b0wJhwxFHMupVKJ2vo6yoQoyVL0s2QLDtfv2seB6TkmPJdMP+bo2hkGWYeZA3Nse81Oinvz9KMuYRzRaXfotEMGvYRWo04mM75IM5kMvV6XyUqV6co2FhaO0tnYwFgDYtvG9CMwgsr1KeYrDJopiY4xWoji4eCzlE17o0+lVMRzhLATgDIUyuO7CRzXJYo1qQg2kM1nSZKUqJ9w6MAeHlp9GMHD9VNcN6FSzXE6UVxc7rL0haMcuX43X/zCSbrtDsXJKm6xRLPdRVKNfRUxcT/joR1rGNfQCeVijqmpDJOTHrNzPtrY6NhFKZio+lx7ZJpWOyIMNEmkyXou2bxPsZQnibsY0YhSeL4QReNbeNvmtjFbncJoTZAYnjx5ionqduamq3zuxFM8/thTeK7N937322i36vQ7TbbNX8PSWkI3yBCnMUHYxbI0lm+R6pQwCDm4c56hkhkPszNlFpeW6PS6WOcWaF5cYWW9hpPPsLM/YHJ2O9vmd/D0wmmSJCZNElLHxVJCPudTLpYQhG6ny4VoiTjSeI6HJQa5GrdJ6CCpR9Z3uLSsQXXYvtOlduE0tdUnqdXPcvzMWR649z0Y0yLj2fiejfGKLJxcY/7w26itHGdqm8+F1TqGASaFwq48Oq6PTSOOU8IoQIlBlJDGCUnqYXk2lm0waUrzzCKlwwc49chT3PTGOzGWIY1CTKgxrqAchQOYNMXWLiLQ7bRQV2F0tesrPHX0yyyvL2KnKUUcMkaYyMOb3no/SZxgUpf2vilanTZGJ3zsC19io9OlW6vjOznSIGXDNvzxh/8Wy/GxXJsb9s5zYKbM991xx1g8XlHlnUQpK70eGxdbGK3YtWeSbEZhUsMg7lNbb/LXH/siFxZqKLFwLMOJE4v4GZcD+/ZwcNcErXbAseNnuO6W16B0zOriEtUd24ZxvjExOzVBFA3I+YI1mSPrCqv1Ot16lZ3zc8xMTDJVnWTjwhLLi3WWa3Vk5wTZahZcTaaYxU1ddBIwaLYouRZxQWPtKpOO3wcwxtDr9XCtNufOnmLhwimSKEBLSHF6hrgrhP2IgfTZ6EMa+LieS7fbJ9UppVIJ27boNEMKuQw6jlB+hl6/h++PP4P3en3SXoojFp7rI3GIZQk33XwY3xWUY2GJAYSN1TUaExku1Tusti2StQE7r9mNjmGmMkG1WKLR6oNR2LY1cj+NB9930a4NSYoCpqeylEoOE1MZRCwkLeGI4LmQpB1MOmCikscYizQRbOVgSFBWShzFIBCnMTp2CYPx3SbZTIEwMSRxhHJyZNw82ycnKPhZ8vk8c/Pb8CwLhWGyWmZtvcGg00VZFvV2iO9XKGUTVBLj+SVc2wYNYjTVcvnKBEbQOmDb1AzNRoco7jM/P8PCwgIbax2W12qUK9MUKhXKuQzTu3YyOTFJpVJhYrLK/Pw0h/btQ4zQ73T4u09/nk995hFOnTlPEIc0m+NvO7/zpmlKuQpzZYdMwef84jr9YIXd2/I8/vCHmKhMo4IGa+uPUMzuJJMrMD0xzae7IavdgKePPYa4A/LVa5mMJ2l2asxMzLG4tEDK+P20WW8SWw4mjVEiYBm8Uo7iRIVc3kMMbCyvUdy7l/byBt1ej2K1QNCPCXsD/KkMlm2wbQVKIQqiJCHUMcNXpYyHw4fm6S6fo3/yFBmt6IlFF0Nd4Kff+U68bAbXVkxO5LDEYCLhLbe/jtMXLvLhBz/Fl54+i237RKnGMho7jqhkK1w4fRq96sM3o/LWJsNbfuRHKBSK/Mg738kf/OUH8V2HUi6L1oallTXCVPCzijgaUHAUfi/P2UtNnjy9Trd+jorv84Vnljj6G7/D99/7Ldy5fx+O6w4d2WPiqWMLzMxkaXWalKolylMVBrrP6VPHuOXWvaRJSraYge2TWMsLeFWf3O4SkWtIrZT1lXXSWJOYhFwhB1GfgzfuYeDHxNH4s4jrOlSrFTbq6zxtPsXMtipZs42gF/I3f/gFzh9bImiGNMMObibPzp17mdk2z5SO6XV7pDql0+px4fQaly6cx7MdlHEJJcRcxbeEut0AiVNSDNfs3s7Zc+ewjJA225w+fwbL1vi4nGrW2XbNHINuzEqrSxhGxEpx/NTj5HIZPM/mUq1OmBpwHYJBnygZX2laTsLs7CS+K2ybLlKZSrFdKE8UGbSmefphTe3SgEqlQJgE3HznJLsOJURRiiUaJCFJQ9Yb68SpIUkTPN9HR32UNb4v8dSZsyil6AcDolRRKe4m52VQSrjr9tdy+403oJOEpZVLhFGISaHV2KDf7BA11ugGCdt33kjh2jJnzx7j+KnjKAuqxRz1zvgrgPOLLVrtOoVCDj+x+cjDRxFlcFG89S03c93B67n+2iNcf+MBjBK0MYjIMLKXxgTddVzLkPpw4Dtfzw+96U7Orrd58w//FKjxA3RVV7F9yieRDW64+S7uuf86Tj/9UU6deJj9+/awtrTG2eMDZmYusmpWaPTbTHYvcaN6hKVqhKldIPAP8bnPPMP22TydmkW3d4KbDu1DXcXHn1aX1lGZDDpNQRnylQxRU9NqdrAdhes5+DOTHP3TB7FxqT16gsfPrzOodQiTgG375pndPc/koe24ZRBi7IzCw8Vm/BjAf/zpH+Ndb/t+nChEZXMUt8+yfWqCcydPcHR1g9tfdxeW0QS2YNuKbN5w77YKb7nrNfzU930Hv/Sb/41ap0sm46FXTnD93nmKGRs77aKS/tg8XlnlbWvuvOF6bFLeevcNZE2fMxcu0mguU2u06fRiDu4/jAlrDNKUJAhp1dfQWASx4qnzS+ycmWJmZobbrruR6eo2lupNdhhDEo0/c2azWVRqsGyLTrNNlKRUZyrEKuWpp48zNzfHwsIaEnXphl3IuTx55ixxkiBRSrFQJVsokM3nGPTr5PI5WoGm0exRW2temcAIlq3RJqIykSWfK9Ho1bHjLMmGx/FHzjLohJjEkBghTgKWLy2jEaoTFfwMXFq6RNSP8BwL1y4QRn3SqE9sYgb98QdnFIbYRqhWhnEADCjfpZlE7Dl4gEKnTW+tQ36+wozrsnL+ArbnE8cGYxJszyOIEixHo2wP34bBICBJEtKrWIp4fkq1rMgVYP4an1R3sFyFsUKiXsrxp85w9vQy+/YdoNloUWtu8I/nSujExnbAtfOI5WA5FlEUkeqEbr9P3i6SXoWbYPvUDEqEQRxRb/XZaPaot1tYnZg9c9vRro1lKSanJxiEIUsXl4iI0STki1mMHVFfuUgabLB3fpKTZ1Iu1dcxZhJld8fmoewMluvRbLbJG49cMYdt21iJ4Z7Xv4433H0fOkxJB10SY0DAsh0s2wZlo2yPIOqSRBEF12ATkDch++bnOH3+wtg8+lozO1mkn0aYtEu+sp9DN08gVsKlhy7i5S2un56mf2qVRMdYfsDUnA27c5jgCMt1TRDluVhrMz8X4GYFZWcIogGxHr9/JLEml7OJUw0iRIMQ5Wpik+JoiySJ8dwM6+vrhGHEoFGnmJ9AMj46TFk9fwGTGtzpIq4xZLMpKuxjbA/lja+8V46dIVOoEg5WyZdLxJFmojqLe0OR2lq5ag7cAAAgAElEQVSNp59+irwVknN98oUyE5U8naCDlSZkMz7/y1veyIkTJ3CslLi8gasGRGHKuXoNrTVvvjIF4BVW3mI07/nJH0PHfSr5DLfceITZ7TOs1up8+MHPEacp7foKtx2cZmk15uJqn167iXKzLFxapxNEdKOE/aUSeybzVKbKqCQcKYnxX5Q2tb1M2qgRtgc0Ol2STA7takrTVVKxefhLR/njP/oLpss2hek8md3badcTVJii6z2CnCFTSVDSwtBHpkvYTkoSudgUxubhuArfdxCxsCwhDQxRI+Wph44z6EZEcTTcbYJBa+j12liWR61WIwgj0iTFGIMYQ68XEUQBkhosx6LVHX8SieOYcrlCu9liITEEQYohYdueKVhvc+2uWfqz2+jXWxTrbbYdOMzfHf0wGcvD6IhScZJ6vUWvF+LZCtCQJCByVW/SPnjtbjxfMTVTIJvzSbXBYMBYbNQ71NbqhGHAysoySQL1xxU62IWXHYAKsUafR/Vthco2cLVDPwxRlsK9isE5U53kyTPnWVpdpjcImZg8jEYI+wParQ5KDOVqmbX1DU5fuMDJ8+dYb7dotXv0BgGtdotiNkO5kaV7tEO33yfj5mg0W5TL4/ePjUabPdfspVuvs3FpBaKYSqmM53mk3TZRu4nR4Ng2KjYYBCNCggZLULagQ0AslOPgZhJyWUPFTpGriBP1w5SNjTZ79m1n0KqRxhtkinvYtu0G6v1HGQwyKHsYdFNOTKmgKM4eojU4hDN4LTtny4RnjzHFIqsbTdoDTdZ3aHWzpFehvC1loZMUnaZoDWIpIh2RYrAtC9t2MEZhMJgkpdcb4LkBWILtWRArLMum3w1pDtrYtoWXd5menUfL+PL4qz/9AO3FFUwwYGBW6fcSPnz0GPnpKtnKNlq1NSqVAjcc2Isog+0rLlxaBDFM5TPs3b0H1/c5+uSjzLopYb9Ls9sjIECuwv37yn7x2Bgm8i62m8EYsCybUsanozW7t1WZODjP/NQEq6ceJ6MFZVl8/tgxFA6T5WlsW4CE+soiD9z5bVhOyq4de65aeTMDRTtP2PXQXpZat0ejW8fLeFy7bz8512N2/jaa6zUmJsroICV7egmtoDxVxbUhl8ZYCLavSLsbFHJFtu0os7Q8/rInCgxJrEh1RLu3gGrP8emPPsGpYxcJ0pjEaMS2SKMQnUKn08F1U4LWgFSn2LaN7SgmpoqsrtZwXItCJo/jgOeOv9tkW9bnwK4Kc7MHWbi4wvFTPcJel4e++AW2TW9nl+Ny4MhruHS+ztOdHqsffRDLQG/QxQDr9Q1SDEaEOB4ekhBlkwQRchW7GuZ2ZnBcoVzJUcgXSZMSmWyWWMfk9k/wtrddwyc+8UXiSBMGKa7fIukUaV7KECVNqtN1tAnI5/PEvSksD7JWA1EpVxModJTLU6eX+fRjx5ifLnNn5hLPXDrP3PaduK5HnETU1zc4v7LKxz/7Oda6QwUdBgFJHONnsiw3mqw02uT8MlpnsEyC6/u0G+P3j/X1dZrNGnPVCfpxSjfUdC4uo2yHM6dOUylOs3v3NRgRfN/Dsiy0mOF2OSxc18FWeYKeYdBoQxSgBwGzU5P4C7WxeXz7fd9KuTpFxq5hTA7P7nBx4SF+7/c+yw/ebRH28qzXUvycR2gXCTfWaLQ1K3I72XKB2uoGqV1jIIalJ9ZwcjbaVnRCqDjjv+Cw22mTtR1cx0GMJg4hRXB8jzQUEi1oHRJ1BgiGfhJjGg18zyNJAgr5PIWJCYyxSfoWCYpOc0C3uUKcRsNvRI2Bx48eZaY0wWJ4npgQ1PDgkO72+dh/+20iY/jOH/pxHH+KG3bazE/EvOb6I3T6A3qBZiOEG2+5jde//m48HRIkCRu9gP/5kQ/yzPEnxpbHK6q8A5NimwilHVIDQRDQaTW5tHCK73rzHfTqiyyuNNnohaQqh5/J0R0M2D5RwTYphYxNNOjgOpPk80VKOQdbLHQ6VBjjIpv1mDU2fTUgDBMq1Uk81xCFA3K+S6tep1wsE6YpruMzX51gV7mAN5Wj7yaUHJ+pQgWFwnGFMA1IVcIja6cp5sc/pJOkGs/zSbWFJAmnj61yaWGNIBwQ6xRlW8ODTYl69jt3OI5DQghpCqJxPZdczmfXrp3ESUJrvYntWWQy4x9a8jyHrBJWVjdYWt1gslpAmzydfsCF1VUmJiuU8hnE0tQ2NoiTBD/rkHd8okjTDaOhhQxfaQejNcoaHiYaF5PTRWxnaEWFYUjWr2BZLqlEaAIyuQye5zI9NcHaap1Gs8+DHzmJkjxB2ObQ9Xl2XTNJ1HU4c6xDedrlmusmaQ9WCKPxlbdSwnfe9wZWNzp8+amj3HHkWnTawxiDZVnYTgbfsfnymVO0uh1IUtB6aECIQmHh2EMLMDUR/WCAbVk4lkU+N37A8prdu+i068xum4FUWFtvoJSF47g0Wk1q6zWq1Sp+Jk8QJCjLws74YFLEdjEyNIAc22Hh4kVMOCCTLZIkKYbxLc35HdcwNfcakmidNHXBEqJBjcbKaSINltMiTl3KxQIShNh+j4X2NeBWKBQ8Hnv4BGuNHhvtiNAytNZ7WJ5HlOmRL4/fLhnPI0kNYdjF9TzEclCWhdGC0YxcY4IowXM9PHHphzG2eCQo8pkMltL0eh0sR+G6GXQohIOYMBo/gOtlM9gDm0G7A0GfaKDRysJ2bLIZD4lizp44zoWG4pO9NeZ3TnH3vd9GnCriOEE3FrAGDSyTMFkqUKpOsn3vQW66/X7WWt+kPu9EJySpGR7bTTTr6+tYSmNIycqAMKjTbzZo9UMaQUikXeIwQZIU19dMVAqUMjbX7d9FLpejtb7KVH6eUMdoPb7lncYJ5WIePYhxHCGXySLKIHGESlOIEwadAStL6ziJMO3m2DYzgc4J9fYlgl6TcjmP77g4YlPJT4LWHNeXaLRbY/PQ2qBNShiFWI7LyoUa/XZAGA+GfksDSZqilIXRmiTRwxOotsKgwIBg8DNDl0CSpHR7fSZmJhF7fKUZhANa/ZTj5y9gtObafdM0Wj2yXpYNNSCMQs498zi7J/M0imV0SeF4CdmsQ7OtOXNhBSyLMI5JjEGJDBWduoqoKaATiyjVGG+4jzcVCOIelmWw/ZjiFGzflicIDKvrS4R94ezJFrY1oB+0WV1a5U1vupNKMcfGxRph2GZmvoi4FtXK+IeW1ms1ctk8d96wn0ePHeUzjxxjvlLizJkz3HzttYThAKUdTpw6TRAnVArZoeVloNfto1MNSoExBFF3eEhE2WgjaD1+u9xx62HSqI0kQnO9hlECaFyJOXVhBdd/hm5nnftefzuDxCCWRblSwbYdxDNgCaQJBCGPPvIlJspFDt9wC7hCtji+GynjF9Ba42Ym8fwCnpqhVLV4w/3X8/nPfpwj1zlUd+zBKQ3oLazg+zHLtYC52QFnz55n0G/Ta2sKFcNscS9Pn1og6RjOPrPM5HXjB3CNMcSjE9ZaB2TzPogiSSLgWQNHEHt4ZqSYzeHmFF4+h8Km21ijEPRJbMMgiiiIjaUsBoPBVZ2wJBTOnHgSRUQaO1hiM7RREqLUwSiLZ44eJeMv0lo9i/OGu9FveAvNSIh6Xf70vf+F3uoipAmOlyGTzbL3uht487t+HF0a/1Oar2zAsjfAWEWSCJZr64ThgKKnObO8zr3a4dbX3sOtd9hc2uhy6twin3rkSZ445ZHzFa4acKhc5OYDu9g17VA/9nmq1+yiLwPSIECb8S2JhUaf861LVPJF8rumsPt9fJ3i+x7FbXlypQy9Rh/dD1lbWeWzQZNtgwnKMxME2rDQWOb8oI0rhqTZZs/cHvJ+nvmpKUrF8S3v1BhEDI5vYSLNYj2FbAYrHRANouELPZVFGgZDH58IyjJYdgYtggpjlNHkJzMEep1s3uXIDTvpDkIcZ/ymLU5M86WzK5AqJiuTnF5YwbU9lHKwlUWr0WZiboa402V/JUs+65PN5UCEFXfA7uokrusSa3j8zDnWWm20JQxMgLHGV+DZTBmjwfI1vaBDp9dCoVA6i6gWxZkc97/pFh75QoMkeny4I2TQw5gucRyxsS7899/9FPNzFQZcoNi0WOzb3HffbbQa40/up84u4NoOedvmjTfdzCcfP8VGo4GvFN+ePEB30Kfejrn1yGEs3QfR1Bo9cl6VddumFyZ4totl2cRpiqVsRBRaa5KxPs06xM237GKi6OPZGYrlHE+fvoSJDWlgeObsIspy6LSb7N+1A7GLrNfXmJ3LYdmQ97K4Tp4giDl1+iyJW6Q0PUez20NEaLbGD5x6hQOIcoiiACNdIpViKNKqXWTi4JtZWfoQ2w7B4kKDchrQq95DMZdlEBk826M7WMHQQyKLpZU6+WKeWtRmwpnFz42/2wRjY4sCyx2eDwm76DAG2yKJBU2Csmwqe+epnV8kbm4wffgQ3tQEkoKJDLoTkXEt0rJPP+hhkhSV8UfH0sdD6peZ23c9Z08+ilUtkSofWxSeZZEYi1tvuR2vOMFDf/lBpspZzpw+z0Mfeh/apCQCuw5fS7hvH5ZrYblCkiT0tOHTH/5jZssOl/lIz2XxiirvNDUkicaxNFnfZdDvkrVcbMdmabXGvj27EMcmn4VDe/agNXzpsROst5o4BQ/fclhfWabq2+y57ghu3ifqdYCvvoBnHGhtEykXnclgZV3yVkzi+hhLaJsByrIISJGCS+ClWIWU4p4q/UHA2kodT4MdpJSn8sRZh6aK6aQhcZolUxg/IJXxckRxmzSNCLoGjMZWgpihu0Hr0ftNZPjOBhm9E0YBaNAqojyV5dCRHQyiAcakWMrFtl0ymfFPriVaDZedcUK318MxBqNDlCQYnbCytsZT5z0OTk1SzObJ5vJYogmDAZOFHH6pQqvdptPrM1HMESYh7WAox/G+Iz1EGA7w/QxxGEGaYivBUT5pbDM5XaLf7eMUbe5/47fSbjU4c+48jfY64SBAa8NgEBE5hno/ZdeRCqVJn6nZMjpR9MPxLbxKpUK32yUOQzK2TZgk9ATKpTwrK6ssr67gug7TkwV2TBeJ04Q41HT7CXkvQ7fXRotGjEHU8MSoiMK6iu2KAMEgpiMasg533nkLv/e+v8BEQsnL4mczrNTqbJsokSsVcL0MXmaa9fUVwjDE83ycTEyrE/LBjz5E1o0o5bMMgpA4jrHU+DER2zZo3cVx8pgkpRvUqa/2yKgW199+B5//04+zb/4+nIlLZOM18gffQRSdoTvos15bpVj2COMOs5UKQbOGpA4mddHpAOsqdgEpy2IQRuggIAX8sk+Sxpg4wRAiNliuj18pM+PspXXuIirjEunhe3m6SUAhO0kyiCCjsV2PKA0Igwgl4xsZu687SPPsEvKMjeomJCoithRSyJEplNl76Ahie4SdFvU4QK92uOhYKCL6seb8yjqDMOT2O17L9/7AP+HkiRP8/u/+Dq2ZGVb98VXyK2t5j/xSOk0p5IYW3NRUlZtvumH4rgU3g8bguD5KbA7tuYbX3XiQTz78JIhianaWrOlxemWRM/U6b3jd68lliqQ5HxOO3wmCbsL27buYmixDGrBcX0IVfFIjDKRIIe/RrwXk5wo4FYd81adj+iCGbN7H7Qkq0HTWWjjTOWrdBk4m5dK5DjYJb71/THlECYNuj0HQpd9QmDQhiSIsFJH5qg/ZUorUmKHiFiFNE0xiyJYsbr3rWnYfmOFk7SlmJqfQSQewabfHt6zqGz0yToZ+FNPtdqnmM6RJgu0INoZeEnNsaZX90zPkMx6+nyEIBsSxxkiE63v01iI2Gi2icIDn2nipg1FgX8UKwJBgiLHExbcVrVaTTN7Dy7pEYUoYxkxUXUpU+aEf+H6WajV+6Vd+mSgyaB1z6+uu5ctPfhGv7DG/p8KevbNUqmVqy+fw3PFjACZNQUGj3abb65ImGq0U+WwWROG4Pp1Wk4N7djAzMc16q4YSjU6TkW/bHb3eIUWUPXRjiIVSw2X/uNjYaLN92x6CMKDdXOdN993F5x96hHKuSJgOWF9u4VguhdwE5y4tsLxSY2l1DW1S+oOIWDmcvbRErdui11ylVCpz1803Eg562Pb4PMKgQb4wQRTXScI+gs/FZz5GvjLJxYVFar0sfnkW3TtHNzZUcz6dbhslPvmsTbc1oG8U+XwBt3GJeKBwTYpVsHCu4r0WSZow6A1Ie32wbTJlF9+x0anQDzq4lo1jCZ0koFop0V320bbQ63exlSKWlAGGpDtAch7GZuh2iRL0VbhNqlNl2meWECNEcUqasxHHwVgO2VIF/BxJlOJbFnGigZAnn3gYWxKMeIRaE+uQ2vlnOPXoF1m+tER3bZnz6zW8zFVMqmPf+TJAayEME0wS4XkO1x8+gqcSpqdn8CQlDhKMUYjjIJYii/Duf/wAb/nWu/mbzz7Jl06d4fCeae5+7bfwZx/6GH/1f///7L15jG3Zdd7323uf8c731lzv1ZuHfq9nkt2kWmTLIjUxlAlBsqXEdAQ5gRUHtqRYsIIgQBwEjmzFESIHjgMLSGAjlmTJ/kOKJUgWQomUyBbZA9ns93p8Y71Xr+aqO5575r13/jjVzRYlBLfkoCEBb6EKVSjce+66u+5Ze+21vvV9/5yPfexZfuyv/gC12uyZ5rzbYu/122zrhKXVeZ78tqeQXY9BPKY/GqLLnM65GuPdCXvxkLt3IlqbNQLHw5USk0ERZ7QbNcK4ZPXUKlqBaYTs7R3M7Eea7JFNJc3wBP3RPpQ5nhJo4ZIQY48CtjEGKSVal8TTKVZrpHD4kR/9fk6dbxBlA7rd8xSFZRKNqIUKXcyeSTz24edYf+cNWg2Ps2dOM9jvc/niOfq7OzzY2WMcZ4hCspPldGsWqSy3hgP2hilpmsK9A8ZxTjSO8AKBFj5Bb5GsvwXHqPEWOsHRHp36PK5yCVUXz3fJGKILj9BbYG94h90twdLSHNaJiaOCoBaweLmL0zrg2U+uIZSmSEYc7CZ4zjytdgPPmb3GOxyOmRZVJt1tNQkUTJKSWxu7uCJmZb7HNAgQpeDq5cfZ3bzNwe6YySTFcaDb8HHcgFGcIF0PKSRaa/K8RB6DLkAqhxu3NxFCMN9u8L2f+k6G/YgvffklHjl/hjNnL3L/7l3+zW//Ll957XVeefUNVODheJZQuGitsUqyuLxMo3uKz798nS9+9av85c98mqWz52f2Y7//JtPJEoejXe7efgs7fYfN+xM+81f/Hr/3G7/CpScvsXn3ReKDbxDpFdTN/4comyB0RjS5z8IK7F0b8s7bOZHOGI58HAlnm6fx1OxcL34Y0LIS43kYBOmgj9Yl0gkoC8jGMUFdU3qKQRQRxQO8dBEpHEypkYEgkyVTaZkXHmk/JilyavM9FLNv7mFTEU/7QIFSDnpqMTIlzRI6F59kZfUEy62Q31lcZjwY4IUhZ68+Q+i7+J0Or/7h7yGnI+5v3OOf/rP/rWJLlJLG2XM0m7PTWnyw3CZYyrLEc91qqEBbBAopNNYPQUgEYLVFWFE9Q1g6dZdPf9uj/Py1N+gPUnRe8kOf/V5+74XrvP76TZLPxEdH9NlsKqckToLjG1InhcAyzsZMiymFTrHCIYmnFNZQFIYsL5nalNpcEyNg/3CXeBKRmw7pg4S7d7ZYWllheXUZjjGGLXFZmJujHrbYc6dgJcZISptSaovRJdZqhHg3eFeIBmsl7V7A3EKHwXCCX2uQJzHNRg2nFpLGOXkye4336Q8/xdrJJeLhFh9+4jFev/4WJ9bmefKJc3z5S69xOIloKcnapWVOLAQEXp04bGO3Drm3uYuQHt2wgVdvMZwe0Gwu4Z48SzQe4jqz1zQDP8BzQpIkwqk3qTJXQR5XXObGSjSCU6cXefXaN9ieVEMNnbkWfsuQ2ykKaARhhQnWDkY7aGEQavagOUlztBZYCxJLpx6QlwlJrpFeiNWCxcU5FhYWyIsp7UaLU0vL1IIWh5Mpu7uH5GWOT8kkKii1ASEJAh+OgWu+dHKOw4MJQVAnkIrCwmOPP87XX3+HZqPBM88+S71eZ+tglwvnTzG/sIQKPYTS3Llxn3t3N3BQkBsef/oS2p7lrddeo91YYftwa2Y/3nz9K4hSkZUjrn1tgw8/fZpWr81wuMt+4pDd73NKw3QwJWwcEsUDsniCJ31Go5JWTbB2dok0zRhvZqRlRhLDypPgHaOpXSQVn7nrOEhhKFPwghpOECJTjSkd8jjBcWqYRCOLgiTJcDwP13FAWIzQCN+lyGJKLI7vMtrfxlGz98xO1E7whd0DDDnt+Tkee+o57tx8h3w6ouUUDDbXOdjyKMucmifwAmjXazhuiMDl5PmLTIb76LzE9ZtVYVEpLj71NJ1ud2Y/Pli0ia4GN/ICpLa4bhNtNViLtoDROEeNHWsryJh/NJa82HX50OOXafqCWhiwuDTH537o07xz4x7aligx+w7eWOpwGG3TWZ5nbm2J2LWUGrIkp7/fxw8DtACtBaKw+MLD92pYJFJIrHQxwiHJNYPhhDwvESpAKkl/OJjZj1qtSxRleF5JWWh0aXCcGsqNUNLBmorMXYiqsSkkGKNRjmLt9AJ5GZOXhrDmIIoYk1V8x9L46GNMWF49t8Kr6ZQLpxc5c/okjz1xmXZbEXiCu+ubLJt5Pv6xxzhxsoXnWNZvPyC9uU1aljz+1FNsbe2TJjl+u0E69hhPCszBAb7jcRyZvZrboMgKpJKUOkFITZKmaFOi9ZQoijDSo3bSsB3f4o1bd7j66FmcRkyhDlHCxfMVAk2r3aZRr+G7LRzfYo/BOfPiW3d59vJFHKVIi5y5dp390ZTSSm7euccTl6/S7bYQQlIL60TKpdNsok01ol4kGUlWUG82mN7fwxQFwqkSAucY63F2bYWG69JqtikLza0H2zz37NPs7/d5+9o3WFlqk8VrDHfvs7S0wONPrLK9t41yJCudVXa393GUw3gYMd+rs7J2iieuPs47X7uOkrMnGdeubbG64KIczYeeXObRJz/L7Zuvcu/Ol3ln/XXOn2qz+2aOUB7qYMLUvokyEsdzGMUF2WDIINGVsIrfQ08OcGPBuL9Nu3FhZj+m4xFGSjQG5UiUdDFWVpPPrsJagbQOOtfoOENJRRgGSKWQFjJtmEYxBQLXFMRYlONxsL1BEM4eP1ZPPMLOoA9OjdUzV/m+H/phDnd3mQ4O2R5MWF/f4MTpy4wGhzg2IUo0yfgc3/Gd30aj06XW+xRJFpFMIv7JP/w5pDWA5XDnAT/yn/7ozH58oME7y3JAIKXBUQJrDUVRYoXA6AIhoBa6GGOOhBcEnhviKAddFPwnn/2uCv2kS0pdInTM1XOr9NOEJJ797ozv92lTZ6k2TzEqOFB9UJYyLiiGJVl/ivR9xoMxeZxQ5AU2zBnc32cSTXBNg8X5RXqNNu5aDSMtbrNOlJWcWp6dXH738ABjHLSRJGVOYiOMUWhqhKFAa0WpHSiLqpbqeYxGY5rtgEuPnGFpcYXSlEghWJybYzgcEo0jsiFko9kzzcvna1w4eYlWt4XjN5DCQZcZjuvwN/+LH2Y6HDGaHHLqzClUo03vxCobQ01jKWUSpSyvrdLvjzCl5OlTTzLc3GZ/PCB2fcRxxBiSOoGrEb5iMo1pNpvkcUqZhSTZiGmUk5Uxb8hf59JHHRonlnl65TN84YV/z4ODXRzjUGYx0nOQhCzMLyNEyTSKWZlfmdmPrcMJ03RKrRbgFA6Pnj7B3mHMYJyxtTfh0UuWPInwpCUvDBaF6zmEoYvuJwhZKeqkWcmFtZPsj0YMoym1Wo17N9+a2Y/7Ww+Yby9gjCGexpw+Mcf8YoP//HOf5R9t3uPESh2RLzIMYH7Fx9oxC50ujXqbojXlmWc/zAt/9BWuXrrAubUVXFegpSHNxnRqs+PNm7U2UX+H3bElqE24vflLrC3X+Z0/2OPBHtzdPeTSqTpJVIkkbG6XuCqh3XXobxcYaQhrTeZXerTrMYUVOKHAkSV+4xgNy7wgqNdIs5QyL9GFxhMB1hp0oBGeQQqBNIKirERVRnt7OK5EZCVFnFD3GijfRacpju9RZhOWex1cd/Za84efepwvXX8TxwpsURLlMbkuKYuS/Z1t+geH9Hf6/NR//d+QpFPytCCKY966c4PClFilqAU12q02z3/qu3hw+x08V/LJz/7HPP6R52b24wNGm1TDNFpr5FGGLaUD1lCWmjDwKYvivWzN6EopQ0hFXuZ4nktRlpQa/DAkTTTWuiTTIULMnkm0T8yBrhO26gStgPXDDabplGatzpVLjzIcTOgPJ+hkgs0UJtNI5dBQAV7g4xiXMs7Yy/cQDYcoSzDSRQvFbjx7zTvTBa7jUVpNqiOaXcVoUCBdhS4qXCvW4noe6gh9AuAoF60FSWyqiUarebB+gNECz3E52Bqjs2MMx6wsc+vVa4wHIy4++hhZNsLz3Yorue4QT1KaNUlGhGsqHuVLp09w5XyDUZYxnRakhcNLL15nYTlkubOGd1tyJ0nAn/042qq1SLMBUvi0mgFYg+fUKEqHRl1SD13K1BIoyyTL6bZL3rrxNUqdUwtq6KxAH5Xc9vYG9OabtLs+1lRwrJnXo1Hj3OoSxkqy0tJt5pxeHjOK7vH2zXUevXiJ3oUV4niK7/s4vk9WaNKsIPBrSAqKXKMLQ2ESAley0GuxdXBAlM0+hFGruZXYSClpt3qkZkK/v8s0Kdjd2eX+xgaKOnPzPTpNKIqSWq9HGNSYTjSNZpPl5QUuP3IaV4IwOb4ruHD5FFv3Zv+cNjt1RuMa+1sHrN+YcqJbsL55SJSmKGnQRcn6ekyz4RIGoFHkRmDHEGWSAEVrwWdlrsthVtJVJWHkMIpi2nMzu0FYC3ECH4shzXJMWVBmEiMEGIOUFoxEuR6lElXjP47JHagHTbSTo8sCg8aTBUWqK1WeosB4s8ePTuiCU0H5hRA0VRtpJcpKLp9cOkYvY/sAACAASURBVOpVuWhZicpIK8jLDG00aVmQJik6L6pmZ1mALpACCrdJoWcvI33AMmgKLJiyqkHmWXrUnXdwXJc0z3EdAUaTphmOcipYk5IgHawVCOGgTUGcFiRpCViEUJTHGI+3dU0Z54yKEUWeM02mROOYumrQXe7SqfcI3H1U4aETTX8wIJsmKEdQEzXcUDCJY1w3RMkQT1qEkcjQod8fz+xHu9MhiTXaasKGw7lLK7z95gMKXdGZKqVQrk+ZJAjHodPpcHjYR0qfLDWs39kGBKdPrrC5fhejJb1OlywqscXs/9qdrX3C7iJlPGJ/c51GS1JahdU1Gt0lhlFEW60QKAdlahS+w+nLZ/G9Om6tw9bmPWqdeS5fPYsjC1y/yYsvvsXS7V0m03dm9qMsxviuy3CSoj2LHxh0qbBlQmoyPE/gBIJc57gCcAwTZ5vC9EFqMpujlI/RisIYbt3Z4PyFUwhdEmeTmf3QRiGFi+NJClLi/g7NmiUrIrb2CkbJhEIvgNYURYE2FQ/JJJpSFCWhH1AUCQqBEhpXatJphCVGzZ7gMZ5OCKSiGbbJdUmcR8RJjJA+gqo/dObsSd6+/hanT58iy2K0iSt8vOPQ67b59Ke/h3Nn5qk7DsgSrXOWTyyy1599Pb56/RaOcshTh/4QRofjasK2JplOS2qOC6VAqZw4U8TxlIW2z7Sw5Lmh16rTadRxjGK5u4Lde0CMQzyNmOazb+7aVpJ0ZZFhdYnRBbk2IBWiyMEB4fjggVQCUVrICqyB3DVYYTFlhtGC1OZo30MIiy1LlD972cQ6AulU4g8WKtiuMWAFxgi0sRQmxXVdpBUIDJ4CoRS1wMOb71UUErZCNuV5jrGWpLCkyeybyAcavOMsI/RDamEDo3OyLAXfP8IvC5AS6XkoY8HmCGlwXJeyLDFaUxiD53k0my2m0ylYiKIBWElxDPkgEViyccp4Z0jxoGCap6wsLXJ6cYHoYJswDKAY8vija6zf2+TW9hZPPfE4bSeg4wRs7e0Shi4oj8xNWTs7R2ch4OTSGe5vbMy+HnnO6KCPIx3ClsJP4MOfeIT9nTEPbhziuLC8Ms+LL77EyTOn6bXbbO1tsnh6np3BPq1FB9eVPLi3zspim3q9Tp6XdBunqYezd62//G//Bc/9R99HvVsnT3Ki2MVxBa5vSQYZQXuBXMfEkwHDgw3azTmiyZRmQ7P34AZf+f2XefOdQ8LeElOpac8tsrC4xNxiAz+afbJxoGNqXg23HqAo2dnZJI5ymq06RoF0JdPR9Kgf4tBpn8Au91k7s8g4mrCxMWT91j5aK8bDA0ZjyWA44pknH0cw+835xnaf//Z//1Wi4QC05nN/7YcZaZcTZ7+NU0s9vvHmPWQ24crZNQSKSRozmUQUhaE04DqwtNBmOo0ZxRE21YSe4OJCl6X52f2YFJZYTxgnMXEag0oZ9MecWrvIt330abSJccIR24f7LAyXgGqiM0kT4qkmTfo0GnPs7O3geqB1jtaGwOtycu3EzH785e/5CW7efAejLY9cFpUOrVA4QmFtiZQGz3VJs6zSpzUCSotU4HoOrgO6NKSlQiUlzfAyniNYXpL05mdHvZgiIc8TlACMRRh71LjMcL2qBh74IclwgDCWMGziu6qiy9Ua4Qc4jsIYjRWSdughHUkj6KGz2YMmAuQRg1RF/2Ax1mKNRR7p8FpTSTuCPZqQrpIxbQ1lUWCOTtXCVGiyLM/JioqAblb7QIO347lYUXF6KOVUfBhCvgeJE6I6hqRJQpokSFURvmhdvWF1xHmhlEJrgzFHoqTGcIwBS3bvH+IjUNYDq/C1RuYaJSBsVRjnpfkOJ1d77O8/4MRKi3bLYa4Wstrqcf/BOtPRCMcPOPfUGitnOwQtgchyAn/2Gt50GlWZYmkpTEGz2cBRNfb3Drn6xGnu3V+nt1Dn/OUTnDq5SDZNWTuzSG+uxfxCDz/wCAOPwHHo9ardPE8Lpn2BEbP7sRFLfvnffQHXlegsx/cCCl2iEThSYYVGUzUCOdLGieMJjqOw1mXUP0D1auym94ijhK3NN+kv9kDW6S3MnmqOowlZUaCPPvgCj16vjefBtMxI4pggqCBwxmiiSUQtDPF8h7ZqYK2PED4b93eJBhVxF1bxYGOXOJkdCobVqLBJJ2zjSPjKWw/QqoY2irfeeYu1pR5v3FrnyulVhNXUwwDfdyl1TpblhJ6PLspKW9WRuK7DNLHs7Q2ot2ZH3/T7I6b9Ka16Gyf0yU3JNDVs743wA0ngNxgcZpTaMEkmuJ6DF3ZY39jHFg6uL9AmIYo0nU6bMOihtabb7bC/NzuNw8ee+R5Wl68CIBC8Sxle3b+ArcgjK1qEqvkmjhglra2oEoSskitjRSVtKCzWSBqN2SG+Vy5fZJrkICs9XGNMVX4tSxAVpYJUDtNgQlmU1MMQoyRGgJIVnURZluRFQZ6l+EKhpKJIUtxjDOkIBNWXOOLyEQhhq0Z7WVZC6qLS3jWmEkovj+g7pJBYIbDGgKlmXtI0xXFdsGVVJpvVj+OgAR7aQ3toD+2h/fmwY7DHPrSH9tAe2kP782IPg/dDe2gP7aH9BbSHwfuhPbSH9tD+AtrD4P3QHtpDe2h/Ae0DRZt8/o++YtM0xaIxRxwP7zZMv4k2qeCA8C5/tQJrcYQkDAIcx8F1XVzXxVqLLjWudBCew5Wzl2fCC549e8k+tjpHSsHmwT6d5knOXX2CpXOX6C0u02y2uPn2OyRJguNIBAXNIEQhEKXm87/1G7jC0GnVGUYx7bqPq3PiJGeiM756/fWZ/MhMYsuyYngWVmCpcOsI9S0onG9e7v0N5vf/Lo4EEN41x3EInfpMfrxwe9fujCTFaEDZX8dNthAmx8UQJQl5odk7GLC+cYA1BVJW/CpKunS6XYqy4LA/ZBxNKdwOF574KJeuPkWj2aPtl3z/xy/M+H9Zs57n4vk+Sgomkwmn1lapeR7b2ztIJUnigsFwQpymnDy5zGNXzmFtRadw653bCL/OqbVV9vaGuNIihObS+ZNsbGzw2194dSY/Fp5/1FJo/EaDQkHoSoRQxFnO2eU5nDBiNCnYOjCYxBLUFOkkoYwzhKdozM/hOgKhLDopKIqCxYUejpMwigy3f/2rM/nxXZ981j766GPs7u6wsb5J4Pk0GgG1ekhmLNM4Zmd7h3PnzzM3v0i3M0+aVaRly8vL7O49IAxDzp49i+s6lWye8piME27dvsM//sc/Oyu+9k+gGirFTMHGv/w7vL0dcWdzl4vPf4rh6IDh3h7xNOHu7dvoUnP69Apnz53l1JVn+NTnfoHhQZ9PffeH+fl/+NOEtYDLlz8ykx+v39+wB5MY67hs7u5iVEmn2UYZWGx3WO42afkBtbK6FyyG/eSAneEOL73+Cv/u938bqTTtdpM33ryO73kMR8MK4TbNuf/F7Zn8+LV/88/tt3/0Y7R7p/m/fvkX2TncxnEkrgOjOKIoCxYWF7l8+mmeffo5rM546+7rjOIhw+3fBjVE4uHIGq/tS0bapdSGwHQYb0741//sl2by44MVIBbifUGmIluq4I4VJLAalNLfnCR0HKSo+CLefZ4xhqIo3rsWWAoKRuMRV2b0I2y6dJa6WMch0tBtz/HI1avkns/m7h7ycMAfvfQSZVmNvOrSMNftUa/VWF6YZ371JB453WaNwZ176KPNRSiFOQbe/E83e7Q+f1xW7FuD85941n8AakhQIIE02sdEB0wONxkOBoxGA2rNLlobRuMJ+6MJSgqEKZDSI88iDocRxmT0h2PyosR4Y5aGJ8izc6hOG3sMUhElK+kwxzmCbQnBZBIhanVybfGOuMEtkOY5d9cf8NTjF0FbJlGCchRxmuJ5Pt1ui2RySKard5gcA8ebTGPC1XmsNUgVEDgeg/GE1Fi2x2NO+C7TcYbQliJJj4jBEjyhCFo+RZHiKo9Wvc3d/jZeGLAzGLPagMOD6cx+1OstsBVmOI4TAs/DO/rO4hhhDFJYAs8hmgwxpkQKD9cNSJIxiwtdlldWaDaa5MXR9OnR5+jP/nExvHtgt4CODgi8JmG9Tn93G69eo9XukuVlxcsjOZoSDkjylGg0AQHrDw4YD/sE/tLMr1wIh0QbPFeycmKVcRoRxyl1r8bu4YR+NObUyhLzXo0omjKeTNg83OXajdeZlhmdhRMU6aAapspKlJI0GnWSJMM9BuuklBIp34VMakqdV8LHxiCPJjs938XzA5Tr0h9usb1zh7GestZTdGoVV01awGlZIyodBpOE6SSj0LNTOX+gwVsphVKKeDLCUr6XRTtOFbiLosBoTRzHCClpt9sVPvMogJe6xFiDNRUo3hjD9uYmhIqvvXmd55+cjRfg25//JN3AZ5omXO2sInAxwlCv+aQ4HA7HNLotFhcWGY/H3L27gdNoMEhiWtLl6jMfpSFzTq0usXrvATVPEQiDdHzsMeTH/nQTler6kb0/87b2m7haeF9At1SDAe/PxI/xir4MqHuGzFp293d4cPcm/eGYg/6QUysJzTCg4cAjF0/SH8VMowylPOJsWMl+lVOiaUSpDdPRkDe/8XUajWWW5tfIi3RmP5RSIKr36fs+rWaTMi/QXsloMsWVEt91yY6EN4wx7Owd0m3WkNIlbPdoqQA/aDCZ7lPzBdm0YHf7AePp7H64rQbWc8inGfnwkIXTKzSET72UCN8jLhI6LZc4y3HaLqBx2yGe6yEaPh9ffpTtaJskiZifawGCmpGETc3CMTaRMKijNSwvn+Du7XvkeUGSpHh+JcDrSEHo+whjKE3GoD+hXu8QT0csL3U5e+YsnU4bISQH/ey9gN1qtyolpD+DVVIgFZmcEJLp3iHe/BxYeHDvLo986EN4rsODe/eo2OAtViqUo5iOM7736Sav3Byyfmef2+sPaDRmFy/Z3utTKLB5Tp7l7E8GNML6kfiIz2Z/k/Hde+jxlJ29PdIsw280EWEP19YQ6h4wZTQ6oNXtMp4MadQbTHZHtOqzK2AJIRFCVpwqukQqiaMUSgqUtSg3wHF9vMBDKLDCkiYJEx0xclzGMeSZJi01sS4qzdE4Jy1cZOPPKSVs6Eo86eNnAVYYvGYdZcHzXIK6R2E1MjcMphMKXdJq1PjGiy9Ta3fZ3d7hox/+EFmeoZOcUc2lHvp0ay7/wz/5+Wpa8yf+u5n8WD35CMqt0ZEabEGWZQT1EOVYrn3jRdbOnCNNYzpzDQoKBDlLi21u3z5E1iURAY88+gjdpsezK2soIVBS4DggnePpNlbHOzgac+C9X/lmOen9PysVw2oD85THnbt3qNfrzC3Mvzc4gLXHCt5CCTYf3OPt117i5rWXuPnGK4ySkisXz/HdH3+SaZrSaHfZ7o/Q2ZS337jF/Z2EWuBQr3m0Ox2MjTk83OPCI09w+fGPsrS8jMHSOIYQsud5WGErnptQ0Ww2WWy1sDpncNjn/l6fsixRyql4lLXmy1+5hu879Oa6fO6zn0L48xgruLrq0Z2vEUUxX31rgwVv9mCVRBF136G0lqDXZvcgRjqCLBrRm6/TnGsxkQnxxgZWSTLPI/PAt5LvPfNdbN5+wKn5cyydW+Kte2+yvrPBoczo+TVEOHuGt7+/R5LEnDt3lk98x/N8+Ut/yCSe4tU8iqIENHO9Os2aS2kk84urlEXFE7Q832R1oU2uc7a2d5BOG2skZalpNessLhyDVOR9Jqyhv3uXIGziOh7TKGNj++ukMuQLX7tOpAVPP/sJhNfErwVM45ilXhuSPju3bvD9j4fk6ZTfu17yG//+JRo1jw89852zvbbwcF1Fu9kkdH3KHUXd95hORuyNBtzf3ubunXVMaYmzFJTCwcdzXeLpmNNnTzNQNbxgjlwP2d66S7c1T6BWjkXV6xiNdCxWaqQCYQoKozGOwFEKKR1cJ0T5HkpJ8swyisf0x0MWF59mcf4iF89e5OvXX+btF36fjVu3WV1c5ad+9G/x9bffnN2PmR/5/4NJKUmShOvXr/GRZz+C8lwcDMLT6KLEMVSTUsKiJBRlgi8cWoklyS2jWxskowm5KOn0eiyeO8+d8QiZG2r57NwmYNGmrCbELAjHY3vvkGa7yc7mNk8//RG6zRbDcYLv+Vy6cIHQ81lZWsaRhizLSZKMoiZxdJUpW1RFjnOMCalvrWm/F6Dfl3m/m12/V3LSpmJZFJp/8A/+R1544QV+8id/gu/+3u/55nWOsRIA0liWV9ZoPPdJzq6t0b/3Jmm8h0vK5auX2No5AOVx68VrXLv+BtEkBlP5kqclugjxPA8hFE997Hme/cT3oYWDKx3KYnZVbsdxqpMVFl0UBK5i72CHojC0GgHewAVr8H2PhOy9PklZlkzGYxY7NTSWQaHQA0Pq5hivyTQtSKaz+9GsNwi9gNFoRJxkLKws4LoeIgwI/AybZchCE8x3ydCUUuAjWJyfZ2FpkeeffRacGm/dvMmHHnmaM6snub2/SZTeIXBmH483pkQpQRRNOHPmHKUuyYtKWs3zA0xpuXTpHKdXT3Pv/gNMYTi9tkacJNTDgJ2tDdIypT+KmF/oUhSVmHVYC1g9sTyzH1io+FwtukgY7G/QbC0QBB5j32M6FuRI5rpNrr/yEtEkZ+H0I/RWHR7pKJpOyp27B1jXR+Sa+wdVNro/yphGs5eRwlpIbg2TSUzmaSQQBj6+2+b6ay+zdXBIagpcFeC4tSqQlilFGjHs71GvKVq9RTITEfbajCcjeu15Flpdimx2P/I0pSofWYqyQEmFNkfrU1blqbIwCOkAAm1KCq0xpaDTWKLuNKi7NRwtaYQdTp2+yNLSCq7nsLl9f2Y/PvCa9/2NDW7dus2VR6/QCDxG0yH7k22WRZuTbhPPgWl/D1Hk+EoQBHUOx2NUzWfv8AA9nqIbLs7BIYeuz+bBPsnIYrLZd05jDNIRCMelPKJyHIxitJGcPHmW82cucHLpJIlbpx0AuiQMQ7Isxa35RAcxK3MhVsdkRYbU4GIpAHUMgqx31+Rb7f3B+v1/s9biOx7r6/f4zd/6TX71X/8q/9Xf/SmeeeaZP7EBHMdcJanVG9SCM6wszNFrNYgnh3TrLtLxQLncur1OWWiwBpMnmFJSCoUrFXma0Gq1OOiHnDp3Gb81R5YX2DxDHuMI4DgOWh81sivNPNbv71ELqyamlJLA9zG2ov58VxNSCMk0ThknilYto+nVKJYuMhjvIouUpB+zvzs7i54nFePBCCksnnLIyillaVCFw8rKMraICHHJ1Ri3VkMrgRgntOsdwnqN7f0ddvbHCOUQurDSXaLZ6vD2/YRb23dm9mNubo6yLBmNRggB8/PzGFPgui66KDi5dpLFhQVWlpawFl5/83XqtUt4rkOZp0jps7m5RZRkzM1fwJh3WT1Nxd8zqx3Vdq0pydKYyWAPUxYclikbW/uY1gLdXoPlaY/CSra31pkYwUpdgCdZHxqE7xPiszvNeHAwBePR7yccjGbfVMeTIV6tQZJmjKcxQeAgEKRpxsHBPtoI/CDEakno+hWX+cGAOBmjbdVUzwqLqAcEYZt2e54waDHXWaNVn/2E6Cqnql5aAIkxFmMskqqHJwRHgbviGC9NTpYJslRRlj5QxR1TVDoE9XaP5twC2pr3SoKz2AcavL/4xS/ypS99iWww4P79++Qb98inEXuHW+y/eI3t1+/jhZbu6iLGWiZWUfz43ySqKxZ6XUb9MVPf0Gh2qVlL+s5bnD8c8hMf+xgv3Lo5sx9lUXLp0hkWV1fY2t7j+vXXcdyQRqPDc89d4MaNu5xcnOfkXIgRFs9zWFueo0imWClwFxaR1iAx5I4lj2IGG5tMM3OUofwHmqi6+e82bl3pcNg/5IUXXuC//PG/zWAw5PnnP8HnPvfXKIqC+rfUL98N9LOadiyBsOjSMs0MV65cZKHt823f8Sk+/8VXeeXrr7KzvUVRJHQ6TaIxTKY5lAabSwaDHOU6nD13iYO9fdrzW9RbPRxHERyDRi/wffKiqiUiYGW+x1zD48HekJob0ms0mcYx9/cOCX0faw3DyRQlFQLJH3zlFc6urbHQGbI91ty8eYNkOuLxq5c4e3520v9xmlBf6CKtJYsTFoIO06SkH8XoqYsXCA6mCc5+RJYdYlshQaPBYm0Jm1kGWQm4JGlCu94gynKElVw9+TH2DmYPVmVZUq/XOXfuHGEY0uvNMRodcnBwwJOPXuX0yUWsTdFZzONXLrC42OTFr36V5ZUVaDSJM4fB4JC3b9znzJmPvEfJLBDHKu+V+Zhh/4DQrxENdxkPD4lGIxwF10Y5T59tI70QLTzipMRzHV5/6RXMpTl2NmC526NRaxOlA37lxQlxXtGp3nhnn5/9xa/w9356Nj8830EIS6NZR1sYDQaUacY3vvEKWEUzCBiNIxyvUhNyPIfu0hIt3eBgb4f97V1Gh/t4zRpp0WZl+SLLc0u4ssbB3vbM6+EpB2kFVkORa8qi6sGpI0EIayS6zJlOx0TRmFanyyc+8QPsD0ZI4fKNV1/nq3/0RYTOyRJNoSAtLTdv3+L2+t2Z/fhAg3enFVbkK6Zkfn4OPIHOuwz6B0wfPOCyLaHQlPv7WCFIHJ9uUuBqi9oZ4VmN47g44xEHN+5wttQsGkNq+6hkf2Y/irJgMBiQ5DnKcRj0DxgN+ugi5VStxts33mF5rkOQ7mB7p5BS8drLL5HHY8QRQ5gpq8xwQk633iKIU7xOm8wev2H5JwOtRRuN73k4yuV3f+t3+Ve/9Et84QtfYDAY8sgjl/nrf/1z/PiP/y3+13/6v1Cr1Sj0t5w8jpHxSmtQGMqiJM9Lzl+8yFKvSa/X5Z1b95hGEXmW4zgwmYwBS7dVwfnAkGpBnsVIx2NxoYPvOyhpcKzgOIxhjutirMGYqpNfojh/9hxBsIfOwXddRuM+o+kUISVJWol7CAAhyIoSz/MYRSWu47B64gRl3gavhXcMlkXX90iyFBeFtYo8yvFdy2OXT3DOybmVRRhdIFd72OkUmRSEQZ1GrY02lvIIDVUWJY7rUVcucRxjjWVxefZyhTGGNE1JkoSy1O819z3fJXAdQt8jDHwcJXEUKGlYXV0iDD3qtYCdw36FzspLSm2IplPCMKwIlIrZT4j9/Q2MkRQCJsN9/KCGIxyi6JAnHjuPG4YYayqVmHrB4XDM8so8SWro1hVprinTAe3A4dZOCliMNghrGA5mV3wqypxWo4VyPaI4JstS7mzcY3tni/7+NkJUXN51p1vJBhpLmcc4SuM6Fs8x6ELjioL9nR3me3PMzZ9gd2uPsDZ749RzXOIoou69SyR1hITTFhA0GnXyMmH93i2SwZB+f8DK2Sd4+ZVvsLf3gNWFRTbuvc00GnLm/AW0ElhTMhyPieLZ+d4/0OD9xqtfZnj4gDIz/P7v/Q73N+9T5prluQW+Y2mR5PA2tcJiCg98j4WlFYL9PerlUVfXkWTTA5x4zOphjEpi7o8G3PAVjaXZGzBFUbC7s4MX+Jw+fRppDZ12iySJ2d7Z4sz5cyytLDHdeZXe6gV8N+TlO7c53H6AUA5GCExhkQYiUXB65SRqOODco49T/BmW9P11bWsr/KynPHZ39nj5xVf4uz/502xubr0HQtnZ2eEXfuEX+Pjz384P/uAPHl3jm7Xud7OrWa3muuSpRaFwUcz1unRrijJPqAUSU6SUeU69FlIcNQxDVb2mlB7xKEGYgjQec/fuLTorpwiVQBQl2NmPga7ronWJtZY4Trm1/oBGrcajV6+yt71HLfAIA8v24QFpoSlKjZKyohQ2Bivg0qXLTOKMwhQsrawwGAy4efsu0jmc2Q+lDSazCNdBSZfDScRfOt3jk4tN0sEm605GPfQ4iCxBs0FejvEdH2kVpTHVEVoqrBG8+NWXWVk7wdLSInme0/BmP4mUZUmeZ+R5RpalhGHIYFChPGq1EKUkvW4HSos1miJLOXPqBJMoIpoMUY6iXq8ThjXyLGc8GtFqNtG6ZDicnc97f+seSycvkGcJSVoFF6MEjWaHlaUuXrNNlFjqo5JkMsD363RqCQZFf5iwcHqe0d6Aqyst8kKDqDZnY79JrTqLZWmKlEfwvLJg48E6uzsPUI5lb/fBe/qupy4+SrM9T1kYXGXY33vA4e4m44MRQjpY0US7PkZDrd6i2zPoY6CirLVcv3ad7mqOkIosy6nAzwalJMqRFPmUIjMMtve4fWeLhY0Jf/jCF3CcgkBaiiInyzM2HtxncXkJBazfv1cBL2a0DzR4n1kLaMtHEAV0ax5/58f+NvNBg/LggJv/8l8wkQ7al6w++RjN5UViBPm9G8xNU0gSaodDSp2Rxwk3iwl1LNo43Di1yseffXJmP/rjAX/4b3+Ns+fP80qrQ6MzT6PeYL7b5vFnniGohcz1uqw98SMoaRHWMI2nhM0OeVawMDd/NJhyCGnGfv+Av/FjP8b9O+vs3793rDV5f8PS8zziOObnfvbn+J/+0f/8vke9W88G13UYDke4rssffOmLNBqNSiVG/vFrHsdcJfBdgykKfDtmONxGKsHVJ5/m1//v38L1Xc6eO0WWpUzjhHY7II7jSmsUged7uK5Lb2GJ9Vs3OHfxCu1GA0uB689+PFdK8WBzjzTNCMOQz3z6u0myjBffuElYJtRCSafd4uqVy9y6u8nhJMbznPfebzRN2BsM6XQ7mMSQJTlKKZYW55jGxyhX5AW1hS6lqcBuz199llUn4HqmuTOWrPYMAy/ixqtfo9QlteV5HAXYghNLC2ibI5XHK6/skBaa27fWufbaGzQaIasnVmf2Q5iCaDTizs13WOjOoYyk25inKApazZCl1VWanTlCk7K7t880yXnqyjLSnuLrr9xk/f4ueZYyODjg7bffwDqK0+fOsrW3x2Q8e/D2gxqeUvQHu2AMzfY8AsH25h2+9uYWS60+7/RDFmtDPMdld3eHi4uS7vJJXn/zJlE0ICvGdkQZWgAAIABJREFU3Jp0qs1cVOUPrMaYYwh2S8VoOCYvSwbDAS+//Ed0202MKbh18y3CwKHe7OIqjyzOGI8GvPbSbxKNDjBFysXzZ5nGOULGUJtHUgl++0GDRm92WbhBmTDqH/L21pDd4RAlCsKwwYVHLvDlF/6A8WTAdzz3IbJS8NXXtmisPsJv/9avYLMRWMGwNceNW2/SaDfodJaYDlP62wOELegt/jmFCr5+7RWaSZenrzzJE5cu050m7F17m/LgkNHuDip0aSzM0eh1iZMMm5XoNMbGKdN4xLS/z1RApBTtD1+h7TrcvbtFuDRPlMx+c968eZM8z2m1mpy7dJHrb99i4+5dVubnSMop5y6cRWbL2HiAqxSNVoP1u3fBQpqkTKKIsiwZDPpM4oiFhQXefucGprRE6ezHQPjjiJPXXnuNX/vVX+P/+MX/830NSKiCd/VdFCVXrlzmZ37mZ6jX6xXJvBDY92FM/rQm6P+XuY46arQW+I6h1ayzcuoUnd4cvh9SGovjCKZTDVQDClKqoyErAbbE83wazSa5UJgiA1tUg6LHQE4eHA4oteHihUv84A98lieeuMr6xj32tvbI791he7TJnbv3sE5QTX7mBVrro1quJCsylOtUpZPxmCRJmE5jsjQ/FgTH833S/hjrCeYXlnjy1IcYDwYMRxOyaMxuHuGvFITdFlmeQ6HxPB9rLXmek5cpQuk/1nuo1WpMo5i7x6hpJkefadd1aTQbRNFt9vb3CcMQpTyWlk+CUBSjKXEck0xjXr/+Ft3WMtE04dTaGq+/cQ3Hkfi+R3t+HtfzODw8ZGFhcWY/mp1F8jwjmU7QRuM5dZTjoJTk7KklRuOEQsWMopL1+1u4nqJeb1EPajSbdfYOh2zv7HPuqQ/x6e/7KF958U2GgynCB3EMiJ6xklazR1FmbG9tUhYlt2/fYWGuR7szj+saGu0OaTpF2JiDrVugc8q8En6Js4Q4TTBCIMiJpwl5miOlJM+ymf0oCk1pUrQGq0tcr0avt0QaG7JY4LfqvPbWfZJMkhUBK0sN4lgTqJBGo0a7M8+lS1epNUK0FaRJeiQsE2PM7PfuB6thWeZ8/1/6PhYbC3S9gM2vvIAZRYRG0Znr4My36SwuEU1ijAaVZWymE0ZxgpPGEEXIU2ssXHmEhdUF9u+tU7ZayMBnNJ4d6pOmGUVRMB4N6XU7LM732Iwn7G7f59obr3Kw8xgLn/kebmxtEvohK2snOHvuHHmaURZ5hTWWDqsnVxlHESdPnkTrkjvr93n77bePtSbvL5l8/vOf55f+1S8zGo5RqupiH+G0jh5tee65j/H3//u/z7d//Dn0UWPvXTZ8y5+EHc5i1hiwJVIYJAXNdpt6Zw4VNvD8AE8IPE8STdKjI6tGClW9lhA4TkEYVtQFnW4P33Uo84x6s4Y2s29meVbwn/3Y3+Cv/JUf5MTJVUajIYU1eNbltdevoUqXMAi4dnODg2FEqfVRiUJWogyuQgiIoojRaESaphRFQZ7nJOnsx9GgUcdEEUoK2kGboZKkQcBS0GH7wS7TRLDg18jyvBqtnkTIxQodlCQJ0rEUWX6EPBBH4hGGer2B489+cwZBgOd5aK3Z29vFDzwee+zK/8vemwfblV3nfb995nPu+O6bR0wPaKDR3WDPI2cyTXEWRVmyotiWZalspRLJtqr8R5LKH6kopXJZTqw4kh2VGNomJSWSSXGQODWHnkg0utmYujE0HvDm9+57d57OuPfOHxccXYnvK7raUhW+KhSqgIeLdc89d5211/rW99HpdrGcAMcr0On1adQbJHFEEkZ8d+UGTz99jCeeuptzFy7ieS6+71Eul5icmhqelrSmWBzd4cgPSnSa2yAEQb6IadqYlsP05DhffG2VJJOEqsPk+BKHjs0yaIdge3zn/BWOHp6jtl9lbsZnZmqK3/mf/hbPPPcyf/Jnz/LchS6mOfp9mmaSKI5RKiOfzxOGA9IkIYkjJicncWyB5fi0Wvu4pqC+v4HnWPi+hyal1+8RRTFxphgvztFpN+n2WliWRxqObl+YZopMDf0nAy/ggfvPkKUG1b0qTzz+XsJQoi2bfgKTdpEwalAsligEBseXl7GdgKnpebq9FtFgeF+mSUYUJngH2Ed4U5P3u9USj47Psr1yk9VbtyjEKZ6GLAspTc6QJAm9KCFuNejXm+xIgz8tGzx35QaPaIP//vHHiGxoN3ZZ+fJZuo7FBQZkOe9AN4FlmSwvL/PKuZf4zne+zaHlk3TaLZKwx/j4OK+ePcdP/dT7MW2T8ckyY5UyuSCHZzuYpiC77eIhNRRKJY4ePcrhw4e4cf3KgW6C77FJhBAopfiN3/gNfv3Xf5297Sr/6B/9Y5577nlq+/XhEZNhQv7KV76CQqIMhfihXolS6gcV94/pofzHYAoDU2lsFBowS+PoLKbf2efosSUatRadXhdtgmHfdu4zTBTD7dfxyUlyuSKlsQkeesfbKRSK+IEJKmbIhx0NX/7yl+kPuly6dJnPfOZPmSiaPHTmKG2rjTc/y3iuTKFVZWO3jiFMqo0m0jQQAlzboLq7z7PPvcDi4hytVos4TojCiE67TXoACme31aZQLjPhlXjXW97KoLaHbWm21q5y/fIlJiYn0VsWvmfR2mxQqpQIBzGZlLh+jn4SUhorkSiJUMP2gGUYSCnxrNEpadPT04RhSKVSwXVt5uamqIxXMAwD1x0jShwwFL0wwjIF6zdv8uQ7f4pUBly6usKt1TeIkz4Tk2U63TalZJIkSZicnMQ+AN/cNEwGrRZ+roiWCjSYAm5evYTjFdlevcVMxWNucY5mdY98WfPG3hbG9CxvrOxQmZ6j1+/z1edfoVj0ePzuu/kv3vVP+MIzL/GJPzo3chyW42A5DoMwYXV9lcATjJcmkFlC2GsiTYdUtXByUOs2MOgTRiGOJShOTpJmw5V9naUIM6NW32Rt8xoTk0uoaPTKO8kMJiaWOVaeYWZmlkh5rK5vc/TUUcbH59DSI83g3KXnaVQ36HZ2eOixoxh2lbBbIxkYCDNDyoxz3z6HZVocOXyUXFBkb3901submrxLHcXmS+fo1Wp4SiK0RZqlyCzBxUCGw8q2vr1FEsd0JubIL81Q3GuQ1OvsJSHq1h5dldAyDNYNSbMUMFfI4XmjD4KkVPRaTWSWUSyW2NvdJk5S8oUc3W6fTCpa7QFPPXE/tm0gMDl1+hRIRb83PDqmaQLC5MTJU8PqWSnuOXkczxo9af54qyO9zfGcnJ7kd//lv+DZbz3Lp/7dp/niF/7y+8PKc+fO8fiTjxGlEd+b9fx/8cJHhWkKbMtEWRaZ4yNyFRId40jJoUOLCASWa1NrtoYPLSkxbAfEsN/suC6O67J0aImJSoUgCIZH0TTFt0e/xfb3qvzxH3+KLOpx9NAcH3rvoygZ8ZdffYE3rt/kPe/9IKVSjqnXXiVLG4wXc0gtGEQROd9ne7/JjVs3CaM+SRyTpbcNgqUcegaOCFvB2+59hOXFY4wXJ3ju6ndAp6zeXGVqchYlE/r1CL9YIC5JYiG5O6hQihVjYZO0G6IFEA+Pw4Zpo6VE6iGLaFScOnWKWr3OWLlMEARImdHpdCgUC7Q7fZJUYVgOcwsL9Gs7TIxV6PcTap19DMvEti3K5RKuk94uECRxnJDL5Q70cI/jAaZtoWRKlmbYlkOaSUpTS0TRt5CmS8412Vxbo1LKYQqTeivC6q1zYmaRsxfXOXKown6twdXVfaL0IsXaBh96x8M8+sDJkeNIpaTX71Or77O1s02WhaRGhufYTIyXiXoh/U4Hv+CSJV08x6SXRkipSMTwez81OYMyDJSU9Po9ut02QaEPB+BXm5aHJiCOBLad5+r1HXLlKcpTZXoDTZZE7GyvUm/eIhzs0O/3EFaMG2QksUOcSlSWYhsmMpPILKO2X6PVbdNNRz+pvqnJe2F2lsHuPn6myZQkk8NjuKk1vW6PXrtL0u+jwpREQDgzRlAoUHEDJkUDPVEm2uwQJYJzbh/z0AJT83MUcj72AZJElGga9SpSSeIkppgLiPsdhPQIB320ENT3t0iT06TJ0HV6Zn6KKAy5cv0Ke3s1TMPA9wOK5TEGgwFROODek0cpFUanHP0wI+SHB5dSS8qVMh/72Y/xxFNPEP/S3+PcuZdpt7r83u//PqdOnyRXDH4CcaEfhZYS2zIxPBfbnKCnU1TaRpgZlUqJJI4RpoFp2Tj2sOcnhIkwhg3tLFMUSiXGJ8fxXRtTgIHGMgQyGf1L8W8+8YfcdWyae+46w+L8DK3GLqYlKRQU+XIJBESpYmp6DiEsco0WzUEEQmAawwdJGEXsVPewbjNu9G3JgIM8zO45doq33fcw+/sdbtyqc/3WJjKN6XX6fPyD7+QbzzxDP5ZYAkzXJhQZxSTm+quvUOjc4tVXXiNyfAamjTe/hGX7aMMCqUGM3uMtlEq0Oh28ICBXHJpux50uTibR6YA0jnGFzd2nH+bi2W+yt79Haa5JrA0M02ZqYpooikjCJhoFWpKlMZZpHmgGEIc9NJDG8XCJSguUlhTKE0xUymSmjxG4LEzZWKbL+Qu3kD1JpiVr6R6ma7FTbZOGHT79/3yJh88c54nH7scr3GBq8cTIcUgtsV2HVGY0Gg2qOxskUcj83Byz0xPsqx36A0m/NxxQptrAMgVoQRLHGIbDWHmCVENHgmcPzc+TLDpQkaHMgE9+8jO85f77efHc6xw58wThIKG/3URhsrW9Tru1RdbvMOj1QAsylaPdUCjpkyiQyiDOMpaOHEEpRRjHdLsdhDm6fMKbmrzHtUFLaEIlUVGC7lTpRT3Cdhd9e6gkAGE41A3JVZXx0Q9/lLXXVpgNI/5o5TKJCcWTc0zf+zBFLAqpID85diDjziTNsN0APzd0++71uriGRoVtjp86Q6c/4At/8SXavT5pkpDzHLSSKDlUQjx+fHjDXbnyOv/XJz5Bt9v9XuBMT0zxoQ9/eKQ4hlKw+gdd7R9SE5RKodKESqXCn3/+s7iOy+7uLkIYFEsFMil/hMv948lJHECq3RKaVCss28QWBolfJEWh6DM/N4GUCTvVXYZGqyam4ZBJgWkYGAgOHz7Gg088xvT8NDnHGm6stppMTEximKMfz3/zVz5Io7ZDt13j0ivXeffHDmHnX2Oju0+4PYvc3aPablHCZbk0zWuOS21lFakUhtYYwsAQgl63j3V7cGkaBkIcsI3UlfzxJ/+EY0eOkPcydKtOv93BIKPe3CdKIqYLPr/9sb9Bd3eLzt6Ab65f5bq1z42beyhiskaLqN1nfGeLfjwgC1ymZg8TTY1+QrRdj/LYONeu32BufpF2q8OtW6uMjZUZLxZ4/htfxHUC9o7fzc0rG0Shw/mXX6FQmuD0fW9hs7pGEmVMT00zyAzisIfQCp1JlDH6Q6TTqYNUt9lOLsKyEErg5cY4deY+7heK1WuX2dttkvXb7O3s4OemMUwL09b84pP38tz5q7zy3V1UkvDst77L+Zcv8pGPvY/Tp+ss3/++keLIBiFyLGVhYYl777mfrZuv0Nzb4Ua7TtxZwDTA8mCQSFwnwJQmoUjJsgTLtgmjhBsrGxxZXkZIzbHjZygUp5AqpheOPjPbq7ZZPnGIazcvMog1xx95B4m2scwcq9cu0Kxt4pkm/+fv/AGpjLjn4TMs3rWMKcvIOCVLhi2aaBASRhFj5TH6vQGWE5ClB9iLGPkn/xPg+oULdHIWHQ1FbRLs75KoGEsb5H2POEkIZYYyDdppTBxLqjtVNne3SbKISmWe2eVpClPjlLSBZYF2DUxDUNsfff3ZNE38QgnDckjSlCzqI4RCy6Fmiunn2NzaoNftE4YhsWVy+eIF5ufn6fV7/PzP/RymafLiC8+zs71Ju9UiyBcoT86hxOiX9Pvp5Ed61D9gmWg9dORWShFGIeMT40MNcyl/WFzwP4T+0ZbMfwxSpqRxRBonWMKgtreDyiIqeZOxYpFCoUOxmMc0DKShMS0D9HBgaQiLqZlZfM9HZpJep01tr8HKyk0WlxaZmhqdf7+/t02sM77y4nm+++o17npkkWa3z+5WxtruNrOlMobS2HttLCGZLZVI5HClOExSDNMYPhCFoN8PQUMpyBOrhCAY3aXcdFySqAdWxs988Gk+8clPg7DIFcd4/hvPEoUhScnmz7/2Tc5++yVqaca75g5xv1PEslP23IjJsTnecGoYdoFOQyJjzQQhW+3myHHEUQoYNBpttDLoNDtsb2zRqjWxlhdwrOF9PzE+ydMf+ACHF6b50tc+y9LcHIHrsLA0R3W3RrPToFiZQwuDQqE4nLUcpK1mmbelmiVaKTzHJukPhk7pfgVkF5Wl7O61kHGPXqy578wiq6u7eIbipUvXuHxtB3SGH1g0GxmWY/Hiiy9jGAYfGDGOY4uL1KOYQqHM4aVjgIVjuTR2d7jaGmA4AmVJHN9E9SW+6TLcoTExbJtizkeLHKWxMipSLB5axsvlaLY38b3R5QJ2t3fRKuLYsUWKE7PkXBPteDieT6tWxdIZb7x+g6nKDM1ug2a9xWyiQBpkseTmjRWkktiWTbPRxnJ8Ug3HT5wgiv6Krsd3m22u9hJe3muwYLt8wPXJeS6ZCV6QJ9N90jRl4FpEymVzp8E3vv4tDEtgTo1z6MgR/Nvr1qbS2LbN2MwUO6ubcACyvxACTAfTUVhCkMYD9O2jdRxFBJ5P2O3SrNWGR/EsoVmvM14Z4+bKTcrlMfr9Hkkckfc9TIr0owTbdgkPMPgYBVprjNuJPcuy78f/40YMPwn6vTZhf0Cz0aBQyLOxdpOxsRJ5NweGw1i5zMxEhWIpT7c3IJUJMhs+cEzbZnp6lqKXQ2TDL069WqPX6vPtjXOcOXM3vGO0OMbnl/j0n3yBL3zjIrV6k7/7K3s0m5qpok8+P06922K6WKRaKYGXw7JtuoPoNgvhNuUrzRDCJElTgsxmMl+ilvSYmpod+XoUczn6jRbra7f43X/9b3E9G204SK05fOgQF8+/itQKERSJzYAxwyAW0Ot28D0TTznY2Dzw6GN84zvnmT1yhCiO6eeHfc5RIaVmZ6fK3t4+lumyvVOl1eoABvu1Ovl8gc3tbY6fOM3RY4fRsskb6wtYbkqadehEEamUxGmG5/nYbkCxWMY0TWx79BORIUzUbaqqUopBuzlsN4QRWbOG8Cws1+b6jS1MUzM1nse1NKUAqrt1WrHBYCAxMsFWK6WfaEqFjE6rzrdffGH0z6VY5I2d6wwGMYZlIAybyclZ+u0ucZIShTGJihizcniuy6AbE0YhmZIEhqBcqFAszdDp9ihPzlIo5vFzBW6t9/Dd0amTURjy8tnnSVTG/Q89wkMPvIvUgCjq0mvuE3iClWtXOXHXSbb2tumGTXQMuzt77O9X6fbaBLkcQT7P8ukFxscnGBsrMzs9Sbs9+gngTU3e7ULEqZ7NsclFSCNqdEFqgsikmURkpsXkmYdpHJnm1q03aNza4oiV8Lan7iewTALHG2qC2xZTs7O0Wi1eP/8ahULhYMdi0yIzHSxHYFo2KktJEwtlpmyt3qDVbKKU4uw3n8GyTVzPwTAFV69cxLQcPv4zH6dYLlPd2aK6uY5hGExMTWMB2QGT90F6sT8Q0v8xmdgfGlZ+T/P7IP3w/+V//qfMTAwZCHNzM3T6fdZXN8nCLh9++lHyvsPs9DQTY2MkcUZip8Rpim05eL7P9uYaN65e5tq1K/zeH/wrrl19jTgNGYQZq2tbI8cxe/gevvqt/xEDTSkf0O5Ilucr3HtyibOvXOdzzz+HUpK58jzZsSKXV18jDGOiOEYjCAIX0xyeCB686wFmp2cREkpZ+H3Bq1HQ6zQo5QvYlsH13RpeoYIQJotLczz8yBnuu+8E1Z0brLyxyvzsEpiaS3IXKTJc26W13oBGj2xrE9/1OXZ6mbXrN9kLG1jB6G2Tv/yLrw6HXcJkv9mmLSWl+Tlm5+ZJZcpmN6ZvBXz2Gy/w3KuvM1HJMVEpUKt1iTdbDDLJ5MQM41NTKExs27m9hQiDwQGShGUjkxjXdYdMKy1IkwTfNXn7z/59Vi9+m4nlJ/jWuU0ePzNPt92gUrK4fL5OrRGx1TNptyOUkpjCZKqsKfo2nVZKuTD6stDG1i750hhKpVS3N0i0ZmpijrtyZWrtfaJejzjs4NgJSRRTGM9zdGaZ1bUNNIJEClzXZ2K8TDMc0Go1SDOBKTzq9fbIcbiOIByktBotvvyZz/ONv/gKiYRCucIDDz1My5Rs76xy5MgS084s+y9vcOP8VRZnDrHwlifIjQ8foG4QgDMc9uc8h7JnIIy/omYMN7wAsxMynmQUpYVyi4CBFAb1JKKmE16srrPRXMcaK3HmzAnKBRfXEtjCGgoQCUEhnycMQ/b29mi321QqlQMlb6EljmmgMZAILNcbGj4IQRyFaJWBHorNJHGKlMMJsG3bGIYiCPJUJueoN9oYpo3j2AT5ImEif6Iq+PtJeYTX0N+TL/vee7rdXhn+5W0634gIPI9LFy5iWxZrN1fQtkUchxQ8a+gqY5uYwkCmGentX0PJkqEofRT2yHsOlUKeWnWLTnufLO2jZUI+N3qyUtrCMmwC18XzPUquy8L8BItLR1jZaCL36ihgdX+btfou3STCdW2kyoiToa6J53mMjY1x14mTCCCKQnzT/z6TZxS8sb5C3M5QaYoQGcfvvo9KeZzq3jpf/dqXqe7uYOgB3XrCqZP34ucCwlqMlQ6XdHBA6gzISBPJ+YuvMOhHWOMGwhz9hOgVihxaPo7ruqRKsigzSsUSxVIRDBOpwHFcGvU2MtEU8zn6YRXTy+FYkvnpylALyLDJshQph1rfSg9lBUb+XKTCMEzSNB4uRSmJVppCqYDTWiHaOEdcuYtSXlDrpARuga+freLlK+SB6s09DAEZipmyTbFg0u/HvPUtRWxz9BRkOS6V0hi9foOd6ib3nDmNrU12dnaYyFv0Wx2yOIdOm3SMLmGaUh6vcO/YOGsbWywsHqNVa/HGjSrjc4fJMuj1YjzfY9AbXT7hjZU17nvwEfZ3d+h1m0T9PkkiqYyPoZKQfq+LHoQYtsmgMSCXK3D3mXsoVybximP0wojBICTMoDgWoJWFwEViIEafV77JlffcEc73rmL2+9gyo9gXaCGIhaBvaYyiR2xE3L2wTKVYQtsay1S4lgVa4Hku4+MTeL7PjZsrZFlGuVym2+3iHaBnpTUIw0SIYRVrWu5wIqw1g14bqYZ64nC7JaGHWuTo2zZtaDBNwijG84da1oEfkCnJT9jBGP6f/KCfreFHaG7fH3AK8YPff6zM1t+b/I4IxzHp99rYlkUUdlGGges5uIZLv9djcqyIgSBLU7rtLolUSClQeijH2m41aMUJOk34yhc/z9b2Lv2BJI1TyoW7Ro6jFxlMT86TZCGtdouH7jnO8dOnObx0GHvsMM985UvcunWLaqeB1hrPcRgrFUizjCSVOLbDocUllg4tUSyWUFmG73mkWYrtjN4miOWARq2FV3ARcijBGuTz3Hh5lebGNrbnMDY3gecZtFp1uspBxSmp0mAbGOMujueCVNiGiTIU+XwOPI1hjP5Qfcvjj2NZQxZNt91isVAYUjMdm8xwSDJJIV/AcX1UNpTJFfawweF7Lp5vEngBKEUcDjAMA8dxiKI++QM4tkiVYrsumAIjTdBhSJokaJEnDPsUSiXWr36HJ556G3EWs762ztTcNNdvrFPrBkg1VNsMPJuCbxAPMsqeYGIsR6Mz+vJULpcnwqDT67DfqHLsxCE6tR4ZGX09wHQ8VJQn6SuE7xDFCWubGyBsKhOTKDS9fovq7hbH7n6QQ0vLdLopXi5lb+/6yHFMTs/QatUQtoXt+WSJxLIFvV6P1y5fRiiNKQyqe3s0Gy3mlo5QnJjC8ANSDYMwwjBMpFQ06k2kkniOTdG3DySg9qYm79kTs8yemMVMM2Ilh1uUlkmmEvqdLloqCn6ZVtwj1n0KTh7P9BBK4Pg207PT7O3tsbe/RxSHlMpFPM8nSVIsa/S3YtjDvqPARJgWUhgYlo19uwKP+l2EjHGcH7ymEALf97E8j0wlZFmfcjmHXfRoNpu02i3cnD5YRXN72834sX+jfyhBw2isrh+3QDtIO2bj5k1MUxInIb7voVJFL2xC7HHz5iqlUpnd/Sbbu9tgKKJ+iGkGyDgDT5KGw5lAEsecff4svu9h2w5Jv0e3tjtyHL/1T/9XfuG/fT8rN2POvdZhcPQ4JW8b8/qrvPt9v8Q73v1Brr5+gRef+QvQiq29Oq9cvDTklZs2M9OTvO/p9zIxPkGz3SPLUtI0IU0zNjY3Ro7DKbsYIsYvj6GU4rWXL7JevknUa1GYH8MwBFJFmJMeHWOAqROcojf8LE2TwDFJVYYhTLQQGMJAGxosQaZGZxOYGASuz6A/YGZiilI+uF0BJyjTYb9Wp7qxjlKKfLGI7TgoOdw+LBTy1KvbxG7MxNgYU1NTRHFImqbUajU879DIcViWfXtLVA+NsdMB+XKJXC5H8/qrbL9xiZuXrvPlF66RZhbaEphjR3FyBXZ2ruN7Dlpl5FzBTEHRaQvm532eu7BHpz/69djZ26PabKFIOX3qAb5z7i+YnpzixH3HufDaZby8QLoO0wun2KquMx0E7FzbxnN8hDSZn19gcWGGre0tHMelur5JUBhjq7pO4I+eP8JBgmHYuEEBw3bIUoijGGFpfMfFMkyCQhk3X+DRu+/Dy5VIhUUsNbY2mJmZRwgxNIS27NsFoiLstem2WqN/LiP/5H8CuDmfMAzRpkEu8ImTFCkz+t0QYVpYtoGyMnzDxnYdXHcoEVosF5mfneXatatIqXA9D9/3cByLJI0xbAdxAH1iS9xub2iNEgptgjZNUAZmLsC3DchiuG0GLKXE8zyKxSKG7bC6uUmn3WZyfByL2zd2HGE6LuIAgyDDq29YAAAgAElEQVT4D51y4HsuaPpH/vyHbdD+fz0uOVjiBvjZn/8Fzr70IvX6PguLi0xUxtncWMM2DTqhpB+D4RV5+PG30ex02KlWOXrkFK1mjyxNeec7nmBlZYW1tXUMoUmTmFwuz+LiAtNzCyPHsXzXCQ4fK1Oa6LFmnMJubrGYz2j2I1785jd56O1v4/CRZeRT76LR3Ees3GJjc5Nmu0MchfS7dQwd45iSQiFPFA4wDNje3OKls2dHvyCuQW66QNbtYUhopym9ZhO36GIGLoZp4LkOGUOFvyyTWDmHLJPD+9g1cQwbwzJJZHZ7iUsP3XgOoPfu2w6B40I23ND8HhXSMi0UELgOtihgmiapzFBZQqmQx7FtSoU8zapAaE233UHKhHwx/30T7+gAcgGGIUAbuKaNISVpb4Oov0/m30MvjDEKFaYX5jm6sEO1FrJTV+z1tjl+dJ40TQk8j/16h5wvaMcW0pa8sTrAydssLYy+pj8zOU6r1aBQHEMbZabHZ7h54xp71R1yfhHTcUiAnF+kUhij22lT8IvUqjUEPVw/R7NdZ3JigqnxMWbHC3QHfQLbJtOjn9yFMHEdD8twMFKHfApBQQKaIAhuSzk7FJcW8NwATAeUgW/b2GLodykMA4HCFMONb8d2cYTGdUdf4hI/iev4HdzBHdzBHfznwU9qdX4Hd3AHd3AH/xlwJ3nfwR3cwR38NcSd5H0Hd3AHd/DXEHeS9x3cwR3cwV9DvKlsk29f3dcIhdYKpTW9ToPaxk3C2k1IuyilcD0H389j2gFagJYGvU4TVExpYpb1rU1ev3aB9eYVBll3qLugx/G9Cl/+t18eid38uc9e02Ploe2RgcKyFEIoTMtAiOFCghAgcPi+uajSKDmUlVRKoVBIAYbUoCQqlUgliLOMpz90fKQ4vvTc7+pqewXXlwgjQygHrRWpTulHkjCJyLlj2K7Gtk0sy8Q0HcIkJAsVnXQPgDgbMDU+g5YO/agP6VA86L9+//8+UhwP/vI/0wvzxxCYSD1gTLXYvvIMJA3K5RJxHGMgsEyTTruDYds8OOfz5PFpNm+t8s+fvcnx5eMkcUaahuxubLJaV9z3d36bsNbkwh/+g5HiuNC4oov5KUwzjxIOw20jhaEFQv/AkAJ+MJFXYsio0JlCWA6YCau3vsOn/vU/5cn7HuD4/Q/TCzOiNORDj/yXI8VxeGFCn37r08SDAe1Glf2dXRzbwrFtPniqimNlaGnw/NoyZhZhuNBLXZwkI5dEzOcdbrZSMmEwV64Q5HzqzTplNKHv8ccvvDBSHP/37/+mHvRjQmXS7HSpb1aZnSuxtLCAlJLJ6WleefUqKhkwMz1Fmin2trcxrYxWM2R/ewdMl1KpTLMzoLm/y0aty/TCAq5r89mvvTRSHH/w3/0tLdMAkSaYrk/WbZAPNBhQ6+5hOA6l0hRSu/TChLWNHS5fvUq73cWyDWydUTQiDo1JDs9BEJgIY/g5KlPw9z+RjRTHRv2s3qtdI3CmaLSqvLKxzfHpt1Hfjfn9P/wE2aCHoRLK+SKu59Fs7LOzv0ucDpfuPvoL9zJRPMTXv/aXXL26jqWGJsVxKEnjhHajN1Icv/nffFj3o30ENmEYY7sRhmHcNs4WxFLi+0PVTysT6CzD82wCM0+WGnQi2Kg2GJ+oYMo+juOhlCZJUsoTc/zOv/zUSHG8qcl7bedVKsUFBCYr6+c4fuJxEA43b9zEMWNc1yKXz2EICxmGmI6HLSw8zyVLNGnS49jhoxw7vMxrKxfY2l8ljHtc39gmlaNTBaOoS6MZkwty+LaLZViYpolhAEJgGMZQt+OHXlJrgZKCLBuqq0klkGhsMgwhQSj6UqAO4JbeiqqYOclANdCxiRID0tvu6Y7vgzZIVIptm2QkKGXgWRpNSj+NCZwxpFII7WA6JmE8QBsZldwcoRzdFs7SEkcILJ0xW1SMJR0efvod+IHDhfMX2NzcwhBD1+xivohlu7gqZtDqEoUZZ+49g205RFbM/kCQAMqwaQ9iOIDaY5rGxFGXfOCCsBgSI38gNvU9KHV7uco0MYCNtVtsrq/y2ONPYpmSzbUbRN02YbuFZYDQ6kBxuJYg63UJsIhbA6bLFVSWgYC9cJZxYZApjyPlGYJei6RQZKAMDnU7FEoe+1nMfTM20rZJ4wQ7zHD8IkaSIA9wn/r5PP/+S68wVi5Qa3aZLJU4++J3Wa+s8TO/+BEMu4Tp5ZgumcRZzN5eF1vH9HtDiYbKWIlQCtLbcrC+a1AwNDdubvLAqdF53psbq1QKi5imx8vPvcCTD98PUrNbbxGlBhhDre1LK6+zsbXF6tomhp/Ddmx0qMhbOXqDiMVpm7KZogBtaoRQwOjXoxfvEytJlKyDp0iaCbvWeZzKQ+y3GgzaDQzH4z3vfx9O4PP1b3yTxsprJGGM5doItwm+wfiixVOzx7l5dYv6fkqmNE4wOlVQmgHvee+voaSmXt/nu5c/j9SaTCmSKMYyfLLEJfADbMsmjkO0IbHdcZRIMUWH5eMzuKZPd//29jKSTCuydHSq4JuavD/31d/ixOLDjOXmabV2Sbptmrf22bh5HWFKpmcm0UChWEEpTTboo0QG2NiWIOlFqDTFsnMcXzzJkcWThHHM6tq/wjjAW/nTf/9pojBkbnaOQzOHmRgvA4qZ2SlmZ6cJcjks08S2BfwQL1dmCssEpYbO11qBg8TKUvpRj1SZeN7oNkbdrIZSMYO0iykCtJUSDgxcM4cpNKZ0SHVGmqWYliLLTDI9QKbDuBzPphN1iYhpDjLCuI8ph/ovUX90Hi9YGEbE0SmHJ++a55VnLzBRnOTUqRMElsdzyQvsbG+SSEUUhphZil8KyKTBIEwxbJPeoE/SHxDGMTKVCKeEoRXqAB6F58+/gsoEb7nnIebmj4JwQZlg/GghkqUZmczI5XKgNdGgx9Ur38X3Yo4ePcLWrQ1MrSmXxxCmiZASDmCCMLcwR9AbULQDjlQqnBu08T0Lw7TY7rkMTJuCGfDwO9+O0+1gBgX6cYJc36B2Y4W2lSPSCflmnbYfIEyTQElkUMA6gKPPG2+sYdgeWjscO3oKqRNc12D3+hVaHUmjdYvAMegMYvr9DEv3kcJGq4RGs4XvFUi1wXh5mvsfO4YMUzavvcYn/uwv2dgcfXnKsvJE0qS636DW7xPli6ysrrLfbLE0M0690eLaxXOs7ddJBj0sy8R1HXK5PINBn56hUE7Aq+sh9x02scwEaQKJiXWA5D3oD9AqYLt6BdOWyFRz+bUN7n/0HWRRyHhlAss0+M7ZCxg6Q6WScmmCOIjIopR212ZiusvikotjBYR9RTKoIUgOJGuRC6a4/4GPUCw6ZFnIdq3Kzu5rCBHiuza+bWFbNjoRpJj4TgUV9wlTBYZGKIWMYyKtyecLJGmMYOhYJPgrmrzHhceh3CK+V2RyosRz33iW9Vu3SNKEJAzZ3+8QFAKmt3YoFXP4rkvgWNgGGGT4uTzpwMJxArphhrB9/EKRX/jAr/H8q6+MHMfK5ZcxkWy9cYEXM0HBdzGQTFYqKAws22SsUubI7DyFYp5BHLFwaImJ8QmEtMgVHBYPTzNWcmEQUr/yCjNWnV/+J39EPRljZeUrI8WRpRJHFTEzge066Dgm55UwLAtNgulLUpUxSAeoTGFqG5kpMCTSjOk228hMYuPS2A1BW5TcIrtxjYEeXWhHI3j7co73PHKSfrvBz3/8Z6jXmjz/rW/yN/7mr3LvmQd55utf4flnv4ntOJiWwZGpCZLWDm85uUx7tc227dEQmpJvspsJgvIMhr4tJTAiSrbL2e+epbp6E2Gb/NTTP83SzDJK+2SmItNDo2GVpcRRRMnPo9KUu0/ew30nD/N7f/jbfO7P/w1rK6scPzTO/NFTaGmjpIYDJM3x0wtEl5vcau6wl4TMT04yPjlN4Ad0Oz3CJKU4oXnkbSfw3RxeUEE7ASrNWL9yle3r19mvhmxcWUEMWtiGQ8vxKe3dYt8dff358q7CNAPmFw+zsb3D3OQkiWGycNIhbjWYnRpjYwfSzjaV8gRX3miSpoIzj76Ntx09hiVsXj77PL3WHmuvXyQbtGnut/j1/+qj/MkXnxs5js9eXqWbbfDTH/0Y73nHu1k8foxG5SITQvD1L3yG85deI5ZQzgfkJqawTLAdn6BYJMTAsiR+ME2SCj57vckH3vsQSglU/w3Qo4t5CKlJ+g2OHb4LreHE7ATfPreLtCyW7zuDbVv87Eee5qeffBSlFP1Bwu//yR/x7e+8xF51k1trgrCzTyY1s+MJTzy5xLETZb72+XWKExMjx6HSNv/sd/8x737n+3n0ocf527/46zSaG1x5/Rzffv6zhGlMlKSUvCKoEKliBBpp9FA6wtMlMDWGYZFlMaYFOgPDZFgwjog310ln7Bj5YIxep8fO5gbNWp2tnQaN7gBUhO/ZeLbJzsY2c7MVZmenKOVdcr6Da4GITIQwUcJA324X9Dtd8iWf4gG+FNpI6SbZ0EhXm9iZwEDSCbtYKkOgaVbXiPY3ieOEdjigND6JrWzGKxP80q9+nMkpDzsn6G5corm/hixa3DWV56UbeyPHEWcRfsnDyiwsDEruHEvFIzTqG6zstUiSBOFYKMtgkIQ4pkFmx1g29GWIqwNIHTJlkfYjfC/AMz0QJnEyekWjtGJ2vEhgAXmfT/zB/8FHP/LT5HIFHNujVKpw+NARztrPA0NJg0K+RKdfx/dz5Ow+WV9h2TbCEEhlYnsFDHEwudr5qRnCTodSMSBK+3zmc5/iwZMP88CDT2IGDoYwQVtsb62xtr7B8aWjzE7nsQOPJG4CLlGUIExFP1Vs7O8xIxz6vT5xPLpaW2VqiQu9LbJUM1Wa5MjRZYrFApbpUMjlmJ+bwLMiPK9MrjABGERRRGN/i17UYCvp8cSH3sn0o4+z8b/9Dt3DCyydXubmn++QT0ZX83vXY6d55eWL2L7DBz/wNFeu36S11qbk57i1ssJ4fAjXC9iottiqb6DtgL/zD/4h+UKRP/13n8Q1IwadFhOVAkvHTmJmIRvXrjM5u8C9J4+MHEe72WJts8nZsWfhySc4+/I5Nnf38QKPG7c2hkfQVA23kMfG2a83mJubo96oYbs+1eoOu2mN8coY+80mlWt7HD12hnx+jkwNRo7Dc4r44xVa/RY31s8zP3Ec180x5hncc+Q42hS8/uoN9tbr5OSAGIOtzRoLE4sslCo0431UO09z32CcFsqTLC06nHnoCYQ1uoBaHMfs1rZ59tmvY2Dw0IOPUy7Pcd+ZJ3j98kvU6tWhUYkx1BnSWpEbmyJJ+1jCorubUqr4KA1SytuCd8MNWtv+K+qkkyWC+vY27U6Xeq0+dNomI4m6RElCry8QhqCcd4njhP1ai+Ujs+R9i2LOpVhQKKVJ0wzTdEiTDKmGZmI6G/0mqO5toZ0A19AEpomRDRBakvT7mIUKQVCA0KExiGg0G/SjkFYUUrAMTt9/lHsfPoSpu2TNBree+xwbGwMWTyzzU4/dy17j+ZHjkDIjFSEpIWiTx+76e8xbJs9crlE9p5BKg5GSqB6DJEaZIbOP+KSORGPhOjlsy6MfxhScMfK5PKZwaA7qxHr0nrdUCtsLkEJgejaRSrB8h/e8971oDa7jMT09PVSkkxJhGqxu7nJ0Zpo0E+zs12mEFoZlkkYxgzDGERZCH8hti163RyGX540b1ykslDEkPPP8l9jcuM5HP/ZxotCgWu1wbe0GUqY8++yXeOihJQbRHmlzm2sXLzEYhGg5dPv58te+wvGjJzm1fAyVja4qmElJL+zjF1ze9/73kGUwNlbBMG3KBZ+cG2OQDLVwLBvLdomae+zcushrr1+kp+fo9vq8811P8bmvHkG4JjMFg2tjSyzt3Rg5jsXxgMFdx7l85QbFQhnLNDhx10nWVq+R9XscKZsYwqYWWxy55wEef+KtfPsbz7C7tUa/VeXu++6lUsrT7/TZ2Nqis1/FUQnVV84RNUc3LxG31/GvvH6NfmqgW+uYuRzbOxlRZpEpcISF1rBfq+O4PmGksJ0cZAml0jhRFFLfayBkzKWL1xkbO4o1O0smD1Bpag837+C6sxgLS6TuHIt5k72tTd7zrneSKoN+HEEaIlNJP0m4282jsgSdRXSEx872BnalR7t3lWSrzolchbGJSdJk9PYeCBbmjnDs6DEgQ6qMfKmEFoq3vvVDnD//Au3mHpaOsbHxgzJPvfuj7O7ucPW1c+S8PgJFr9fFcZzv+8IqrVEHaO+9qcl7f6uPOT8gVRo/X6RYCpgM82gVsdvQw+msaRB4LgiDOFXsVhuUS0WiRCOVSZok2N0+nmOj0Zi2Ryq7qAPYB/XDlCNF+B9+7W9yVyVjPGfgOxb7e1U+/8Jlzt9YZXOrT2p55OyUj7z9NL/5yx+hVM6hcj7R+nN0b16nc/0S65sDXr+yRjuqcfz0k/zWP/zbI8fhmB79bp9UDbj70PsxNm6yFfeZnF0k0mu4QWmobTJwccyhDOfqF9YpHwm45+334Nk2mUzJu5J+0sa2DQwlEKmDnY5eeWsp8QOLJO6BhF/5pV/B9dxhm8JIsLTJ4vwihmGhhMYQNmpqHhVYkPS5sV3HnJgDBPV+i1hKCrkSAht9APOBrVtrfPh97+fi9Ys8e+l5xibz+GMe660VPvVnn+beu59CJj6tahdFyO76Op+89CV8a58Z1yTHMeYWZplbmOPk6bvYa1a5cvkqX/3yFzl9730jxyHbmjP+OC83tjj30nf5+Z/7IJXKNPOLy0MNZhkjRIZpuWgVMeh0QaV4+WkOLT/O7OIy04tL7N66wcTb7ufI2CJrKyvkienPHR85DqVCpkrwd3/5l/n6M8+yvrHO4UPHqW1ssHxkko3VOjuNNWr1Dlurz/HKt57nLY88xNzCHHNPPsX9b3mUjdVrhJ02mTZwTyp2b7zO1HRIMTe6Bo8fBPi+T6k8xmOnC/yL3/pViPvUGj4PfvQTTI4fw4hCpJS4vssgjPGjFqXKBBlFRD9Ad9uUTJv63i6dgWT91kWmFmew7dFnRPvdFWp8gHgQMugLBnubZNLk1uoOC0vQvH6N/JEjxJ2Q1s4KXnmSuNOl32miK/McHQ/YTobG51blAQba4vnX+9w1Z8ABTgCGUGzf2uXVs2/w9NNPs7vTYOnQPMeWjzE9f5TFTofaKy+iBn1yxSlK5VnCTosw1nz30gYffO/bQaWYGxt0ag2UGLpAmcLA5a9o5e3omEG3SRRnwwmsjDEMQT7nM+86KKmGYi0obMvAtC08zwaGQlJJmmEYGsu2UVKSKU0mI8JYEY5+7fGE5ENvf5yn7j2E3j9PyQDSFC/c5INvmeT0Qp6VaspABSwvTfPwPUfwOzfp12MolNFphtdpEZopF7Y7vFZtsq1Tgtn7iBs3eXDEOLSy0NJFCAc9MOj39yhPLzBbKWBbNrZtIzOJ5QZDbRulUMJh7coeM8eaHD46T0JKqiI0QwEhZaTMTCzgu6MbISt1m/6oh/rcrl/E9z1SpYbi+0pimkMWju04HD12hLsffgg3Dgm7TSIMAhRpPHQXx3Rw8iX07YpiVJgI4jDkxOFlqvs73KqvoD2J7Qasba8itcfhuZNsb96g06vTbewRlBzSyCGUJnefvJtjy4fRwsBzfaYn5vDuy3HDNbAOcBwdtBRTuQlEu0p1v06/uctEoUjcbmBoiUwiDEMhrATT8ek0m1i2ycziccbnbIqlIoZpUt1fZae6R62T0WrX6MgY4wADKSNNaFR3OH53wuFDC2xubxIN+pRmZjGDPKk2aHTqlMfKPPbBD+HncszNzrGxuoLn5thYeZ3FI8tcevlFLK/E+to6tY113vPRj3PxO6M72LiOdXvWIHnk5DKpodCmQ9mPsPl/2XvzINvTs77v877vbz9rd59e79Z3v3OXubNoRttogUFiEEbIBkwcMKEQm20SDA4mGLMlqYQyjmNVAQITMMHIMTGmlIAAiUXbSJpVmn25a9+l13O6+6y//X3f/HF6RnKFkNM2NSWq7lPVdau6+9Z5+vx+5/k97/N8lxxpIsqspDY3i/IC/LrB0xnJMCbNcnb7/bFIGAaNwFBiyiGOEyH3oef9/Att/ugT/xNJbwdpLf00wRhLPQy4GlUwfgX7mT+jPxpA0MDoHM/1ybMM2/sDPjUc4OocIxykznCkg1AuZ779W/4jsbf/37AGy4Ct9hq/+Zv/mp/7uZ+l2WzyxONPcPLkSV599TqDfsGhmSW+7n0foFJr8vjjj3H95ioIOHr8OMoKfMfn5cHjjJKCUu/PuhDe4OJ9ZMZlPYlJh2NX5cFuh9FgQBwXRI0pgjBCmAKb9VG+ixEhpkzBAWF88tzQbDbw/IgyT5FCk+U5vW6PYTb5n/KeB0/zNfecQKSrWAYkQ42wGf3eBgcOHMWRGUfnAppTR/ECH0GXzJSU+Q5iVBCoGspzUJVp0mRIc/EkW8Mujz13lU5/yHdMmMdUbY4sL4j1Dq9ceZFAVJg+cBjrSBxlcJXEGIODi0BQlAUaxc5OymOffI4jJw4ihKDQKY4TUBqLwDITHWFp7vi+rs1oNMI0akipaEzNIYSELBmjqnWOkIKjR4/ieR7zC3NUpmYIpEfVlrzjka/n2vUb9Do7eJ4Hjo/yK+iy2JfCYRSGdHe7zLVanD98lhevPoutQWgFaZxw9dLT3L5yiU6njRCaIh+Q5RGRqFCfmuOee++hVgkYJgl5VmJK8JyQQ8vH0PsYm1RTSTp7hCPpECNL8mRElmYM+rsk8QglBWDwowrWMXQ215luLSCUoj7VGDs7IZiaXiQbPUlnZ5ft7ghZd2FrcueYa7fbNKISm7eJkxH1WsQrLz7D7Nw07UHBo5/5HJUo4Nu/5ZvobW/RbRue+syfYnVJFqfcf//drN66webta4y6Q5QQhL5Db7tN5/a1ifOohD6e8jBC0R6OUNE9FHnCYNBGo0A4LCxMsz3oonIPP4hYW7uFH0VEtQaNegVpc+IkwQoJKPJc0x/0aTYm31Vt77R54Nxx2oNFnv7SM/wXP/ij5GVOd2uHj/76P6cUEmGhUgmR6Yh4FDPY3UVgcJTD6YfejRs2Ge5sUTcp09OzvPT8s7h+hULmE+eR5SnIjKJMaW91+eOP/xE//MM/ShhUGQ4SHnnv3+DqlVep+op+atnsbfF7v/8JsjTmxvUrfPzjn2D5wGGypE+WDzEWpHTG0sH7qN9vaPEOpw4iTUxQASsshyuHWSoKtC5Ik5xuZ4ftXsbUgWPUoxDHJlgMjXoFT1mkHhEnOUZ4VCoRConpxkzVC2qyPnEe3/i2Myz4Ca8+8Ulc2+XI0gm6u20MOcHcUZYP3E9e9kEZrBE4noNyQkSlRpbmWJuzPoy5vGX4wDc9gpUWrXO6uyOS/bjYJwVJMcSUknoU8sefeIHPffFV7j57F3m2g1AZeW7QBoTwKTWEnsR3Pa691OH/+JU/5V3fcB6/Nh77OMKjP0j54rXPszZ7g3vvfmiiPBwp+cQTz1NeWOLogQNUsxIpHYRwMHosOVuWBd/4vkfwPI/RaEgQVvH9CLC8650P47mf44uDLzK6PQSnjvFDHOHsy1tUipwbK5tEocfm1m1wJLkpKeMByWaKTvsM42tUGh46LSlGGfedv5tzp89y+PBRCgujYUyWZWR5jsZS6pKycMjzyYv3TGwYViPePHuEK/2reEqxvXGT3fYWjhOR5CX9nTbHzt6LNob1lVd44jN/jDI5Z+++jzc/8u24Ag4ePoVrIAyrnDtyP8NnXuIK/cnzqHvc6ET0vvAEpy68iU9/8iZvedsDTE+3GAwGfO27H+LP/ugPaTaanD53gd1OB6Uk97/1nUil2Ll1haDa4Nip0yS9PptrK7SmGmy88jwL85OfzP7Jf/MP+Z4f+TlSfP7nf/UpPv7Jp8FahqXgW77r+9neXOfpR/+M/vY2rhcyvTzFyXMXSOKY9uY6SRyPteuNpTVVR5V9VNggmp4n8CavVsPdNc6dfS9HnIive/i9/MxP/ghTrsPIOkjHoRyNUFgKaWlGAe3BLo4rEUIxP9ti+0tPkWcJhefxgR/8Yfo7m1w4e5rf+fBPEdab8I9/dMJMFH/yx18kLw0Ww3/4vf+TT33qUb7ve3+QX/rlX2b5yBzf+Xe/g69977ew295mu7PNd3/n3+WlV16gLBJ+//f/L+675wxT9Qo+Lr7voLUhzzPSdB/8jIl/868gYh2QZrsUWmOt3JtZO3gOBK5D4Di47i6bu108NyCKmjhmSFYYrFOjSGKaM01sNI1mRFnkFMWIelihqyfXBQ5ci9Ax3e1NWg2FVC5GunQHKaUuEaLECgdrchyl0EXGbrtDIKsEYUiqBaWMaC21cKSDNSVWSHTooOPJ5zcL9Ra7Ax+/4tOqzXNJvsLllTV2dnYZ2fHrl6WmNC7SKYnjhGrFJ4oC3EHM44++yGgw4pv+y3tQgYdf8Wjg0R90Sezktk4aw9MvrzHv5iy1WmN26d4pUkqJtRKhxzZjzWYTP/D3WKgGx3GYn25x15mztDs7PPvcc6CaKM/DGrD7MB8gGdCPezz96uM8c+lLJLgsTi+SFwN2sy5KKOYPzCN9jYk12i/BWI4cPIQjHeIkIc9zsiwjz3OMtZRlic4KdDH5Qmo2SdkOUxxt8OeWyG0AecEwHjEcrLPb3UUIw5FTF7m9fpuVlZvcfP6LLC5NMVMNSHs9doY7VBqLrI8cDJZrq89Qf/wxpqrTE+dROAqdDDl69gBb69e5976zPPvUE/hByKGlJa69+izTrRanzp1ne/0GeTLg8KHD7HY2WTy4xOnzb0JrzaXnn2B7fYs8HdHpdzGMmFloTpyHGO5y7uhBeqWgPn2U+y+c48UrV4ncgJ/88R8lyzJ+6UMt/s0v/i9UoghrDJ4XUBYFWDMeWwBFMdYcD0VOY3oW6XhYO7nn6yF1kVgXcucAACAASURBVCPHlrm2skFEwfmZKu+brfObl1YYlhZdlpRG44UBjnJJkxSrS1zXxRrL+w/WGF5e4dHmWaanp2lEDrnOcYNplJm8FA6KjLwYg2AtliLPkaJkOOpx5u772dm6wUc/+gecuetuzpw6SRSFDEcDLl44x8Jckw/90r/gsS+9zLnTRzlzYJFSiLFpdp5D7asUKjhMcsrSUBaGPMvxfIkpS2yZ4ilDreLiuw3Km9uQdMmpoOoNIGd7s8MXHnuKw4cWuP+hdzC9cJgijalKFxVG2Hjy4i3E2IB1MBwQ+hHCr9DPt9gZadZuvEqtOUut0QKrKEgZdNv0djao1VroNCBzpkkKDysUo6SHLg1WG/Iy25f9WN2bQgcuWOiNekzX6vR2etCs0bl2nZ2dNkIoRpkhiOpjlA1QlALXcfADj2e/dIOsTHnre85y/K4FalHIbr/Lamdz4jwKaxl0Uq5eW+c9D4077bHtm3jd5cdaQxRV8Lxx4TZ6jLkWQhFGIXNzcywtLgISqdzx7xjz/3IJ+ssiS3NubndYvXKFQbpNo7aIzKBIcqwxtObnCWo+7d46lJAmKSvXrrG1vsniwgHKPKNIM3RRjO8rbTBlic5zynLy4p2FFVrDBKsCUgIuvXyDk2dOs7G7QXt9HVMmVMKQF168zOrly6zdvoncycjClDgZMuys4kRNhrspn3/iEk13TFYy8QA5mtwppbML586fYTjYpLsjufv8aRanpujs9ul2tnn31zxMc2aObncH3/U4fvwEGsn67Ztcee4x3vLwN2OGI6q1OoFXwcGw8sKTtOZmcN3Jr8sLT3yarz1/htif4tu/77s4feoM7Z0dtjrbVJWgWo2474F7+d2oQmtmBgRk3Q6h79GoVelsdShLQ5anKAXV+VnmjpzBmgK3Ek2cR6w1m6vXuHD8CFlZUs17LPaeJcqncN0Gnu+jiwJXuUgEURgiLDiORFlLuH6JBW/AYyjKrE1rdp4kGXH25GnsPpjR2giQYM341CCVYjDo8Yd/+AccWD6Pkh6jYcqvfvhXec97H+bhh7+Wufk5trY2qE8v8K1/5+/zhS88wVpnhVNLElsW1PyQ3A+R+3AEe0OL9+1+Tm48tHQp/YC4TJBUEB6YeAiMNSOi1jTWQpon5AMXP3CxlRbvet/76e7s8sLLN+iNLH59Cp23MLmlqSZ/gpsSMm2QokJ/c4d/+Et/jDGKt911hi9+9AucPXWA5aVFWvOLuMojH2bsbKyRxbtoN6A9nOPQ0btxpKVacTAGlJDEyZBKPvlCKjG74IJEce1yhxevrVDOhITLszQaivX2NnlckG2M2Li5SdByieoRZd1SICjWwXWhvT7gyeev88xLN1CuJYlzTDn5zegJSX/U5/lnrtF9/0PkeUEYeijpUBZjJxiBS+BXsUbhuR5GmT0fTYvnKVozMzzwwAP805/8WWbPnkNKD2Ekeh9jpI1+wY2tlOEQZK/KzvptBpdWMcpBEdCVPehaRlmMJ12sEmzsbPNr//rXuXjuHt70lgcpdYE1Fl3k6BLysiDPcvJ9zLyvVqd5YGOF5xvzOJTcurJF/wu/T754mLpXo2NcWhs9LvfWcGXEXf4c7lydYLjNjSvrfO6zn6I1O8furZTv8B0uRy38ckT/6DRHd9cnzuPgfIUb19Yospjls3fxykuvEpDRrDZJuwm3XnmS5/ox9ZqiO4w5c2SJo6fv5667zoA4j2tyVKg4duY41168zI1nn2Z7Y4WZmRMU+eTXpXnoKLd34Xt/6L/m4IElrLXMTU8zOz2N2CtgD73lrVg1HqmhC9729rfz8iuvMBwOKEuN1oZKFDE1U+e93/g3OHT8LoqyJN0HHfz7f/y/49OPfo6XX7nE8vEjPF7O8Iw4ia7cptjpko4GaGtoiAZh4FEUJcJqhArwo5APD6dxwyPQ7dFLFP2rtzh335u4sTsCM3nXtXJ9C2vNnsuVRCkH5Xrs7HSYm9ogcCXD4ZDPfvazjOIBt2/f4i1veQt3nbtIoV1O3OXw937gR0g7W/zeRz9Ke/U68WgV3/PAfpV23mmvTVlmZPGQPIuh6CNMgSsNkaPHWgdWY63GGk2gFRtbEbkb4VdqzC+fZsp3uH3tFeYrGutrGoeWGbVvkxWT08EX5xfwi12iSpWk3+fZq33+9t/6Br72nW/jT/+k5LkrN7h0fYdK/SbNRp1WrcrGyirTdYf5o8cYJBmbm5t005QgCBBSEvoeWZoQZ5MXCSskcd6l3y+4fqPDLobd/g6dl1LS/hAhXEIvxNiYUghUrYrwFZ6jmJ4PUaVDe2ULt6IIXYk2JXkOnnXJ9eSzRI1BSktnd5ed7i4YiS001rWUOkcpBdivsGOzCCn2iroY66sgiIKQ1twMMvBxpIsRJd4+jiKmSDC9HsOtTXS/xGu6lNLBFx6UgiIu8aseTunihh7Kg1JqSDXPvfg8CwcXmJubHb+3xlBaKK1Bm/HXpLFtc1Lp4uiMxSxmC0PVU2ReBSGgqhxOuhXcLCbzHGp5yqZJWchBbxeMtKQmfRZOHCL55OM0RZ9VM2R++jRST4566Q9GzM86xHqWrfU2B+dmKMqCm2tbhLUGN27cZrYZkuSaVq0+Rgz1tukNt8mJqFYaWGuZWlzC0Rkq7zO/WAPHQcnJi+a5sxfZeOoKXjTukl8jXr1myWctTNebtGbnKJMhjhI8++yzdHs9pqemWV3doixLPE8hlcNwlGKlQ2lK5D463s5On1ZrnpOHFvmzzzzGB7/rgxRlTH8YM+jt4rmK0hiGw5Si1ITzR5Fq3Hyo0jB9aJmigNJqRoMhKvD59d/+HQSSbB/46q2t7f+IfFYUBd1un0atDmVKd3eXtY1NfuiHfohvev/7WFm5zuVLl2hvbnLvfW9mqXWQxZpPv+/wtoe/kU9++gu0r2bIdJX9bCzfWKigNGiTI0yKNCnxoIvQGcM8o6x4uI4kCB2a9TpSWEqtqdQ9NndKBv0ut9ZWOXjoKGcu3k8Q+UgMJos5cvw0Vy9Nvj0HQVGkTM1OIRoevrfG6eNHQQ45f+/9rC0usnLzNjd3OmwnA7ojw2xriVbTp9k8gI3mMNZBeT7tbg/HcfH3TI3jdPKttfKryDimyEbUqxHOdJVyEJMOY1xHAhLHEUjlMjNfJ6hFQIoGHMejMVuhv6VwZzyssEghCB0fTwQk+9AUsULg+A2GJqA7TMAIdFlgsBRFDrh7XYbdM02WrzcIUkq01lhjcJXi/N0PcDWdQqIwosDdBwRL6JjDzQqt4AAvv3CZhZkT5HmJK6BSC2jNtdCUJL0EjUVEEhVKpAMmt3zhicc5e/oUhw8dobRjLarSWqzZn7ZJK+mxJhxyDK0yoVUUzKPYzBMCAVJIAqOpSYF1HCquh7WW7cEOWkbc3rzN+votGpUmJ5wQR2vaUjBTqXMrmHyxvtvZZv7MIhurGgabyOkqt9fbuMKysdVhZnYGTxZUfMFcaxbl+eRFgk1S+r0rPHF5wIlTx6jPLrB14wZZkXL8/AkwVYqdyU8AvuORlCVhJUJbi3rtgSzGjaIVFgP87M//PL/xK7/M9ZeeJR71qVUj4jTFak1RaIIoot8fkmtBVKlT6pJwH56vT37hi7SdKTq9bZrz9zB98BDa5FSsYEYXYCx5mrM9SMiyEdU9tUltNGWRkQ/6lIWmKEv+5JXL9NubKN9BdjYp1eQMy7IYNytf4SSLtpYkTbi1vsbObo88S3n3O99B5Nf44499gm/+wPt44YVn6fc7fMu3fpDBMEVVG0zpGo3pY5hih81XNnDNV2nxzoqcZDggHvZIBrvkaUKW5yhhqNUlC4cPcfzwMnONBmmakaQ5jueOj95S8sRTr/Lso5cYFpZ7HniIZmuOmmPpjwZ40eQz70F/SDm4zai7yqdeGfHwm88ii22uXt8C6xFWKpw5f45KLcCxilApZHqL4foVekNN4RkcN6VVDWnWptBakyQJG+0dwurkH86yVHh+jdacQ7e3jhQCKUoiP8DIEs+CLRJCv0J9po52M/KixFiXLM/Qucv88hLutESWEkc7RCbAQeGIyYuVKXMOnLifYS3iZidHlzF5aSj2lAl94+MoDykVZbm3ECwLXNclCALyPMNxHCqVCv/oR3+C//DJF3i5HaOVA/uYeetRn+WWj7WLnFiY52Mfe4KpmTpn7r+Pw8dO4AcBg1GfK69eoho10KnB1HLqzQAhNTvZgEdffhLxzBN8zTu/nlpY3XOPLyiKyU9E02nGelSnpwxJmTCnqtyI4GZzijnp0ROCYPMKwo+4VmsyTEZ0wwbT1mBGO3zpqUsMepuEYUB+5s1Mb/SZ0xC1b6HV5A+zwweXePaZVd701jczGM3R3VjlxNGjPPf8l7j/4kmuXF5lanqW+ZaPYw2VSp102KfX7zBTr3N75TKh7/H0+ueZX32Oc/edw+QOQaQZVcOJ87iyu02aFCgNuJaSMXVW7ZUwYUBgeeBtD3HfO97Jv/xfP8xv/OIvENkIoSKmj5xEbt0mTxOCap08GZFnY9VQxOSd9/IDD1KxOQfS+bH6nulRWEGpx6qe2lpkPqLWfYXFWpNub0R68C6MkZgCdH0GrXNMUeALQ3jhHG5U4+ViiF1/cuI8QCAEOEKOIbzaYAQUZcnWzg5REFLkGX/rb74fISyeF9DvDjl74RxLB4/xbz7yYYyRnDh+F0rUqJTbqLpHt3UQuQ+m+BtavIUwjPW8S5QCiybwJL7ncvDIUY4fPkKzEmGspFpr4IdjHLe1BUJILl44SmumxktX1nnxmadozc+zsHSQEyeOMVWdfPEhhCDLYoqyIB1q3vXWeQK3IPTmqPnjvIQSaAGm0ExXQ0ZpQb1RYWZhjkQ1UKpEGUmRW7Q2OFYiZxvjG3LCKMuY7e6IUTpA41CL6nTTLlJYcgPCsbhCUmpNnCYkoxHSLShtTpE5hJGLshXyMqXmN5FG4AqFyQz+PpiNjlI4IVRmpshKSVEk5MaQlwmO44yRJ55AChdrxyeioiwoyxJjzFgjRo278PmWw5svHmH0zG2udA3lfop3nuMqi7EQBgF3XziJQVONfIo8RTiC9vYWCMGRQ8s0p6b43HOPohyJqmi0a3FxEAaeevIJzt91jqhWJTeaYh9jE6/QiMjSynapW0E+auM1FghGPeYbiwRFzEEkm0mfVrVJIxuxowdsj3o0nXI84jGKupTUDy+zduWz5MawvniWcjg5LX19bYf51jRZPGRrY5VGVOPK1SvUQo/ebsLhI4epR5JK6OJYQ6lLHAnzC0cQukAFDlEAvtIEgcMwHeDgkicGx5u80zx76ihPPX2FJB7h+3VK7FgOWYwlea2wWGMwWmEFnD51lG/77h/g1Jm7KIzl9o2bfPS3/zfsqEM/KXn1pRc4evosR8/djW8m31Xt9gvq01VU0MQIy6hQY8l3JcfXONesrD7Fmw7NUA1hu2jzgj1PpjWFLimSHsoayiSmt91hbv4MXmMWTYZXTt7xWjum01jL67NvRyoMglEco4sSs0dOE6KkLOHzn/8cqxvreL7HsROLXLp0hcce+zRn77qAoyyj7TZFHuM7X6Uzb4klT2KMLtDa4AcBngOeshw4sEy91kRQUpQGoQxSKbSVBJU6YBBKceigYm5uit/6vc9xa7RL3N9Bx12a0zMT5zFKC5IsAbfC8lLEVMXFr9WYrkRErgvCkKZDhtkIv1qhWvcQWQVbr2FlgChTdJmSZXqsFmZKPGmJ6iGjbPJxRW6HrG5tU4uaaMba19kgJWxWMVaT5gUGxcLBg8RFhjGWQa+DFjDoxuiopOqFOBKqXgXX80izjKyMCf3Ji3fguPihR2Sr6DylP+hgpIMfVUiyGC00SJDSkJXluPsvxx+6ohzrjLuORTkO0qTcdSDE2CVuPdnZlySs1iVKuQgxVlxcWpolyVKyZETVTjEYdrm6cpU8K8jinGP3nODp57/IqJfgoImqLvUwQgnYvL3BE+mQ8+cuoLyQch+LU5tmbC4E1EYZjldjOd5lKBQq2WWrOseoLNkxmluqoOcq3OY8q/kOieNQZgUN10dXpnAdQX/kElbnKZJtNtyIOT35Ry5LeoTNOi+++CKLCzNcu36LUOTMLMxTqdWoBAAW63hj3RkKkA5Zbqj6ksQ6DEdboGrMLy8TNuqUcQzGEuzjpBoKwYP3XCQddLHNKXLKMUvSCowRWGuwVmBLEEXGwRnN81GIEzWohwFr61sU2mCLEtdVZHlKUeagBfvYq/PiC68QzsxQGEOjMYV1A5JBH8cLEMIhL1Jurqzxtjc3ifMcW6mxtbVLWaSUeUra3R6jj7QBz6E5VWdna5NilOHt40Q0RlkJsHZP91+NZSAMe5yIEruHtLJW4PsBrl9y9fpLfOQjPf7xj/8wczNz9N0er77yHK7nsd1eh3wX1ZgcSvrGjk3iPsIkOEJTSoUrLVPNCvOHjnFovoU0GlNKpCfHpgaGcRESBiElnhMRVSqU2vDffv+3cuXqCi9euswzX/w8SVrwoV/88ER5jIYxYaXK+pbmTfeeYLY5Q6IChMjZ7ac47ngJU61USAvDzdU1arbEMRa3UhLWpilLHy9SdDrrKGGRrkPpRLju5EUzL1OaMwrHHzFXreDJGQ7dGzAaxLTXBkSuT2+QcfGei1xfX6Hd6VAUAX4QcmBpmninh5Rjwa94OKKiShyhsLIk3sfY5NLnfhf55x2qfpXgwbeQZieYqk9RDIYE0uIKizSG0iZkWcHttXX6gxFRFCGkoN/dJQxDfN+j19klGw7Y3enzyr/9t1g/BL5vojwSnbFxcwddSowQZEWBdFzmZgPa2xs88czTDJOUd198mFMnT5MUKe9/5P2MspSV9atcvvUyuDlV3yeYq9IZdPnYJz7GOx/82n1B0oJixIGNFQ4Uhm7UZFWvsRKvcaLWwpiSepYRJn3OCsmNrQ0OOx7Gm2eh5jBXrtJSVTanj6N6bdLbbdTuBqccCe0VhsOdifNYvusM3XaXQ60qwzjjyHSFzKkjozpTTR/X8XEdD0dk4PgM+hmu73H1dptRUtBNNOuDJtK0mTmzTF6kOH4FbZL9LXDTggvLDfzt38ckMVTfhFHTZCqkM6qiknXmwy1C8xTCKXjrUpVnF6ugcjqb4wd4s9nk5uoNvMhFC6iGHslwSLQfjZXOZcrOy/zBxz7K008+znDQ5/y5ewgDj+tXriClwPVcPtFYpMgGSOuwtnkFrS1SKcqswPcdHEcivTpf+C0H12YIFTA9NfnD7OjRObY2Ogg5XuRLJdGmAFvieXKMwLHj4i6RmDwnTmNOHF5idr7Oj/34T3Pq2Anuv/duTp45RD/pUytr7FzbJFZfpWOTPMvHsoeOi/UVWIn0IlpTTWxpsHvsEFcqtNavO9pIpQAxvghYHCxZUXDoQIvZmYijqxv0h5NLbVZCH8+p05yqEVRmGAwSksBnlJYE0oNco5QiS0qkF1GbbpK3V4iTDDXVYKVT0N7YpBFFOCqk1BmOEhS6SyEmf0ulUtQ8RVIWaKk4eKxFVkaIA5JmvYOPYBAbUlOglDO2bCpzfFnFjSqI7R2E1jgooiggkD6lhWJk0OnkxTsvSwKdY7Iezz/1Wf7l6Dat5hTGUSwdXGD52DL1aoX+MGaz3eGZ557nxZdeoVavjx9wwxKlxmusTjykSBPSOEM7MZOvb6Esx6euOC4wViBdheeOLaJ0VpAnBZSwuLhEqTWlKFEWPOVy9MBxdoc9OtttsnxEqhJSo8GXvPDyCxw/cXriPIbKwc0zcJs0ij7ZaJvIrREJl6yIUXmKLDIcN8JxXAqrsVgSoZAywitGeNKlDGsUXkBz8RRu9zZOPCL1Ji9WN65tceTQNJdfvoqUFn9xCUXG0nSVRrVKr9cFW1DkKX4Qgc5BRBxq1dlsdzi+EGBFSpILgiii7MVEgYvxFwiacxPn8ak/fZxQD/j6r2kw0xCQfgYRhOwms1y+dpyDzRGHwps4SQcRVjDKR0mfSlSnHGbs7u6ysrKC1ZpklEOW8+xTT/K+v30OoSZ/iJQobFESeRWEcNBaE1XrVCoRzYV5kjRmNBjSXnlp7NZjLZ7wMcJgDEhP4YU+Slp6vS6hp6jPNEiylN3R5NdlYW4WyZ4A955NItYwnuEIXtPSFFIgGd/XSklurG+CH3BgNuDy1edZ37rNBw/+ANXmAoN+inUlldrkcgFvaPHGaLKsIPAEgS+JKlPMLx5kYXoG8ZrdlRpLUFpjkMqhLAqEGM+YkqxA5ym+76FNieM41KoNLp6d3tex2HcFCJ+kMNxqx3Ru3uJW6lDagiPzs8zOTbGz00FqTRDVSLKcsweaDIeaP/i/H2VzkBApubdt1tQbFU4sH0DkfbZ2J9eNDlyPvkxwraQS+dTciEhHxGZErRFQ8wOqqWTl1pCd7T7JIBnfMFIhpABdIoTFVwFREFKr1NjtD8ZFfh8LOjcbUg52SSykwvKp9Rv4CISj8AOXKAqJfA+jNcM4YTRKKPOcnusClkCN0RbWAkpTaoMxkiVHMXInv8VMoWk0K2RZD1uM0S0z0w3CwMcIRas+R5KkCAdynTJWchnvUKSE04dP0QjrrG7dZmt3m9JqjNTc7KxS7IOkMxAuyiakKsSkHZRSGOWNTx86xzUaK6Aw7JGRLEhFLh36lORBg7h+kNhps925wnw0jaw2cQuYnKID042SK5dvUOQZ5+4+gREBFa+CJwyYAt9zcF2P0lgcx6feaJKlJUrDsy/e4lvf8wDPXV3j+Vc7OI5DozVPMhziOlXi3clPAN7Scba2rjCszVBUJLSvQDKkXvV4y9vfTGBXsJ3nke40eE1y6wF1lPQJwogH3vwgLzz2aa49+yRlkRJ4Dk8/+QTf/J3fi9aTP96NLEizmCAKsFiElHS2NljXmiQZkeUp2mgc18VaAWKML5fsiT5ZOe6GhUQ5Do7rkmaa5YZPpzf5+0GpiQKHpNAg94r3X6BdL4QYE3nseI8TG8sr167yyLvejF91uXJ9nU998nOcuesUQmRopdH7GDO+sZ13XhJUamDH8+9jy8scmJ0nVIIsTnFchyDwkAJcx6PIcrQu0KVCSkkURpSORxIPqFWrwHjTHMcJ5T6OgVvtdbxI89kvvMxLK2u8/73v4lanQ2JKLl1dYWq6icUQ7wzwg5DCaIK3PcjZpQYnl2p84NQFKlJSuB4b7XXyPEWIlN20oBJMPjYpdUgzHG/v42yI9FpUqwHp7i53HzzNYJTTKQbcXnuRjdtbVCOXhdYsSIXJBwxNAgacUnOwtkScDMnzmNnZGvlo8jHB152/wNtqJ7BWoI3FdVyEkhhXsufEjLVg9J5KoLUo5e4J6VgKq1/HgFvlYgGlFI4uuJbsw1s0TikxNKfCMYLBdbEmRheg3JCL586DkKTxEOGMH2CvMTiFEAT4HGkd4eDcAS7fmOLq9Wt0BttoK9lqr02cx4uNOr57gFBDs5uQ1qdRZx7i2s1LDKNpmtk6MmoyasxxtVJjtYyJhcSMthnZjCNqDpl1yAOPU0OHW3nC09urHC8yztUm73i7G12OLTTp5VV6vYL7LhweQx6lS5HFuFKSxiMCv8KwP6CzvcXS0hLVIOID77mfy7c2eP76iEEi9iCflqzUWJ3h2Mkf7stnzxMcXGY9u0FrcJvedkBrNqJuU0znFbyaItMtfufzG/S0i/DrVKIa8fYWSim6/SEPvv3dhMrhuS89SRmEXLjrHLub2/j7gArurG1SasPhw0dZmF9gOOiyunYLz/NwfQ+lHBzHfR0qbRkbhwvBGMnFeMGolKRebxD4Pp7rMNI55w8tTJxHLYp4z8Nv5blXbnBt5cZ4YS/HnqvWGl7bZtq9L2HH3bfVEhB84k8f59ChGR556F6ypEuy8TyOK0AXjIZfpWOTrzQcVUpQq1fxHIXOc9Y2tuns9vC8gLtOHSAKfazVSKn2dDQEpsgxpQbMWAdAjAkiRZHvS0wxNgXxSHPs2BJLi/OcPj7PkSN1DCX93SmaUw2UkuhBgTaaOEsoky54M8zO1tjdXWPXKnLl0t7eA+xbQ5xmDPeB805NSp6MqFemsSrDaE2WC6R1SHWBpyo4qs+hhSqyiKlP1ykLyPKC3d4AqzVlDtoqesWQwPOJAp+FuTqD3uQfzqR1kNsLDTwkhRVjLQgBmdUIKbF8xWlQ7EnI4oyL+h5BZxwWvdd9SCkRecZ2f3I0QVFotBjnLS1gx3jzghyEg1BgMeiyGDPnHIW1ag+DLhBmTNm3peHw3CHqfo1Xb17j2o3LKLkPwbD+BqpVpSdHBCInc0LitKRiC4Zxl8W4R72wxDtrBHoGr0xRpiBPdjlYn6cy6jJVjCVKZ7Gk9SmsUdy+8ihJf3LNmdBz6MU51alFZuo10mSEIyTSFVghyfOcXMNMGJEnMbUwZHt9jZn5RXYGmpdXBmy0Nzgw2+SLz19h+fAinhJ4Drj7cI7JRz0865BkUzx+qc92O6LeUZw4WKedbnL+wkU68UlqcycxeQ5OQlnkeJ5iOBqiyTh+5gSzs1McvnCcRrXBwsISSZ4iislVFstSo63FGDh+7BRyjyCk9fj7pR4vChGv36qYMSRkfD8C2oz5EIHr4SiJchRChnT6k+excPAgFsPswRMcW7nNdqf3ehNhjHl9kfl62PEI5zVSm8XiCU2jPs9dbz6JwJLlGUmaEtYmX1iK/Uh23ok7cSfuxJ346ojJQbh34k7ciTtxJ75q4k7xvhN34k7cib+Gcad434k7cSfuxF/DuFO878SduBN34q9hvKFok7//wX9gX1uQWmspigJdlthSI8oMYzQlY+U6AIOgQFLuoW+EcJHCAalo+w67riJGoIoxTO367/7qRBzXf//omv3yRngMo5AC1B5Wc4we0ci9nwsheOaTv0k5WEeXMWurG4RRgMVlOBoRhZrZ2Tne/e3/A6l2eOT++Yny+Jl/9jsWJcdoZSP2srOiLgAAIABJREFUUhljRk1/i94oJWq28P0qVmiM1XzxuU9x4+bzhE6VzfXrBFUf45Z4pkKhC/J0BFJD6HDrsasT5VGRrp1fmMYPHKzQvOviCfBHPHN1nRvrY5qvlJLOZhtkQOBJvvv97+ajf/4kg1FJr9sb6zxg4C8w2DVmMrHkX/nt37BZltLfXcMCgd9iutmkNnuMZ5/+OH51hsCL2FpZIRsobG+d1t3zGKPoJ9Bq1XGsh3QcNreuUKso6vPHGWzuYIshP/eTPz9RHkmS2NeMJL4SivjpT3+aD33oQywvLxNFEUtLS5w+fZpjx47Rbrf3pHN5HSIGYyREq9XCcRxu3rzJzZs3+Z7v+Z6J8ujfXLFxMmAw7PLoZ/6UNC5ZWjzMieOnmVuo7Sk82j16uhnj0a1BSh9rFY7jAGOkxdbWFh//+Cf47Gc/Q61Z5aG3v5MP/ug/mSiPh7/5IXvjRo+jxw9Tb1R45zf8BIePHGVpMWK48ueUMqNR93j16c9CPuDYoUP89D/7d+x0Y4QjOHPxAgcOHCDpDQkdh2rkI9EEfoYjLf/oJ35tojyyLLN/1QALYwx5GmO1YWp2blKOvH1N6ExrjTGGLMvwfZ80TceENSHGiDjAcZyxo5PWZFnGaDSiKIo9+rzFcRxWV1d5+OGHX0OpTJTHG1q8lZBIKbACtDGvu5uIvQIppUDasUTp69/fU/B6/aJ9GZX2ZTzQPsN5DUokeJ0AJBm7rwshkEIg7PhfO6YO4cuMYdzHiwJWbu/geQ4WQ6UxhR8GoC27t1+iMbcMzE+URyAzrLYoR40RlMKMtcyBeLRL5Hh4NsVXPkIYNAWBYwnckF53HcdzcX1FTo4mQ+cZVueoKCTbB+NUyPGDLB5lIDVKOKRpwWBnwHAIURTieR5RJaLU4CtDkReMRjlJPGavjdll/3kfrGQwIncK5loNbq/tstiK2O2tkcoKMgjJTEGR9/nkn30WrxC8ySsoLs6R5gMWZhbIywFpYUmKjNpUC+UI8jhhJ95hsTE57n04HBKGY9W91x/mwIMPPsjs7Cyu63Lq1CmOHTvG0tISjUaDtbU1jBkX0NFohFIKz/NI05TV1VXm5+fxfZ/Z2dmJ8xDCIIUmCnyOHDnBx/79v+PJz3+eXmr44H/1HRxeXsb1fMLQxXEkxoJAoaRClyW9nS5WKna2O/zUz/337HS2OX30GCdOnOSRRx6ZOI+rl26y2RmSFyOWj9xFkhekec6ttZS7l0/z55/9KNYM2FhfYcFT9JIm2hFIz0U5Fs9XKGGxuqAUilJbAs9BigLxFzzs/7/fj/+ED/tfEq/B96RS7ENiBfhy0S6KAqUUQRCg1JiPYox5nffwmivVWH0zf72AGzO2EGy1WgBEUfT6/5vUfeqNLd5S4rguBgtluVd7x5R4IeRe5/aVYu+vdb78JSLl+6/gSo7xoWP+yd5r7XXeCJDSIuze6+7lgE5QUqDckLXNHoNhn2bDx++PiOMZlIXb1z5PWXSBkxPlIT1BEQ/R2Vj0KXQlxmgcx2E7G+EU40IufIOUGsqckwfniZTg0tWcfm8bbQtkqCiHGW5d4dYjhlsxJt4Hw9KVGA2jOCWohbQ3d5hdqJD1CpTyXy9Knu8itKEcjcjTjCQpKcsx8WAs7fmfV7yV8gg8B8dk+I7CmpJmuER/EBOIiEHSx6157HQ2UVLQbTWYchwaUYMwEBSZIopCVFojKQYUqcNUdQq/3qJwJzdBSNOUSqUylkjIMtI0ZWVlhZ2dHd797nczPT3NgQMHUEoRhuFXdMDjv399fZ08z2k0GiwsLDAajVhdXWV6epqpqanJ3w85LuDKkczMzrK40KTRjFjbTfipn/lppltz+GGEttBo1CmLEt/3MFaQJyOKNCYrLd2dLq35Kd70povUPJ/77n0TU83J8wicEEfEDLYHjOZKnL2HQ54VrI98rt9YZ7f9Ks0DAVujhOuPP4W04EgFyhKFAVUJGZaiMIzSAul6jPvvye/Tv8r4yus1Fpqa/N59rek0ew3oYDBgOBxSFAWVSoVarYbrunje+J5zHOf113IcB8/zKMuxScRrXXmz2aQoCoQQ+P5kGPw3lh7vSFSlhhIWUeSotMAwphpbxwc8FCVojbHjnhcLVhgkDlYItDRjqVaxR85gz8FoHyLmkftlMXn2XkMINWYMij3nDeviyAQlU3wVs7Qwz+cefZInn/04eZnhOjXuvXAfX//IRX7hn3+ES5dWmFlc4rFP/e9829/8tony8DF4YYgSUBRDSp3iBT5CaE5cOM32Rpt82IVCEtZcSqdkuN5Gmz7NWkh3tyRLC8JKhAGSOEc5Ai90oTk5c62fGvzAEPl1Rr0uz9xo84MX7uEf/J1v4n/87U9jjKDT7lKMMo4faPG93/oIv/Bbv8uoFCijsBiUUAixJ9Dznxg3Vy7juNOEtZA8U7z00suUZYoxmjOHHsIkGld4SCCszeHc+zbCZIbeqIPJM7Aea3EPoXIaQR1XligDKm4z6k+eV57nxHHM1tYWWmsee+wxnnrqKba2tlheXuad73wnnueh9ZhZGscx/X6f6enpsXPN1BSVSoU8z7ly5QozMzM4jkO73SYIJpcMBsaMwSJneqbB0bPnuXntEnNlQqNRozlVJS9KNte2wBRjFU7tc3uzw6C/y1vOH6fWaLLiu9xz9hBTzQbV2izveMc79iVM9dP/9O/xYz/2LzBAvTZFkZd7703B+nqGZxrUTAORN9EyJ6palOgiZYZQkoMHZrl7+SRrt9u0B5ogCAkij/vvf5CpxuSCUH9p7Mm0fmXHO/62/Qs7dmtfo60bpJJjuYkJQ+/JvbbbbT7ykY/Q7XaRUjIzM8PFixdpNBqsrq4SxzEnT57kyJEjzM/Pv34q832fer0+1l7xPPr9Pnmes7GxwYkTJ746i7dSCtcZu2lbo1+fKX7Zts1irEIiENZg0Th67F6uYdwej0fCSCtQCKR4bdY6+c2oxhIHSDEWx0JoEBIhXbAGJSwOOZEa4MiENG3zr37td7ixuoIl56G3v52bN7aRUu09YX2cPOfhd7+V3fbkjMISi680RudonWGNochLSpNDkiLzAbUo4v9h702DLDvPOs/f+571nrvfzLyZlUvtJVWpLGspSZZthCQDxoCNmLbdEN3QMdDt6AhgItw9wcwE9AzuYJiYAYIOlvGHZvgwbiCGBszYRlgGW3bJki3J1lYqqapUa1blnnn3e+7Z33c+nMwryyxxc+hQ0BF6vpRClcp89J68z3ne5/kvYWrRH8QkWQ/PErR1wvyBA7yxfIVCxUNqSTpMyUSKyhQgSf192LEhieIEJTKyOCWKEzY3t/FKFaIgIh5lKJXhSAlpyEy9SmeQIOwCOs3Iicj/8FlklqY4BYNkOMQfBGQKXKdEsVxme/063V6L2SPHqRZcPvieB7jvnju5uLMFUUChOc2o32N6qo5pFxls3UQ6Hr12D63rjIaTMxunp6fZ2dmhXC4zHA7Jsoxw1/KuWCwyNzeH1pqtrS1c1x13UXvdVafTodPpUK/XqdVq7OzsUK3mlmTWPujguTkHY7mITmfIYBhSq9VZnJ/Nn1mSa5x0ux2kFJSrJcquZK42R71cQOiIZsNFCoVXLDM9t/R3FrS/K7Q0yRAIDYY0iaKYMA5J04RB5ybPPnmWbDTk9jtu4+GHHuDQwizPfuMS0oixHZditU595gDF8gH0jXXCMGboB2xtdTHE5Ofx94fYKw9v6arf8hXf9f+c652o/LO/z5GM1ppSqUQcxwyHQ8Iw5OrVq6ytrXHHHXcQRRGvvfYaL7/8Mo7j8MlPfpJms0mWZbiui9Z6fLNzXZc33niDs2fPcvz4cX7qp35qohzeXnq8lLlC4K6AuWFIUsPIJyJ7oxGVX2PQmlQLtJJIIVAGuUws5CMNQCKQ48IxefGQAEIg92QbDbU7ukkwZYwpE2w5RCcb9Dpb/MUX/orV9RGGUeTQgQbvf+8DrK7+NVrnWr6maWIagjj26fYmnzVrnaLVENvSROEI0PT7PWJiiDyEWcBwNEYScvmNZTzRo1kyaBqSURhR8IoUDJtgGJAGMSrJiKMILUU+R99HjIIRtjCQUnDi0CLSLuIVy8RRQCZyarFhppw6dZSNdgewILPYW1AqlctE/f/ZQYxDCmxb0N3eQCkHoSN63T4KgSmgF/Yx2xd4z8ElblM9+mc/T9hcYDAcML0wTxQNKbglCBL6/U2q9SOMBpsMuiOUmlwzIssy6vU6cRwjpSRJEmzbJkmS8dxSSkm/32drawvTNMfdmNaaxcVF+v0+w+EQz/OoVCrj+ejeEmui0LnJAWhMw8Qf+dy4dYty0WXQ62O7HrZlc/joYdq9HoYh8DyXWsGjs72F55WQQuOH24RBRLk6xX3vfR9ZmiL2YZLxwksXUFLmn1vLRKMZ+UOGwz43Lnyb1y5exDFc+v2Iolvm5Il3oXW+43JMC9v22NzpkkSKVrtFMEoJg5Br9jVGfo/33Hdm8jP5u45K6DEN/W8e49545G/vwKXcAy5MFlmWobXGcRyEENx+++0Mh0O++MUvsrCwwMLCAv1+nx/5kR8hSRJ6vR6GYTAajRiNRvmSNI4RQpAkuSPVaDTi4sWLdDqdf5zFG3a5/4Jx0UNAotJcuEVrEAY6y8CycZuHGPg9TBJKhsnWygYmAkPlFkSmlDhG7jQj9nH4lpGPZCyhETrFsAJQAUL5EGyjkiEpKb/9+3/Gs8+/ShprPvBD7+YDD56h6LhcuNHO51W2TZompGlMmmkQcmxSMEnMN036nYzhcEQUB3R6O0RCEeqYuulx88ZVXnnlJY4uzHLk0EFKhQp2ociB2TJuwaXolfjG1fMIGWPXi/k1MCmShDHJcPI8TMvEVAKlNIawGK3f4OVslh/7weO879QCy2ttEIJ/+9/9C57466/xa//xj8l0CUNZIOO3XHr+If23oT3Wb65Rm5klHozIVBWXAUaoqc4fpVios3XpPGcOH6JUqaJqFYJOBx+Tl55+idkTi6zsLGMY0B+FdMIriFhCpgj2YS/V7Xap1+tIKWk0GnS7XT7ykY/w/PPPEwQBX/jCF3j44YdZWVkZzz/jOGZqagqtNVmW4fv+eKaplGIwGHDr1i2klHzkIx+ZKA9ppGgluXjhOn/4h3/CxuZF7jh1O8vX1pheXCBMfN518k5621vcd9cxwjAmSRTadCnUGlxfXebwoSUOHT1Gv9NhZWUFyzTHeU0aN69vEIR9wiSh2ZylWISbVy5y8dVv8+I3/jJvqtwSC6dP8xd/+SWee+45PvWL/yO9fhfLNChNlWhvtVm9uUK738MfRhiGQ7fdpeBOrrHydyFNlNLE0YhXvvU8WZrwwEOP7DaEeUEXUuYN4Xd9D4HAMC3Gsq4TRpIkRFGEZVk0m02effZZpqamEELw8z//8wwGA06dOsX169c5ffo0nU5njDIxDOMti0vLslheXub111/nox/9KOvrk3uLvs3CVAKlk3wsIjTClLk8ozLzGZxSCK2IkZiWi1mwqFgF0jCh6tl02hapn+YbdSGxhERLmaMl9jE2sQwwlCZTIwwZIke3SOIRSRoisgQpNNKyeOaZl8iEpDnl8GMf/gAFSxIOYkwhsAyJYxsUPYfphkMYBkgU2T6Q8zpNGUUjlEpQaYAiIdQpApMsTWhvLlNxBSVHYBsKy3ZAaQaDIb4/ZLqywHxjhxtqGUskSNMk8GNc4eIYk19HVabIdD6K0kLyL//FP+fp81d57vkXWai7rN+MeOCB+/jqF79MlAhuu+Mkr7y+hdaQfGe38w9Em3SHW8zN3YYixatU0aMB/U5Mq9cCHVHNqlRFjVh7aO3AsMOhRp00CHHNGv3OkG3/FqbjMlc9wGZ3ByJNqVRk2OtMnMceakBKie/7BEGQix9lGaurq6RpyvT0dA51zTKSJBkvLb8zhsMhw+GQcrlMEAR89rOfBeAXf/EXJ8rj4qVLfOYzf8xXvvJV1jfbPPbYQ6yub+EHCWcePM6BxSnSDBbOPMD6rWtkaYBVsJlZPMJOb0Bn+wjrq2uMAp9bq5usbg25dPkKd5++Y/KHAgx7fSrFApYqcOq2E1y++DzfPPtFVm68QRqPEKaFEBKvWEIjWL61wqlT7yKKRjiOTRD5VNwqRbdMqhK6nT7b221c16XkTa5frff2YH9DejXfDTiuw/kXX2V+aZFafRrTMnCL5bx467+lQH/HXHw/xfvll18mCAKq1SrD4ZBz585h2/Z4Qbm5ucnrr7+O53mcPXuWWq3GwsICaZoipSQMw/GtbjQaIYSgXq/z1a9+dV9opLe38xagduVDATBAa4Eg19dN04wMg8wuUqg1qFZtLr56jtUb17jn3aeZXZpj62aHbJRgSIklctihkgqhJ9fBRWU8/+zTPPf809x35nbOnCjnoxOpENIlSuDpp56j5LrMzU/zgYfvp+pVieMg1xG3bCzTQEjF1asbzM8foT6lyRJNJiav3v3QIFVFMlKUsNB2hgqGhCpmFHYpWAZ2o4ohJVEU4XmaRIVEYYLA4PpgwGAY4lXLyKGBBkxlgqfR0eQQLFSWi9cjUXHChx77QU6+p83TT3yeZGeTsjB473tOcn1tg/c88sOcv7HC5ev/N1EUE6fqTZSQ/u6xyf5mKG6xjp90EZkk9UMcRnR6fYSh6NzYoFS2mKk20X6XkA42milZ5GqvRWgYFEsecVRFCkFvaxPXLSFM0NL/7s/73xvD4ZA0zfXiB4MBvV6Pc+fO0Wq1qNfrJEmC53ksLi7S6/UIgoAwDMcfTsMwmJ2dJUkSWq3WuDDcddddLC8vT5zHL37qf+OVly/iuibNpSabm21aOx3cUpX7H3wPw1GLra11tjptTNvF0D5uaQp/MIBsyNLROZbmD3Dtjcs8++3zWK7EsNz8d3Qf71nPdTm2sMjM1Dw/cPd7+Nn/+d9y6dVnMSwDJQRewWOqUWd9Y4NSuUK/3+GNNy4yPz9LnISUiiVmpl28QoVqtUIQRKyurnLz1hpxtB+7jt20v2tmL4TIlS6zFMeyeP7pp5hbWEJlKfe+9yHcQnFXKlZ/93fKC7fa39j1qaeeGnfNW1tblEolHMfBsiz+9E//FCklFy5c4L777mN5eZlKpcLs7OwYIrh3K8uyjK2tLY4fP06/3ycMQ9rtyXXF39bibUuB1hloAyEMHMfBMHLBdMuyyLQmJscbB6M23XOXWJptcPLYITzPZrsds3TiMMtvXMU2NdpSICGTMUpMXrxtM+Hy1ef55jNf4Ctf+kP+w//xSxxcOsTayiq/8u9/hShOOfXu4/zKL/8r6tUCmQZ0hBQKKQtst26RKsik5vULA5SYwyoM2d4cUnAnxxOHQZeiW0C7KaWSQ03XEcLGNC26a9eY8fvEaYShAaVp76yjpINKM7xag8FogN+Jufv+R/IOMPaJwj6G1oTR5LN3REa6u/g1tcV//0u/xk//xA/zvvtPE68UEHcuYlfg4Q9+jNcubfGtbz5PlEQEsY8SCSJXuwdy9yehdH67MvIr6aSRxintjS0KBZtStYRhTVFblCgJ7XNXMIsh7bU1jtYXKRbmEZ7GmV1iLh7SMjxUPGJ25iCxShgU+qRRTCIhjaHTmfw8Pve5zxHHMYcPH8ZxHB577DHCMOTee+/FMIwxGadarbKyssLy8vIYr6u1Jooi+v0+aZoSBMEYTlgsFve1GCtYkmOHZtne6aLDhIfPnKZecRiNRjzzxS8wu3iAcqPJk1/5a+48cYC5usWrLz5Np694zwP3cev1i4zCCJUmfODh+zl64l2cuu0gWZZh7GPmvTQ/x113nOKDJ7+He7wK//tP/Ss+sbHK8toyUgtGvR5bYcLO5gaWbVOr1vijP/0CH/3R76dYcBFNCymg3+vg+33SNKNYLFAulej2+xPnkcQRhmGOO+Y9py2tNdcvX+SFb3wd1/NYuXGDtZVbNGdmqVTqaAGN2VkOHj6Wj2S1zuHKgFa7O7N9dN5nzpyhWCxy5swZPM/jd37nd8aLyW9+85tj8s33fu/3srW1xdra2ngsHAQBDzzwAE8++STdbpf7778f3/c5fPgwP/7jP86TTz45cR5vM847ISNFazPXZ5YZhrHb8xmSNE2QWcBsUZJmQ1pxxBuvneP06ZMkoaBg1HDLDpVqgWHokwiFRCNEgmby4n3ulW8yCnyOHVmi3drCK5Z57vlXePKrT7N48CD33Hs377rrGNXpKmmqiVNFHCiGg5DN9T7f+vZLbLc6qHQRrxDSWl0h0QlCnkSpfZAOMAnjBJMc5+2ICCkTVKKwSx5euYbwO0SjAN8fYZgGTqGAEhlmscbiQoPNzU0KlSauWyHNMlQaEsch0aA3+YMREr2L085EytlvvEGv1eeBe+a478gUpsjY2thgWFjhy19/mYuXrmCZLiMd4JoWUZKMEUOCfFEl9jSUxT7MGGRAZWoeKRRrnZvMVGbpDvtoWzPlFTFVSDpcx5g6CDomiHLvxjSKSQsmpl3EdUoMejexLBPLKOAZcGP1CrVGbeI8jh49ShiGHDx4kEajMV44Qd7ltdttsiwbw73gTewvgGVZNBqN3KbL88bQwyeeeGJfs+bDBxfQWUq/5+NHip1Wh2qpSblcQNgWKvFRQYfTRxaw4hHaD5n2HJqzVeJwmywY0t7pUSmVEDgcPXwcQ1iocemaLObm5rCFwZTpYHZ7TMUxP/K+7+GP/3KH/mgIWhBGIUQ+VlYAFDduXOfb33qBqUaN0+822dneotvrMNWoM9WYxZBQ9DzCcPLdTLZH6hN7bOTdF5AQdLa38YoeIAjDAMM08f1hDgUUBqPBAJUmxFGEZdn5CeyNSxS7i+HJ4tixYyilCMOQra0tfuZnfoatrS2UUnieRxiGJEmCaZocPHiQe+65hzRNx0zMlZUV1tfX2dnZ4b777iOKIur1Or/1W79Fsg8HrLd55h3lByZMtDZR7LqSCzAME2mAUhZZkmBKmJpu4toZ840iXb9LEg8hK1EsWYSJwJDkmHG5P6jgt7/9DAXX487Tp9jcLHP9xk3OX7hIrVHl3XffztzsLCqFF1+5Rb+fMBz4qBQ67T7d1jbVWgOx2kdlgocfvoNOZ0hvmFCq2Cg9efEuVZt0/BiM3FnIHw2wlN59ASjcSp3RoEsQjpCGpOLUc2SDVsSZZrpe5eSp49j0MDQI00FYRYRTwPYmJ2FIIVC7IvHaUHSTmG+88ipn3nuYe97/EK4IGPYG/A+/+p+40QqpFEvs9IaYQlJybDSQqAylFY5pc6DZpL3TQpoO7GOM5BRKyCyh3W9jFooo2yYkJI5STs0dYWHpMI3mHOlWn27Lp6t9TLvCVr+NUXMwpCDTMTpRqDBFC00sU0qmi70P84HFxUUOHDiAbdsEQTCmvu8x36anpwnDEN/3iaIIKeUYgbB3hddaj//cW07t0aYnjaOHDrKyfI3mXI21rQEXrt2kVi9SK7scObxIMhoRhD7Hbj/C8089Rb+jmTl6kjvuOsnK9TdILMHS7DSmZRJkRWbnl0h2SXF7yK1JolKpYGUaK4gIVMSff+2LSCm4+8hxXr5+jZ4/QKcpWoJSKWmW0ul06PeHeAWHK29coNPt0G7vcCnNmJqaRQqDqUYDpSc/jyxNYNf+DEDtsl+VylhfucmgPyBJYk7fex9ry8uMRj5ZllEoeGRxQq/TJoojEII4CEmzjDiOaU43cb39MXBd1+Xy5cucP3+eT3ziE5TLZQB2dnaIooiFhQXa7Ta2bVMul8cvbSkl165d49at3AGo3W7jeR5ra2tjXsGk8fbOvLWPzPQuo8nE2mXYCC0xSFFAIgSpJckwwI+ZX5ohTPtYpkm54pKpEFsnmEaKI0GIDG3EqH3MvMM+2F5CrWZzYG6JdnfEkaNHsAyHJ/7yRQ4d2uEDj57m8OIUpmViG2CaRn4lHqVcXWmxvdMnySLCUUK96NGsCTLDJQ0nv55PF6FSX8IszKKzgKR3HceWxIlmY2gRmjPIjVuY9SPUZ+eZOnSSrReeoFCbQlcPEG7e4lCljB9FRKMVEAKtUhJtEGeTfygOlKrEQtHpdqhg89C76hyeWeIOs8wrz1/HiK+jgj6HZ2Zo+zs0SjYdK0XYNovNAyy3NugGPjqDLEnw+wNOHDnKhUtXsPfBbJwuVOm3t5EqplKssN7bYGZ2kWjQ4//56y9RsC0a9SnuLUiSoEelucja5ReYXVpiu9XlxKl7SdOIqjfFOn3iQYDqtThUO4afTn49b7fblMtl0jSl1Wq9pegahkG320Upxa1bt1hbW+PmzZvce++9tFot0jRlbW2NVqvF9vY2r7zyCt1ulyRJWFpa2ldn9bF/+s94+dvPYBjgWoJSwaHX9Sm6RbrbWwwGMcpyeff3PcgdD/wAX/mrv+bRH/4gvZ1VKlMBcWay2e6y1e7yr3/2ZzHdIlESY37H6GGSMCyTjJSVhuZc9wr6xAG+9cRZ1jbWueOuezl37gUG/gDbLuZu9qZFt9dGIzlx7BiB7yPLirnGFNI06Pd7jPwhz3/zK0RJxr/5N5+cKI9+r4NtuwghMU0TQ0rcYpFnn/kqly68zolTd3Dmwfczt7CIUorXz73E66+8SGNqCttxWbl1nebsHN12m+e+fha9K8lhe2V+6EcfY3ruwER53Lx5kz/5kz/B8zwajQYbGxvUavnNLggCOp0OhUKBcrk8hgPuPfcwDPnGN77B/fffz+XLl0nTdNws7M3HJ423d2yiYsgUGgMhsl1Wk8iv7bvYbUtDIgoMhgFxkiHNMqZrYiQa0zIRmcyXi2YMEgQpjrG/bbHOFOVSmTtOTqNVRrPZxLIkWhk8/+J1hGUwN1fCsvZIQTn7MkkSApGCMJHSRGcOTzxxbteHL6bcKKEn02ACQJgWChulXRzHJU7fIFUpSmkalkU728I0bYqVOZzaHJlbxXYdlIZybY4ohXh7mdIzCC0vAAAgAElEQVTMDIFVIU1D0izEygSunPzRFlXMA3ecZPPGG5yan+GH3nuc6WoRa+oAF9oDwtYGU57gwFSdqU5M2bKZbUxhGgH1Yh3HktzYWqfl+yRa0x34zMYJRVPgWvvovKVkcfEwVX+aJApJ6y7+sI/t2gRJyDAc0O63Kc/NcHSmwdTBE/Qin3ptkfL0InEywh/0SNOMwNzBdEA5KZ00JLMnZzaeP3+eubk5RqMRjz/+OD/2Yz82/rtr167x2muvkaYpm5ubbG1t0W63mZ+fH1+Hr1y5QqvVIggCbNtGSkmz2eSxxx7bV+ddLFdo1GuoVguvUaTklclSxc1bGzjFwywcXKI3HLJ89QpTzSVO3nkvqytrbG+usbOxw6DXIso0XrWOWywTRins+inuZ3yTJAmmFtzc2UQ6JlEYM12a4p7veTdPXHiVXr+H6ThIaWCYBoYpSZKYW7eW2d5coFzyiKOAcrFBmmmW5g8yGPSJRj7JPpjRwdAntmJM08CyHUzLQoSSYrHM/NJB3vfo9+E6HkkUYZo2S4eP8s2vfhmUouB5RGGE1uDYNpVKdUxv72xv8ed/9Afc+57vmSiPPSbtHh1+r1jvsWsbjcb41ialxLIsvva1r/HUU0+NSTyPPPIIX/ziFzl37hymaVIqlcayCpPG21q8pYp3Nfz25J4Eu1aFu2J6OvcuNEtYto1WIVoLwhgKpgkohIRMx0CEFAIThS00+7h94RVsVJLhWCZCmuT8g5QsTen0upQqHugCSaRyj7xUoBQkiUF/lNIfxKDBsATFWpkkTomihOEwxt4HRK9eqRB1fUQ6IsoSKmWHJJNkUUzJc6BcYFirYxc8qkVJ7F/HrTYYtnZIB2vY1Skyv4WlfIzZu1AqRQDBcAD7cKH+wfvu4L6770OcXmSunDJXshgFbWTpCAemj1OzphG9Lfr+NvWCzbA9pFmuYAmH6VKZolPCtgzeWNtgkCiCYMj29g4HKiVce/Lz0EnCSGos18F2XdY2rpFlPqX6DFPz04Q9H6UUS0tH0SrBj2NmZ5dozC2wvH2d3s4VOjs9KvUZ4nBIY3oBb7rM9fU1dDL5eWxvb3PlyhUOHDhAFOUz2b0l1NNPP82VK1dot9tsbm6SZRlpmrKxsUEQBGOhor2Z5x7Zx3EcyuXyxNRnAIXJwUPH6Xc7SDSWoRj4bWzX4YWXLlAr32J2rslmZ0BzbodjJ05w8cIrLN+4jk5jvIJNuTHDfe/7AKMwIPfGVWhhk+nJX6qWNDGFxI9HWIbN4fpx7viBuzCnLX7v8T/DtKxdspscQ+GklLtkIItUaYQhSBUgBWEcUCoXaDSm6e1DQO3cC89z55n7iWNF59ZNtjbW8bwih44e4+77HwANQTDEtp1c3K0/YGp6miiMGPkjtMoY9nu0k4TeoM9w6NPv99je2dkX6uXatWs8+OCDHDlyhGKxiOd59Pv9sQYQMH72kI9ZPvGJTxAEAbfffjtPPfUUFy5cGDN5Lcvi6tWrY4bmpPG2Fm+N2DUHFbsCUHK3fKu8oGtFlkGsQtx0RN3VpCOfnU0fw4Z6s4aQpZzqK/eYlQJpuPvCGJfLGRurEf/5j5+mNtVkc3OTNMlIEk3BsBi2e/zab/w5ya4wlFcskKS7mN40wTJKuI7HxvoOXuUwtjtNmgXcvPE8ZW/yYhWHAyQR//kP/xMoyb/8yQ9jGBIpHIKgT7u1zdzR20HtaqA4Br5tEvo+/evnKB2/n6xcZWflEll8FsOyMO0idmkRyytOnMdjt03xl8+9hCUU+ug0tutScUuUJdz9Ez/H6qtnOfflL7C9dot0Z4Mlu8idhxfwahVkpcEffeUV6sU69yxZWFpzfXODOMo4c/I24iiYOI916VMQBvEwwHNLlG0XU1hU3Cnufu/deKbLsNXj6sY6lWYZVY0x9IDe9gXKbpFgXbJ09DY2+rcYRiHXN68xVZ+mUbcYppP/qp85c4bz589TrVb50Ic+xOrqKsPhECEETzzxxJgOv1fY9zquSqXCcDgkjmMMwyDLMh599FFeffVVHMfh2rVr++q8s0zz4Y//JKbj8OK3niVRmvmFecJwhGX4+MMWLzy3TKozCkWbb571mJ2dY2Z6miyJKBZLZIZNuTJNqvKXj9IShM4ZiROGJEcQVSsldtrb/OQHPsqNb3+df/d//jqWI9Hk2iCBPyTYPY9KrcalGyvI569QrTVRKmS22WBmqkpNxVSFotGYolyZ3HD3M7//e9z9yssgJMtXLpNmKSrL5RlO332GH/3ox5lqzpJlGUHgU6yUeObsWU6cOsXJd93Jy889h5QbdLodzr/2Ov5ohNbgB8G+GKdJknD69GkeeOCBt2C1B4PBWBJWKUWv1+Py5cv88i//Mr/xG7/Biy++yDPPPMMv/MIvYBgGv/d7v0ez2WQwGJAkCUeOHBmjliaJt7l4G/lSTBhoYQAyR4voXYwwAi0FVpbgmRpDJyglkTrLVe8GPuVqEUtKXN6c2+Uz9MkXMCeOLCDTDucvrDI1JRl0hszMHWLkj4jjPq7j4I8y4ijFNC2UUtSqNVZWVgmiFFAUzJRK0SHwtwhGLQyd8aH330uSDCfOo93rYbkejVqVoR9hGII0itBJhopjiuUG080a/Z6PVynlt44kwSsUaEcxJc+CLCRxLIrFAmmqSNMRnY1LSMsBfnSiPIxkyNx0DUdKeq0+F5OA04sexSgliVKuXV3jwqWbqFQzUy5ysFLlaLNItVHAqRWZb9QYJT6mSpmfmWG6YtMeRMxNTREMJz8PKXIdG9txCaKAiuNQqbgoQ1Oe9qg508zNLFKZbWB7Bp4HQaBBKla2blEou2xurjMYDag159FqRJqGZElKSU3+Ug2CgGazyYsvvkiSJGNFwZ2dnXF3ZVnWmPK+BwncI/LsLS8BXnjhBaSUTE9P0+v19rWQAk2hXOVd9z7A65cu0m1v4/s+d56+g/bOKvWKS6ngMgzzxdyg28FzCriOQ71WodVq4ZQbpJlCIdFiVyt/V55i0vBHI2rVMsNhn6AXQX+bV9evc11HmJaTs6STcPe2JxBao7XI1Q3DhNrMIu3WFqvrm2xtt6hVbA5MuRydcRkMuhPnYVo2q8vLeMUihmmgVIYWAtt2uHDuZUxD8sD7HspvOq5DFEaoLKNSqTIajWi321TKZXSmaE5PE0URaZrhB6N9oV56vR7Xrl0jyzKmpqZoNpt4nsfs7CzFYhGtNWEY8uSTT/LpT3+azc1N1tbW+NKXvsRgMOA3f/M3+dSnPsX999/PgQMHxs3A5ubmeHY+0XlM/JX/JUJLlNijq+bjE4Uey8JCjgAqihw+h5CYRoZjSfw0Rcc5AxOd4Eg5fltqLdmPKZBjFMiiDaYbMyzON9lcXafdapOlGYsHD1CtlhiFNzGljZAG0kpJ0xFFz0WnAzxXcPrIIWqlIqFjIyUUDYt7TzbJ1OSdZqoU3XaL2dkmaqNNtzMEcknYildEKYsgDjEsC2kYCAmFQi5qU6rXKRWgXKzR0006UYbQEsd0cUvkyJxJwzJp1gukfp80jLm15bMwXaA4jFm5epGnvvI1Nq+vM2NLqsUSlWKBUtWkVtIE/TW032WhLFmaLoGREsYZlrAoOzYimvxXLM1iUCkSzSAYYnlVZBrT7vaoNqq0RlsYpoXXKJMEQ+JY4EcDSoUyXr1K5Hdz1T6nQalYAlFglLTJhikjf/LzqFarHDp0CNu22dra4rd/+7dxXZdyuYyUEsdxePTRR3n88cfHTMwsy8YSsY6TY7H3Cv/MzMz460qlfTAK0aQKDh27jQe/9/t46kufIw5GrG9u40qDKIyolIo4jkGcxFSKJQpOAUNIwiBEGiblao0kzVU6tdqFCGqF3secMe/YNe1el1F/xAsXz9H3DN7/3vfzxp/9v0gh8wIk5a4ph85lipRCCthcu4lKEkxTMgoDglAT+A6z1YME+xhnFYtFpCEZ9Hvjl6jY3UW5rsONK5fZWl/P1R4lBEFIY3qKKIqJRgEFz6NcreD7w1yeehdBZJolHHvyxfqRI0dotVr87u/+Ltvb2zSbTUqlEjMzMxw/fnwsQvb444+zvb3NzMwMN27cAMBxHLrdLo8//jiPPvooURSxvb3NaDTCtu1/vJ13JFKwDISpd2u1fnPmPdbl1hgqd9FBW0RGgrBNuqs9bNNCJSFax1gFY6wyqNS+MPbYhmRhvoZXtLh69RKmCUUHBirhxvVl0jRl4cACWvY4dcdx1tY3ae/EdLd9hCXROqVWKXDy2ALV+QZl10SHAfPTNZJ08tlZwbQpVF1qnodj2jQaDYaDHirLWL15g2K9jk5N4sGQbmsbt1oh7LSRpsGxE8exizYZkrhUZvrQDGmq2WltIbRD6k6Or77vIx9k6uqQlUsvM5A+qxspG5s+ZBv8/j//OKs7IxrlEifevQhJjOF4zJ06ghF2GO1s80/vP0gcbDPnCfqWi3+9S7UxxbEjR2htT05Lb+1s0WjOIVNN2akzjAcEYYApbaIwIFUJbubQH0WkScpw2OHooZNYroMhLHrCRxoGTmASiAgdpww2euC5iOL+FpYnT55kenqaWq1Gs9lECIHv+3iex6/+6q9y9uxZpqenabVaFItFHMfB8zxKpRKNRgPP8/A8DyEEGxsbY22TMAwnziPbXeQjXb730Q9x8dXz3Lx+hXbXZ9QbsrjQxC2YdLe7KKXzm1cBBmFAvVHj6G3v5rY7z1Aq10mTZAxflNJA7wMqOBqN6LRbDId9tnoDulmPw4uHefC+B/iPf/CHGKaFQKLIRasQBpmKSdKIbq9NFMdYrodlOWTEeG6BXi/iK0+/SLU4edNlGhK1+5LcI+gIoXAcbwzjHPR7Y2SHaZq4jkupXCKJY44eP4a/K1mwhyKSUo5FoiaN1157jc9//vMEQYDWeiwJa5omZ8+exXVdTNMcs20Nw6DRaNBqtWg0GpTLZTY2NpiZmeEzn/kMlmXx7LPPcvLkSS5dujT5eUz8lf8FIrJAW2CY5EgTrVFib2G5C7xHYGR7oxRBYqqczmsZCARSa4ShSY03q7XK9icsY5mag0tTLC3McNvxJYbDkChKGIQBb1y6ytZ2h2A4pD8Ycuv6Jr3BkMEgROp8AdMJMr72wutsdgfcze00ax5l26A3HO0L7G+gMSwTy4C56RqDwYDRKMQzBddv3eKwLak3puh1W4yCEVPTNdbWt6hPNTBtC62yXWq6ZtjvIE2bSqmI51UI9lEkhCVwixUSJG6tyLSvCfwRI0twZLrB1VtdkpLGNjP8MGFjZweRCXbafeJMY8ZtDFdQrlZZa22TJiFB4hPGIUE0uSCU4Xj0uqsgPIpuBQMbkQWU6iWiOCaIU5QhKRSs/Jprm2y0tkiEplCwMaIRru2y0+8irRJx5GN6gpAYtzg57h1yfYqlpaWxfdmeU4rjOHzta1/j6tWrY1y3YRjU63XK5TKlUol6Pcfj77npHDt2bDxKabUml6bVKlfVFCJfqH/4o/+MJ77w56zfuEycZZx//SIz01VuO3GEMIro94dUqg1K9Qq2YzJ7YImCV9sdYbxpGKGy3Q/dhBEGI8IoxC04HCqWmJtuYCBpddsgd63fyKUq8u0/YyvDNI2J0hQVRyghMaWg1+tSKdbotDuIZPImw7btcVH8Tlz9XiEHxmcO+Y1hMBjkhJpRgFIZwWhEmqZUq9UxJt913X19bp966ilKpdKYMdvtdhmNRmN1yeFwOL6FJUmC7/vcfffduK7LtWvXqNVqzM7O4vs+zz77LK7r8r73vY+HHnqIq1evTpzH21q8Q0ejDIU0BUK+1dFMCLFHWM0dRLRGZBAZCgyFsK38jaozDFviy3j8Hyuxv+IdBXnBc6SmYAqK9Vw6M5Fl5meqDIcBrf6I5eU1BgMflUU0Zx2yaUGawkZHYbkOK9sdghdf59Bcg0OzdQaeAVpwz4R5KBSdThtTgEDlcpHaYGhEGG5Oy4/jGMezMW2FqRNsy2BuaQ5hmmitEDpDioxKZRppmoDAchxsc/Jr4GCzi2XPE8cR1aKLW1SgM7QpuW1xlitrLUzHILMsjJLJYLtF1PeJw4TqbJOeapOpEFwbyzGoVopEoUFv2EHakz8XU0ukaVKtTbHd2qZccEkQbO+0qJTKmIZLJqC108G0bYJQ0R1sgpS4BWhWyvR8n41Ol+kpm95oQHN6CjUYEoaTM05HoxHXr18nyzJOnDhBrVajVCphWRZBELC5ucnMzAxXrlwZd9u1Wo1yuUy5XMbzvDdVM3mTxm0YBs1mc+I83vyECKQwmJ0/xMd/4qf48l98lpVbF9latxn0+txa2aRerzI1NUOt2sDybOyCjTAtEpWbHO2RcrTWY0nkybPQlMslZJIhDYNiqYLSkvWdNQzbxTLtHDqXJbs/AwxpI6VJkqRgRoyCAbXaFNLyiKOUAT1UplhZX504D8MwxhC9vReRbdtjbWxgrOIoZT7KCcKAfq9Llio6rR1s236LTMGebdl+8PeLi4tjT0rTNGk2m2O44HcusuM4Rik1zvHnfu7n+PSnP025XOaxxx7jy1/+Mo7jUCqV6PV63HXXXSwuLk6cx9tavAduSiJzO7Q9iUYpdn0r2TUc00aORBECQ2kilaFJUZ5CDAz6gzZD2yau5WwrrQUaNX7TTxKpzpdKsRCIVCCNCGPXu7LkuZSLBWZnKzz8/nfnAjKJYjjIBddTlRGGCTojN4uw9Vh/PMQEY/JOYpjFyEyR6owoTpGmJGDIa62v896THyRVCWGUkplFlOXy6qVrVKoVVlsdslRx4tBRLNOmv9nD8ywsaRLFCTrLkEw+e3/+pcvcee9R5mZnCIcd/DTC9Vyyoo3sDPmBh+6m4wcIzyMY+MiSwzBW+DGUai56us7OyjJzQnDoxCKV+YSvn9ukn0SobPIxUqu1yagXUGn0CeMIZ/4gaIMszmj11rFdF9tzqJgOK7fWWFnd5OSxw3g1j512l/ljJ7i5cZWF+Wl0ElIu2vR3WtiOYOBPfgOAvFB8/etf53Of+xzHjh2j2+2OjRleeuklyuUyjUaD+fl5LMvC3JVaDcOQWq2G4zhvMTDeKxCj0eR5KDSZVjmkVmsgwy1V+fBP/DS9zg7raze5tXyNV1/8JrGw8NwiiWHgFac5euI0s0u3kWpJtmvQkRc8UDpG6ckXuLedPMnqrVtoMxdTatSneePadf7os5+lXCyP0RWZsojiGEOalL0yjmWAigiGGUkSYhsmqR0SRSGBn1LzCoxGk98Qe70eaZrms28pCYKA4XA4VvT7TmXHvWJeLpeJRhFOwWVrZ4sDs3Pj57FXuKMo2tfY5GMf+9gYUSSlZG1tbYz1D8MQy7LewqgVQnD16lU8z+MP/uAP2Nra4tVXX2VpaYlPfvKTzMzMYNs2U1NTHDx4cOI83tbinZKR6Tcx3RowtPiOVaNA7pJc9K6nZbZrbJuRv/WlkRElGWpXiyN3Xc/2BX1SKhsL2ozd7AHDyD0khcxvATvbLUzTwrYsXNfNTWkF+KOIKM7QOiVLQ7TWpGlKHMWk+7iObne3mDZrWAWHYRiTRjGreotRPGKY+CA1qdI4BRt/GGDYDtVqmUwadEcjtvtdil4Ru1xECIk0LCxbgmlT2AeeOC1XiDFwbAc/TemPfMxygZY/JNYZWRJjmhadtk8YR1gobu1s093ZwXNdYiFJMoUfxNh1B9MEITV9P0KpyYu3MAs4TkQmHUxX0O10iYOIYqEAqQH+CMNxEZ6FU/Q4uDBHZDjMFhs4hmRl8xZJkuKUKgjdR9oeqpAifSh5k+eRpun4+l0sFsc051KpxHA4xPd9RqMRjzzyCLVabdxt7V3n9xTjvpMqvzf/3E+Tsff7ufd93vz3UKjPcltjmsUjxzh8/HjuxypkTgqyClQqDRIFKt8cjmfcSim00Eg9eZMxd2AOU0gSDUkUY5sOFy69QbvXR2kTyzTzhboA6RpYpo0hJFmSEAQ+pco0WRrS7/dyI2bbZBQERFFupzJp7GmH7L0Q9zrxt/pR5p8/x3HyZ2AYlGtVlNZ02x1Umi9R9wg0e56S+0EBfbce+9raGpcvX2ZxcTFH+Oz+7D0zjlKpxM7ODlprRqMRjuPw0EMPoZTioYcemvjnfneI/Ywb3ol34p14J96JfxyxD+uAd+KdeCfeiXfiH0u8U7zfiXfinXgn/iuMd4r3O/FOvBPvxH+F8bYuLP3hdV0slmEs0O/y1vfHm8vDt6798k07ROTK6bsLCvGmjncu+j830bbwZ3/9GU2ikFaGKw1mpmI2WpJU2xi2hWvHHKhD1YHl9YBB6pLJCkKDUhGmlERZhikVlsrRK6EGkRiYSvNb/9P7Jsrj0AFHE2fYZoYyJCNlooQgVRqtcsQNCApeAcezUTJj6PdQOqPoWni2zShTSMfDa5RJo4iSnVJRMZ1tzcvnOxPlcf6553WSJDkWWGVk2ZuEDqJwLL7U7nbQEpLd5SxaYxsmnV4X3x+RJjGuyJe+8/PzFMtlpCH58H/7ryfK45d+/VO6YQcYhsBxbWwrxTY1pilB2YCgWnWYLQdko5B+u49Z9qiZAtfWJJkgDFLizMSPTJIoh5H24iFJqPnpn/+difJ45Hse1Q++63am63XSoI3fWmP15jLXhyZSJ9x18ih2oUAoGyxNTWEIwfz8NI2Si+sWMLwKqdJEUUAt3MLvtGjP3YksNol1wscf+/6J8vjYj9ypw0yiVG4Y0O4NSDJFqeCgxRApCzh2mVbQpVot42oY9mPSNMV1C0RaUi5lqCQhjIpgpVgWxJHEEvCVJ1+ZKI+f+Ynv17VSGbRgp99BacXsTJPDBw8jMoFXKODYNp7nEQUB/WHEhcsvgFVASoupYhmj6PLt8+do9zZwMkmv51NzK3iOzZ88+e2J8vi/fv/Temb2XVTKJQZRRjDcRqExpaTuFEHmNnxZlu1izTOkaSDlHuoj1/7fAyw4joMtHYTlMWpd4OEPfWxStMHfuyj8m/Xrbw8FpElKqiIyLdkKJFGiuKNZmCiPt5lhqXDTJJd0JUckgAEYZEq+Ba6jv+OfhEpQKkaJgCxVaJUXayFyEKvWancTPTdRHifnEg42QohD4tGAVmuTerFIodxAFQ5QLXvYesgX/uLzDIYB/+SffJx/979+Cs8r05id5133Pcrc9DTVis3GdoxMYwQOlhuQ+JsTn8edixntWKJMkzARBK1cw0UhcWyNZezaPKkAV5rYlsR1LQzTxrQkmdQUAacIcdhn2ArITAPbs7CMydEmllRooVAolEjRIiPdVVm0dtX08keh8PsDgiCg3WlTLHgMen2efOKvUHFCwfNIyB1Gzpw5w7HbToyRAZOECK8zaPnMHlrEH3WpNYpoBKmwqdRdpGkTYLEdOAS9Hqk2Gayt8YF7D5EEbUy7gOs6RJHCNDIySzCKYnwpSI3JUUA7K1dZrZe5+trLmIbJz/8v/55hnCK2lhmEAgeNXbA5+/JFvGqFLBiiR9tkRgXhFljfadE4cpQjB04R9bt4aYpudXj6wnWK5cnPI5MpSQaDKAbDYmbWI4sj+n5GrTyHJTVRFGIlgsF6gC8tlJFRLHpkpNhphpmZFJwSOsnIhMKxTFQskGLy34+a20CrDAkMe35O8Y81N964hm0aqFRRcHNZY8cykUhEJGiWqxQKHoZt5QgZs4CpXWZr0+jBCvWSQ+4xOGEok9CexjVtvKKJjmJKoyFxGDE62KBsi5xIl6RkSlF0c8PuPbieyhRK5byiarmCQCBEQlqwyfzy5Hnsxl7m2Z75hlYEcUKMwk4ydv7or1j7q69Te+AuCj/1/aAUWaYwd3HxQkBiuISxyzCIuHDlPOFoyB0//sMT/fy3V9tEKXLEaS4Hm0QDrrz+Cr1em/sf+W9QSiAliD1NbAFap2g00lCs31ym0phFmDaGUEihv+MNtw9vwPAGq1dX0KlAZxHtzpBw5CMNyYOP/DBGMqTX3WZx/gDPfP1ptm6+QfvmebbCmK1qlVs3lnn0Ax9g4X33512hNkBIhLCQ9uSOHCeOWKxupSip6IWC/iBFxCAzwf/H3JvGWHpm932/Z3m3u9+6tVf13k12N8lu7sPhkENy9pFszTiyxpASQQiQQHEQfXBgI0CCIIsQBE6CwEsUWxEsSIghOY4taxnL8mg2cjgLh5zh3jt7qerat7u++/M8+XCLFJB8yC0gYPQABdSHbuDUe997znPO+S8KiXB2DAEUoKQ91F9QBIFGeZrYpCgctUhSGEfuK6RVY5r0EaBPW5vrTHc6FFlKkSVIIYj7fa5du8aTTz0DfGjUaijSBOEMWsBUu0meJpw/c5oyzljbWKfEfkRcqFarH+FtJzmeSXj/J28xNzdHu97AU4JSKlRYo7QWTIHwQ5IkAQUzzTqKGloAWlBai1IC3zoKUWKkwCqLZyzFESSDLwR1WtNtarNVIj9C2IJzj32CYmueu+++z3DYQ0tBNfBJDXhBhMs2oVZHCE0WBcydOkmWFAxKqFTqNLwK6soBH3xwa+I44qSgwMM6gbCWQVxQZhlpMe4qoqpmmKfU/ICkzLHS4pSH9MZmzKIcIZyhdCXVWpXMCpQwZEkKTE5KyfIUpw2kllD6BMKjzEp836NIUzzl44wF6w7Z0pbBMKbTLnAmQxYWJwVlnpKlKZW5gKcff3x8ETmCoFxJHassmVMop5ireNifvk6+O2Q5H5GJKjUl6CdDAuchOzW8siCrhOjCEfsFQa+HPnaR0lmMFITWRxofZSYvqoM8HZsJm/EtvszzQ+0Yh7EgewM2X36d3d/8l5SDHit37nLplz5HKRVZmqBDhZIKITU7sUdcZAzSmFpnmqnmX1IzhrIosb7BSYkF3vvx9/mD3/9D5jotjp9+kMXjD2KMQDrvo1zsnKEsRrz/xve5fvV9Hv/U8yydOju2UhvXToAjqQr2dm4iVIDne+ggpNbyCat18jRnqjXFu9zGrvIAACAASURBVG+/zubGCtXqDJ//zKcJIsUv/sLP88PXfowKa7hKm1G/z+rtW6jWAxhboJRDuAAVTS4sE87XiHr7+FJSrXhkFoYjSxwbssMOQwkOReNTnFRIXxBUfJSnSIYxzhYIl1GLfGIfytTiBFgxefJOkxEb6wmB73Pn+g1m2lPcv3+fW1eu8ORTz2APqchlWZAmI4qiIM9SijwjDDyW5ueYrbfxleTd1XtEUUS1Wv3Iw3HS0whC7t1Y4drCDT750nNI5SiNReERZynVWoDC4mxGoy5RsuDO6g4n5mp06hrhLM6VKGkJPQta40lNN86wcvIisugF5LurDNI+teXTRJ6P72mSeoegVsVqQVBpcPlyDRO1SEY91K0NkJrtwYjTTz9L6Pusr9wnDCKyrGRYOOpKI3Y2J44jzyX9NEdIh7MpIqqRO4HwPfb3+4hSUq9W8GUVUytIhGVrP6csDXmRgpPkSQnGMD8TkXT3sM6ilaS0kydvqQSjPMczMDM1RXHIGox8n91Bj6lmhFL60MHdkqUZg2TEMB5S2hKPMQ9i2OtjiwLvEENvEAh1lLWbQLoEUwagJKmo49kqYnqW7lvvUIoIG8JIFfhFQL6qKIqStBaiUksx5ZFs7lMXM1CvUkiHJwVCGrScvAPY3t7GFOXh2BakcxghkE7hrW2z/YffpPedH8JoiNUW1e+x/43vU//Cc/hBiJSKQmmSMqKXZJRFghBQDWtUzeSkpY93bJJlJNKj1CVKe9y5dZXZps9cp8Vv/4//gLnT03z1F/9doqgz/g/S8dYPX+b1V17l3KlFejsHKAme1ihxqF+AHf8ZR+i+4uaz9D74NrWpY5gyRZRdlCghs3T3dtneXieavoAMHbFcpDvM+aV//1N89q/9Ajd3NYXTNEOPepBxf+CjlcPIAN+WZEdQSetNX+Ta229STQt8W9JpaqabmjguWdsrMcKhQ4+8DJFBCGFEgERqg+eXaJGR55B1U8ooHs/ytEaFFYoj3Kzmji/wx//T38W4jLSQmCwldYLq7DKmzCnLjCLPSEc9bDliFCfgRQzyDCPhxMIibRVw9oXPUPvJT7i2tkphC3zfIwwmF4Sab7S5fP4C67dW+fr2n/C1X/kczbDCMEmohlBTBVomBG1Nno1Y2dhjdddwsxcyQLAcaoq8QApLVBGUZQG2ZKFeoVdMXtxnIp9/+v4qHZXziRee5t1X/pjPHj/JsflF9vfPsLuyyhvf+j6yv0mtM08UhOzsFOg8pbkww+PHllDrd/CvfgfROYmcWWbr9dcQ2z1OVicvqp7nU1HjRJkmOUnssNZDyoRWp0VaWkZ9QyXYRyrJaGgoMstIOIa5T9uvY4oS5wybW7v4viaKAowt6I0mJy2Fkc/67ib1oEYyGFCtV8jLsSt9YRxIicNx/uIFXnjpc7zyrT/nxWcf5uBgRD7qU7iAGzdv8WAtRC0/QhQ1MAVIYegNJ2cCG2swdnzDT8qMxStXSFdu4D31NLZ1CS+M6BPT3OyTVSNEewrdqFJPM7LhEIlCLz9Mme4i1Gmc9klEQcVqnJ28uAs7nlcLpxCAsWLsHnTvLrd/+T/DKYdzElMYpBuTiVb/279P/V/8CUt/62+y9cBlspGht3OT29//1pgcKBTxsMf+9hafe+o3J4rjY0/egfLBOYy1eH7I5s4uWQ6L8x1e+/77FPb3WVsfkaU5nXaTnY1bnD6xQK1ewW73mF1YQqtgbEPmYDwA5y+cpCc4Qf0YzZNPEbVPUWY9VL5BOtimUrEMbBVRmQGviWh41GsXGI0yrFI0W21qiSHOUjxREgQaHUuUVpSAJwXmCDO86+/eZ7Nn8fsGLzcsaA9ERl7YscWbkiBBVxRRpUKrNUUxyPGEQRQpLneYRFEoyJ3BOYnUkOQJ2RGSlVaaer1OWkistCglCZVmYWmRzOYUzpDbEjvWeqQsCpTwMYXBWcHB4ICw1UCrCpV6h3orZ2enx7Fjx49kdKuEZWNrldwIdtfuMNP4WQbpCKE8qpGmFjkMFlMqBqOSsoTjC7OEoUdsSg4GlqKwVKoenrIIZXEiH5tUHIHZGGcZD0xJTjWbbN69TmdqhtUr73B5YYlhmnDm+CIblx7mlW/tIO/c4+HHnyRcPsvU/ALNmTmkMZRbN6hWwWabJPcPmAsTGm1H4k2evK21WFsSJ5YiA6UEnhbkeUkcD8nSAixUKxHD0QhrfYQGa0oiv0qZJ/je2CxBCYnvK5Qaez9G0eRf/TQt8HVAtz8aW4hJidIahcALPApT4qzj9u3bHD91hwsPPcxcENObKchGfVZv38Mf7FCLd5hdnGXXJvSLcXHVR7h4e8rDGoeVDo2kvL9OwwsYrG+ShXOIzW2qi1XiICUaZvjdAXko8NOcst9DNpq46DTdO6t0zjyECsFJQxoY8iO8H93uDvWpNqo8XOp7Hmp3j73f/BdjNUUjKISiaxNwjroMqCpJev0D7vy93yX8X/57ku1NNn/6Qw5WbxKGFWQQoTV0Zv6SSsLmWUamfZx1KC0QWrO506c/MLQ7FRYXZrj59i2Mg/v3dxl2WtRqHvt7PW5cW2H+1Bmq9Wmc9UB4iL9YGRxNaMf2qc2fRUbThLZGTc+Q9jeYCjzy6jzh1DJlVjAYlsw0UjyRsHJ3n2pjisHWHndW7/Dg8dPM1ufHCxvjkMLiH1FjJSxC8oGDXJLEBXYzpt4QCKHRGnRQ5czZC9y6/w6VKKJWEfRHOa4swAlsGuDK8ay3cI4Sh+c5hCxwR/AGdLhDHQ5BrV5FZjlGaHwgLzKKsiAvs/G4JM3GWjTWIozDGIsMA1Z2twh1yCADVIXdvRjfDzFm8k4ED5wuUdLD82B7u0dY9RAixpUCicDisb29x2iY4emQ0XCbSjCPMQWD0uGFIUNT4AmBNg5Pa4ZJPBZImvBslIKnP/kgQUdxbm6GyET07r5HET9PPYrY3NrlsQsPMNVsUcY9cutIhwPmZ6aYWl4CHHu5JC992joncEOqbY++KgnV5J3Ih3ooWWaRRPiBIYp8Aq8yLpwmJ/BDiszRbEyTxBnGlQReSFUH5GmMNSVCOJwsUVozGsV09y2Ek2fNKGow5TSb2Q5C649kIiRjTX15uNcYjIb8+Z/9a5595jnmzswzPReRFTO89o1/g+muU/U93MEGlXqLVIZkzjH2RpvsBH44vvLasYzG1pOXaegniAcDyoqC3OBFIYktKIzEk4rclyTGEA8HqGaFoFZjqt5mGHngOaJCYgQUR2Ca/6vf+R2e+tQnqTUahEFIR1fo/vF32f3BawyEZWQEPd/SnZL4QjEoHMcGlggJ16+RX3uXe3feJ+9t0Om0sQhUWEUEHq35kxPH8bEm7zhJQCh8r0BJSV5WUGHEqdMLmGHCTLWkEvm0gpDjHQFKc9C3VDyJSRPml08jZRODwXK4LRcOhGH81Z7sqPgaed4mvfMqqjZLGlVp+ZYHLzzMd773GsfaVTyZ8Nb7t7i7coXZTpvrhU+1McWXP/scYXCeYX/IB3dXma2fZOR7FDgaUlIcQeLy1rvrFD0F0scITVykuKGgFmpm5jv84i/9CtL53F1p05qeJy8k19/ZZXBQ0N83ZL0ClEb6PmVaYMVYce3kmSnKYvKXcW9vH4CzZ88yu3yMt199FeckK9ev4k83qVWrZGlCMRiQjRKEhTSLaVQaKOM4fv5Jvvmt77G5tomjjtVVBnHCcBgj5eRfzvu7fVoLxxgc7BMVPr/xD3+PX/rln+PcQwtor8CZkt39FC1q1Kp1BHDuhEbmA8xwQL0zizGW3Gh6pSMCFCVWJoT+5Dfe0e4e8VrAJy8/Sa0Cye2r5Nk19u69wMWzj9Jq1cBJFhdmqFeqCOkYDBOCQJMVhl6cUrn4Sa4mLW5deZvAwkzgeHi2znS9OXEcHyrSQYmSEqkESZriGUfoCWaWZ9Cexxc+/wt897vf5ctffJIfvfZd7mxskRdd5mZaOCTWQJIJsiRHex5+4CiPsBPROqQzFTJ3CItM0gF5URCEPmksCaQkLhyPnpjm4pljzJ2aZ3eQ8N5rb3HjvfeY2b/OwWjIhm2yuX5AmW6wPH+cpRNzR5KmbbaqZL5AazdG08zO0I1j9oddVGYp8hzPGiI/IJGSYWmI8xTpCaynCTJLiiBYOk7oDOTuEBRxNAPzVqC48sp3caaEyKf26g3OrQ9JbcLoE6cIF9oEFY95T6APXZf6W0MOrqxQWx3S+Du/TvjJc/RmA+rNGfCqRI0pqiJHycmfx8drg2YtxlmMHbff91c3GPRjkjilNVvFioC7Nzf53JMnyWLDqBAkpktvo8t0FI6XBJiPYDZ/cdThz2SnU/Ewoc9Ua5rNVHDn/m3OP/0oKtBcefc18uPzXDj/AAfdAwKlabU63Fw94N7mCkHwY156/hN4YY3TDzzIvb2CzFjywmKVI80nV43Lxg3tocKiwBYWHWiOz8/x5Kde5MSx4yTDPpF8AnSNtMwYLcwyCD0GYcywt8koKyisw9MKIS0OSzLIDt2FJjvD7h7a0+SFZX9vD6QkHmUYY7j6+k8498ADWAHpaESeJiRphlMBeZaC8nnr7RvcubeDcB7KE2RpRpGlxKOYfm934jjWt0Y02ksMuwlCDElGJW+/fYu547NMz9TwvIB2SxH4bbKspMgzssGI/c0DtjcPUOEcnoOiKFHagdLY0iKsHncrE56wPUXVV4xuvstQGPrb+2x2S7h2g6fPPMpCZ4qsKJFCYBEUZcFeb8hDp5YZ5gUb65sIT/HIhVPko5jd4YitZEgrrCHiHo9MHMm4W5VaonVBPBp3JeCoVSPAsrgwz+zMPJcvPc7S4hI//zNf5t/+6HXuXr9CkSdjAIAMyFJJXloCHEJ+aH4y2dFK4JylLA2FNYRBiFYeQkiU8hGeTyeA06dOETTq7A1GvP6jN/jed76BjHuc/+ynWDrm8czDz3Dz2jWiKKTdmuInb7xCUU5eRHxfoaKAyAspRUkyKgibU8xV6whnEIxRWpH3F3LIhSkxyuGcJXQChCSTJR4Wwxjv7YuxKN2kx1pHUG0jnMEEms7GgCLLGcwENB9ZGssnuw9j9tFKoVpN8qkm8VsryDdXmb63Tzl3klIHOOER6JC8zJlp/iW1QZNy3KKMFQAFi8sdZmerRJ6le9DHeYpGI+LmnTWOTVfYu7vP+n6fxXaA9nx6O2O/O/H/UBC0HAUquLZylyS9jpsN2e4lZCm0aj4UI4RNSOIBq2sbdHs9fKlotuu0B4atrT7vvbdKMtIEgUdYdYioTn1qDosEBdkRtvgm0FhbUFqDMSVSOWbbLV567pPUZo6zvbVNowY33t3gzXfvEDTgMy8u8/7ONloYjh+vstvL6Q4tmRWAwRhIR+WRnkfW2yG3hmFcEqc76KhKPipIipxkd5ebSUJlqon1FEmcEo8GeFEd68A4j/ev3kLrEGsluSkpy5TC5ty5fYdBb3Lcu/Zq9Po7nDl7jkbtIkI2WT65gNJNDvop1vaxaOJBH2vhoLvDnau38L0Yo2cZ3dgjoqS3u8njj5+jlCCsQuYgj9CJTJ+b59iJCtR99jc2+d6bO8Rem/ZuwsU4wUjJII6ZazVZ394jznNW7t1jsRkxPTePPz9NfxSD0jx0fJG9YZ/AX0K1OnR7/YnjQCiEsUShh/SAsIqzCucyRpljqtXh089/keX5DieXv4BTA+zA8u/9O3+Vn/7kGH/yx19HaQ/tS1wJxShGOkWJoDjCjdf3PIwxWFsipMAYi+cFOOeoVGtUKlUeO7tEuzPHoMzZ2drh9Ve/y0zoOLG0yJknP8ND556i3p7jsYs3aXRaWKV58ycvk5vJvy9aGjzl0d3eZ3+4QTlMePjiI3hhxNAUSOtQSOSH/Ajnxv24PaTNqLGDkLYOpcdcCE+AVApzhBtvZ26BUZqRZClFXlJPcwaqpJiZImiE2CIfG2kfFkrlKULlM5puwqOn2Llyl6XVLZozFfba0ziTkY328OoNVHNu8ucx8b/8/+AEQYgfhXjaQyA4e/I092fnCdlhYXmRVqtBlpYUwz533rtLu4Tnzy4y22qw2+ty4aFjFPkQIUKkSkCIsYOHK3GojxAo/2/nV//mf0KoHYU1DIYDXvneq2zdu8Pqzat88tI58rQgS/qcXWgjSkPZ26NqD7h0KuKg1+PKe9+k3mjxwAMPoPIe/dEGxqYMdI2t3U3gMxPF0d8ZUc9DjMjwtaDmBTz/zJNQlBSjEbK9yAiPO917DF2fjc2SV9/sc3p+mS7b3NvoE/qGpQ704yqb++PkbQt7JO6DiRPiPOXM8hInjy3xxg9/gLCWtN+l6vsM9nbYXF9FN9rIyhRre4ZqU3Hnpx+QZeD7NST+R9K4Y6l2x72VLcpichOETtTHO66QWcw7K4p4OGL0p3/I3PEGn37xEiIQeKpOUIZkecL29gHdq7fZTAv85gh38zaDGAqjef/WOtNtzcUHT7Iw08G6yWfNj73wDNeuXuW9b79Od/uA5mPP8+Wf+TKiXufqxh7tZp0iz1lQkpPzM+z2+lz41JMEUURW5GwlOd96c5XPXZil1mkwdXIRjCN37kg43jQr6dRbaF/SHfXJkwwpA5QX8eKLz/NXfvaL2NEBo941VPUMhSoYrr1HtTHH8594hMsXH+D7P3qd967c4NbeLlG1DtLSqvn088lvvEWWYa1AOJBSUJYWa8YjGE8KPvnIWR659CjXb26xev8+t66/x6fP1Wg35vGDOnff/j4LXo3AltRqVWwJOwe7eMZQCSZPQUKIscTq4gxzssHrL/8pv/WP/oA0znn2+b/KuQcv0Gq3iHyP8eXFEjE2hBgbuTiME1jnKPIx2iZ3DhEKRunkReSXfvXX+PX/4m8TEeFkQaJyhlJSzlQZ5JKpeotRdweNJYl7DDGs7HqYIuHsyWXSp0+xc22duXdv4164RJEN6e2u0Vj6LHH0lxTnHQQ+vh+gtcYBw3TEnY0N6mHJ4vGUsNlARgUiSWnPRty7v8elpSWyNCMrBbraZLi7TVBr4EchhzaYWMzYxCGY7A8vLaBDtPZoeBUef/xpQGKdQ1CCFeTWUuYJrrQUheGYKCkKQzzs8R//R79Kpdbk7K/9La7fuE57uolUhut3N1lYWpr4eZS2RFZTjE3RvkJHirv37yKWjmEOCtZ21ql12kS+JhsN2Li/zfyxE1y7u8Mj58+z0XVsb61SZCn7+13S0iKlGNtmHcnTU1MaQ2EthXEUWUE6GKBMgdCaaugTeIq94ZAkERQmYK+bIYwlCBoIxgw6aw61q4UYu4cIYMKCCmBsQqXapjETcrKuGQ1BzaY88cwDBFGXRmeWXleSj0Ysnb7ApScb/Ln5U7pbsLnV5ckZD29KsFdCtVVj8949Xr27zqOPnmVxbjL2LcA7773D8NrbdNIRwYOP01yY5/SlJ9lYvQVlxlxzAWNDytIwFfq8sTOir/Y5e/IE1SgiUglnOwGR5xPv3COonkL7ITZJcEcY7xkDZWnJipzRMCfwxwbICsHnP/M8gZeztb+CM32sP4sRAbbMyNMBSXxA4Hl8+tknWJib59pv/0t6o4TAc9RbIcpMvosQgDEpWmmEVDjjAId0Fu155IWlN0xZX1/h/gfXSbfvMf3oaSgyqrU6a3duc/u1b5OPUh77zM9S5jkH197CYTnC6P0jAwUpBUp5PPfilzh79hSvvvxd3nzzNfr9Lo9cusyZs2cx5RhWaOw4aQvhxjdyJNaNC4E5NL+1TmCO0Ilsb20RiALyEZ4H0kLqW6KG4ObND3jwxCwij+nHKaWzSK0wWU5QbdNLcionZkkO+nB7iNQ+nvFptWfIRkPCbDBxHB9z8g7QQUCgFAJJNuoyHKRkZcDe+gCcozU9TWtmgUar5PjZ4+zsDrh6Z5+3bu+x+Ru/y4lzJzh37hwnT52gWgnxlEL7PtZJpoKFieIQtkSIEGyOyVMCP6Q0BmUt4OPkeNnlPA8pxh+2dRYhBemoxmxVI7SjiLuYZIivWqBCFjt1Hr1wbuLnkRWGxAcvUugQjp1YwGnJrZUVzh5/kGI0ZGV3m53dPhcfeIBHHr7Mnt0j8AWPfOJzrOwkrO32SNEkxQBjHIGvsIYjoW+0lGNmnJIYC2mcUCQpngCBwZUGBbQCnyI3CDRSaMZIxhBr5KFEgTs0swDP9xBKopj8xttoRmh1jJk5TTPwuHdnh2PNJ5mZm6LIbhPnGcOi4GAY84PvvM+nX3qU8JHjBHMdvnLpc+T/+p8wGu6zunKds/4Ss7UO3YMRL7/8Nk8+Njmu2bcBMVXcw48SzJ+h3YhQgUZon6lmHaEENT8iTTOU5xGEHnFmODgYcKJWxZOW+SrkxpJ+/7fJjz9F8MBz1JeXEcnkuGacIM9KhBIEQW2MMLKGk8eWqVc0yXAPUwzBxgiTjZ+1FRRZRp6OKLIcqSPOnV7mi5/5FK+/9S693j694RArjgCtPVyaSgGeJ8ewXGvBWTzPZ2Vjh7i8yt7OGr2tu1RFSljvMDjYIxcKg6C7epPt3oinvvQV+r1d7t+9AV40XhxOeIRUeNriKYcRCmV9zj1wCVtK/sn/9lvczHpsrV0n/OrXmJ1bQOuAIlEYZ3BC4RDwoTMREqRCCsYEGzm5s5CvFLONCAqLFVA6gTcdEc00sNspOzu7VCiJ0wxTWoq8JFV1bm5ssXWwxVc/fZk4ECSmxI/qGCFwpkAKkMnkO7OPNXnXmk1qYQV96Chy9Uc/pqNhsaaphyEqD+neS3nn/m1q1ZBCBNzbKVlZ7xN6Hj/40Rv88MdvEccpSloqvkfkac6fXqJSrfHr/+vvTxSHI2d9/S5vv/kmN66+y/Rsm3PnHyaK6mPa6+EHXK+P9Q4sAq01nqdZXVvlieeeodpscOb8SR68+CBnHnyEXnfID37wMns7k1fO1kJIZ6mOyAWR9ri3N+TqB5sszzfY3X+DUESEfpXOsTOkheDmrVt8/ms/x8H+Hm9d3eTH71ynu1uQjgwVHSCFoSjMoXfi5Ml7MBrSmVvmwsWH2dvepTfqEUaCmh8wGBaURYEQEChNW5ZYA5tuGvwIaQswBbn5EAXu8IRP4IVIJTFHIAs1mx0GhSUvPfxSMkWNIo8o7NiZJdQw3Um5dt1w52Ca4u0GgT3LG1e2uZ+u8Stf/Q8Zdrd5Tlic12bUzSjWttj89m9TeJMXkZ/qaVovfI08GeEJwcnHn2aYl3j1Jm++c51nP1ElaFZp16uM8oLLy9NsrG3y9T9/hUEa87d/9ZcZjDJGDv7oJ6uc3cuYv/4jZpZOw4nH4PSxieKwVuAsGAtCeigt+NrXfp5Pf+IS+5srOJshnM/uQY96uQu9jNEAwoqk8A0mK5CRokh3+coL5/nFn/kkG72E/+rv/WNMOXmScDiCICD0NDhH5HuUh7NqpSXd4ZD13T3q0nLx0kXagcBrTHPmwhPcub9JT+8TNgYIt8ftd37AQXeXe3c/wHjV8Q12wuNJN/ZxFQVWOhySPMs5e+48pckpDWxvHfC7v/U/Y4zF9wMuPnSJ+YWThGGT8xcfQ2iBdYbU5OMCJEA4jTwCtHZvd5/O/Gn2D/bJB7tY35JMV/n6y3dZO0g4Nx1xatpjfVDSiELmp1pc3bT0EWx1S1bvrLLYbJB2Coo4JS0SQi059fCj1KdnJo7j411YKokvFdY6hHOU8YBqoJGiZEEU+L5B1n0CVyM3sNmHqs14eKnKXgxJVlI4QZkp6lFEqx7RrFfQrsBko4njUEoDkr/+N/4Gu5vP8v6V9wgrdYIwolqrjWdjxnD9+nU83+fS5Uf55je/yUsvvcTDD1/i2NIi9WYdqXwO9nfZ2Nrh1o3bvHftFo3W5CD7579whkp7mte++x693RiRQeT5lDj2BzFVKWgtLhDnIIIql5/6FDdu3sUVOa5IkULijEA4iZICaz5E4Ygj4bxzY1g6dpJqpcZKsooTgmqthshGxHGJlYfWdQp8WVITOWGZYYvxzqG049bTMvYB/dC/LwoqY6fyCU+aGLyaJfANVWlZOjfPyGlSuoRBCrLK2v2SbJSzcCyibzZ48kSH3NeE4dq4JbZ9Gn6FrNhEupxqe8jpz15ipj75+EYHAdaacVdnS3CGZrNGWWQ8euEcp2baeErST7ND9UVHa3qK/e4uvTjB14rluQ73t3fJFx8imZ1nGDma8Q7q2qvwpb82URzOGbwgHLuRBxHPPfMsTz96kWFvnTItENbgrGUwLPGCEaUpubq6Tz0oePhCDeXB9XtrGKW4cGKZ0vWZqrf4xS99iZd/8Nrkz0NpjM0oipwwDMZoHjV2tccZpADfUyi/Ql/41CshQvsMCtjoJRSqSugrOlXN6KBLtzvAIPF8B2LyG69wFinGptvi8IX0fJ9kOGBjY5N+z8dTivnOFBU9tjb73o9eJk2/TWkkL770Oc6dPcbMzCwz86dxhGAtpZPkR7jslFlGMDWD29tldNDF2pLtgwGDTBFGdQokRC2u3F6j6juCmRMotQvxgEhZtHBMz7YRqWJjdRUpM5rHFsl1RFL+JaXHaz5cMIIQhlH3gIpw+EJR6SygfUtQDwgrp1m5vYY32GKxOc3WQYY2Iy4uNXl3tUfFl8w1arSaNcLIJx4eEBxhlqhkQDxKSLOCYZzwj/7x7zC/uMxXv/JznDl9GuscSRJz9+4Kc3PzeF6E1iH9Xkya5tz64B6D/pC9/T1WVq7QHeSkWUljqkVFTv5In3r6IkLO8Pp33ieLc3yrD4V94GC3z6BM8FWN5ekFRsmIoFrH5AWD/Q121g4YHAwweYFwlijSxKZACA8lc9QRPD3rjRb1WhPtBSRphvZ8PMR4KaU1ZVmOnerVGDZWNbCkLKMyJXGaUgYoIcGYj3wa4zimUZtc1wSgNIKqNAQyJvIcUdUjzTRJv0ulbjnY7bF2L+ZTT11mWGmRmJKT9ZQHF2sUhUIWa0z5jkClQIqJclTFknoal04+nEtK0wAAIABJREFUNrFFzu7aKp1WHesco9EIcHi+R6vVYJDmaCUOjbQFpSkxVvLoY5cJfM1+f4QvJcvTUyyee4gBkm6WkZUj5quTdwDVaoQpc4QSOGn58heeh6JPFh9Aqcb7Ged4+527PPHkMkhFLzZU/BBkwPp2zB/8yQ9xKmD5PziG9C0mG/Dp5x6ntJOPTbQnSPsZwvPGUsDWIvTYfFcqibMl0jnK0tAdpvR7fU4/f4Z7ByNWVtcxeYoJLHNhDVvEgCHJc3AK7U+ubogosWVA6SxWAkKgsLz9058wVa9wf2OHRrPBIEho1ATKUzQbbZQcsd/t8er3vsFP39D4fsgnnn6RhcVjLM4dpzazgJCTx6GLjNnpGfZvXqW3tYO0Fm0NdVEQtKa4+MjDtBtVvDtDRknKylaf5x59go31+5iZLvMLIeHSNKZZwR3sk2Qx7tQysfFpHIFy+rEmb19q4HB5IBVRpcnefkaZC/peFetF5LtD3nr3A4alY6rR4ZnFGhdmJH69we1Bjbub72AKR6QFe9vbRFHAg6fmCaLJE8Xf+a9/k8+8+BTXbr9Cd/8ujz71JXJT8sd/9hrr639EmmbkWUm310cKwe/83r/FDzR/9KevUK+ETE01qFYjHJZmExrNOgepT2v6AaSafIb3z//3l1mcegA3lNR8jU0LspFhPckpeuBswVvXbnG718OVEPk1zl86S7r3AU8+doqbb77FwuIijXaDqabAGcetOxscm61Q9Se/SYTVBvfWNqk1p8mtJDMCLQRS6I+MdAE8L0AIgydgplKSGcVmAqu0kc7gCYdTGiklRVGwv79PrTZxGAhhaUmHl5cMRwWx6XEwGiICya2rI7oHhtPnH+LisYDE5mzvZ0ijUShybRkNBtQ8jTIJeR5jy5ysSHHWMDjCIijb36bMMxJRUKvV6O7vsbWxTVgJifOC0BvzCgKlCHwPIXzSrODsqWXqlQoBYzGnVq2KPzPPzsoKcVrwxs37nDn2AJ+fNI48Jww189MdvvLXv4Ird0iGBXvdIfWoTatRY5T0eeHzXyGIqqxtrjI9e5L7a5ucSE/z3/3G/0mj0cTzHP/5f/NbzM92+OznXyCsrPL1b3+T//S/nCyOSuijXR3nxprYig+NkSVaapz2oSzAgTOwN8jRU8fob1wZs3GVJi0V17djFk4UbN9fRUnFYK9H9ygdYpFSFAqlDgd0IscYeOoTz/Hss59hfWeTd99/F+0E050Op0+fIS4ybty4QRRFNBoN9vf3MMZy5vSDKK2RVpKaAXExeXE/98Ay91fusn9mmVq9hnhjjYuLs1x4aJkD22Tpqc/z3ntXOT47hzOSSuDTeeQRZKtOlK6zvNAklJpSlZxausjswimWLl7irbWUbBRNHMfHjPMev+hibHVNuz3enm8NhvRTS7q/S57nPP7QSapBge0eEClDWQ1R7RonpqZ44sFj3NnoUhhD6RxpnjHbqhFE1YnjePSRc/yzP/gBe1t3qFVyNjYzlBZoKehMN2nUQqJAcfrUOYJAU4lCfF8glUNJqFWrWGeI05R7dwW5hUJPkRQCr8wmjmMwSHh/4wpFlqJEOWaCWY01kjjPKYxFBRovKylGOXtxlzPnZqj6CjPsE0lHo1bh7Llz7G9fpd2qMdXwiHxDaSafaUrtsbOzyw9/9GOkknh+QDaMCf5vruVKaKwbt8tWGrCWQAmioEo26qOVxEiJc2NMvzNjhM6kJ9QS5UoECiElo+EQL4Bqw2PloGRva8QjT0gir0AiiEKfj1jv1hB6Ck9CniTIcY+HM44sy/G8ydvzfq/L9EybwbDP9PQ0WmsKU1IRgv2DHmeX5xAIwtAfq1q6sdzDfKcNDvxqBEIySjJOzM+zvbnD5q07dGYXkTPHJ45DKUUYBnzuxRd54qELbN1/jyKXvPradeJhxs/+zIt0Oh2+8Sd/xvFTJzlxdoH/45/9OXfv3GF1YxO/7ujMCEIPKrVl1lZ3+N3f+yOmOlVKOXmycqXB1x5OyPEoR0KWjQ07lFJI38McwkS1HO+HrPSJk4SyzA8RSJJenI7RFconTVKSeHikm3eSJARxTO5ySgxZVmCtxTkwzpJbw+LxU4hSIp3kzso+aQn15imstQxjqDZOghNcv7U/JttIn2BKkx5MPq64f/U6bniAygvmz5/n/vI8Vjhas1P0+zWK3GDjEb4bI1x8ITBFjlQBqVX4YRXnEmStTlKNyJsBnZk291//53QqF4DJsN4fa/IWwsMRHQLoBecvnOX+Wz/i4eUZFtuW2YvH0WFAd/UOdpjSUzmx1yArC2Y70wxyyfxMnf4gZW8UM9WsIq0lHsZ4R9CN/pkXLtMfdrn3QZ/AN5w/26bZqFCJQqp1jVYfOm6MZ5pK+EQVH8/TaK3o9fpsbe2yfzAizxRrW/tUFmZpNjT6CFv8LDWY3OJMjtQWi0LqYKwUiMN5Ah34BNUqnvQo85zd7XUePFEn7h3QaASkRQ4S0nQEVc1M00fLEelRNEW0T6NVp9ftEVRraCcojAU91lf/0BtEKAGlwOKQnkZ9uLk3JcI5jPDG+4zDz3dM5Ji8iPjSYvOMUemoNlooB0FFE/cHSBfw/LOPMOyuIWfncAbyzKH96lgyt8ioBhrtxsJFxlq0VJRijIQRR0DfjLr7zMyODQjKvAAJH3xwiwfOnGXQarC21+f0bJt+nFIPQ6QYj1CqUQUpBFIL3nj7Ov1hjBcqnnvuGYT06A+2sUcgcYVhyONPPMknn3oKNxxinObHb97iz77zNqawbOz3+eIXPs23vvkezen7vPSFp1lb26JSb3Hl+l2On5+l5pX4omRYxHSWKoziBKPAC48wJlAaLSWlG6vlaek+YgXnRYEpS8ShaYe0JQpDmuXkRT5W2yssWZmAdbx18ya+9plud+gPh2g1eVF95ZXvUHILk8UU1pLmI5xzFGUBUpBmBmMcvqow1ZqmVmuRlfIjMwalNFL6aO2jDoXthAVZdch0Z+I4Pnj/FvHGKnq+Sd4umXrhJTbe/x4gSDLHoN8j7vZoViuEQcQoTch6I4R1pAXYUlAWCbrZwnlDcjlEqIxatcCpyS9/H3PyHktJjXUEHBe/+FWS3jrx7haVQUha9BGBT8UPcbOzVBcXEZU60le4wlJ4mqm5GU45n+LuKqWzuNKwuds70oIuyfr88lc+xd17U2zv7dDtWaY7TaTy8byxhoTDsrvbpdfvs3uwye6NAUXhKIyle9Blb2+X/f01KjpjeqZFlJa0vDbDZPKHb0uNUoKo4pFlKaWRWCSFywln21TqNaanG8TJDsI3NKoRhR6x15PUlGDfKhiV2GvXuXSsQ3d7n4aGwhqKI9B9lReysDjH/Nw0Rijev30DrEUqhdRjWKcvx7/LQ5spYwxKCrSWlHkClJT4yI92GoKiTAiOoCkiixFhAH6zSVwalCe5c2ODW9c2eObyw0zV+zQqTUyi2B+Nl11pmh4aRRSEFY+038dXjlGWjQlfeYnnecTx5EXk3MWHqNRrHD95mvDQIaZSr7PX69LJZhmGOff6Qx7sdMZoBQFSKJyDrb0uv/sP/wFrd28yTFL+ype+xN7+Hpcfeox31zzi4eTjmyjw+drPvchgeJ9UKv7uP/xXXPtglVololarsbJ+wP/w9/8pi/M+oZ/wb77+DRaWmkgTkxpJWY4ovIgit3SqHqMwpzlVRSQWdQTTkMD3KcsSJUBpdShMlmOtIQo9SifIS4Pv+ThrEMOYt999g82NexRFjo/GUuIE3FlZZ9DvsrS0yOwRkBUAvlBkaXzIitSUCEqT4auSPB/hW01pHaYYsbWxzY6ENOmO2aFuDGMFMxZiE2OyjioK+tWI+WM14NcmiqPIDPkQvF6O++Ae9y43qJ34FKNvvYW8/BTvXbtKa26ORz7xNEWa02i3eOXVV4h7uzxx+TxGWKq+xgTLnHzwBSqBz/ZBxLkTn4MjSNN+vE46Hx2BwFDtLHDm0SfZfPtVdKDwfIlwAl2J8OpVrNbIahsjFFL6qN0+YRRSq6fU6w280MOTGpOlBNXJX8ayzJFurA0xOzOHlClh6JNmKR/cXmc0GjCKY/Z7I4wdq/YNhzGjUUI8GrC3dRclclpVwfzMLEGoCIOc4cEG5RFU44xzJEmK5wf4lQBdqaEJEGqfWrOJFY4k6dLv7tJsazpzEWaQ0+2P6OUFSe4oyxhsyrrn04giijynyCxHAHl8pPxXFAXK11gtMVhAkR+SOfwwIM0y3OENtjQGjcCYEnuIOHCHfqL2Q6EfV1CayYtZUVpsOXZuKdCs3tvj9q1VRvuGYwsNfL+PJxSjDLJCYaWiNBYhJUJI8qJAaA9rS5Qn8Mwhn8BkR3L0qTeaeGGAdVCtN3HOEYbh+AYnx+L7NU8zTFOiwGfcnlgK63j3xh1WXv82ibXESUKWJ8hRl3uvfoOpSy9i7eQdUZrlpJlGyCZxlvP+lZtE9dp4WapLvMAyHdSQMsMPJe12AyEMfuCjpKQwGWVZ4knFKE7JhcCUhroOx1yACY/DobTCCoeTcjwakuPxZ1GMOwlTlmMPVDPWGNnZ2SZNE5SQxGmGdSXWuUMbvzEpzPN9TDn581hdfZ/1PdCuxCAwVmBtgedL8iLBFIAQaC2QclxVhZDkeY41FqU8xGF3aA/1lQpK5i49TnPyqStJbwjSp59lLDYFs33B1BMvsvaD+7St4Fbcx9WqIAz93h5KOTxKZtpVKp6iFjXwM8hlgEp38WXAbKPG9soanvKAyYh+/z8lb4dDoKRi4aFPY3oDwvw+uhLwf7H3ZrGWpdd93+8b9nTmc+58ax567iap7ibZJJuixEEiNNjREDmmFMmRkwh6SGQEAYIgzkvs5MFAbCORFMGRFQlJpESJk0iW5YQSSUmcyaZ67uruquqa685nPnv8hjzs2y07MZxz89CggV5vBdQtrDr37LW/b631//8QEisV1lhE3MSgQSjyymGcp9PtspgV9Pt9LBbpBVnpkOHyn36/0cS4nDTPORrOeeXV65RFSl7mFLYeNiklWGRBbaE52edo9y7WFERRydZ6QrvZRStJFAa02g3ybMEoe524eXrpPLqrXYK1kEYikaFg88zTzMc5ezdexRdjrCnAKhqho5lkhIFhlkuCRkx2zOMTtiCfC27vlbSijNVmm8TK42vtcvH2FbjeD4ek12GyGGG9pzS2NiAKQmxZ1qo4IcBanHUYKxDCHePrPODqa7QQeF/UBlFLRu4kQgbkzrLwjv2dMdrC0+87S5Xu0whijFMcpYbUeCqh6lUz5/G2ZLbICbQGobG+3pBx1pPnGVW5vKKwqAxe1Va/xlqqoiRLM9Y21tFKs97vUlYVd2cLNgc92nGMwVNYT1pUmHSCJcAWc2Z7t1nb2ObNl77DqXzG4gQv1cl8wT/5/Nd56KEH+cZzz9Fstgjj2p/DU2BcRpx0qFJbQ0AcBFFci1HwKAR4WGQL4riN8JKsyBC+OJHvPMdbNWEUUNmKIivAWAKtyfKCtCjJ8pwkSY5vkPXvfzabgfMkcZNFltZtFRUQJ0n9wlUSZ5bPQ/qoXo88HpYKX9SmT0IjvccLVVtmeItzDqUVpXc4FeBlTbvB29pKOtAYLWlvb7C+2mP85stL5yFKixAal2akVYXfLylPaRJ6pLfuc+H0GgtTcOfaG9y9cYt+r8fmSputtQ7ntrfQlaMYTZFtw2J4n8B1keIUyuU1AWrJeJfbJtTXTCQ1DV4S9Aac/eG/xvyb/wNJpFCdLnY6wlqHbfYxVlDMFzgUnc0tcjEiPBzV/tcImg1PIBVJvPzJ6g9/+9c59/A2Y9fn2p0h1+7sYgrDbLrgYLhHVZZo6UgaU6IYkkjx0PmAQCmEaIHTtJptkiTi8GiHo/QIa6ESI1rx8t4EQZCwtrlKr7fG6uA826cepCqmzC5t8KUv/haDRps4iIiURekYXIBu5XhZoVua6qDu+ZUe7lQCrUPeMiUrITSayxfvQCuEd2glkEpz+bHHeaNMme/tkhlPlqfIKCEQkC4WBGGEsQVlVTJzIZls4vEYJP12m1anTRxGDA8niBOIdHbGGcJZDhcGLzUbjYj3feg0Qs2pfMWw0EyyiokVlF4QBRZny3pohsfhKKqCyhSYPMXnhjhoMJ0ULE5AjlFaY4wFLZhOprQ7XdrNLvNJymG0YDS7iQSSQPDK1WtcPneGqN1B5Dn3b9/jaFaStDRKxjz35a/ywU98gq2zF7nxp/8zzbUzwM8tlUdWOn7jd/9XiqJASs3q6gCpC8q8ROkIrdu4yiCjGB9IImGZTKdYKWnGkmZUtziSZpN5nqHihEBpYhlS5ssP6CbzGQKQi9ridLU/QKugZolKTZhYojxjMp1QFgVVXg8pnbWEYcSiLCitQQoJSpKVBfP9BZ1Oh+oErFXjS6wyGG/B6drT30NhDCpQrK70kQjKKkcpQRSFWFPL6q2zTKcTnHbMA8/Fjz5Nv7/KvTeuce2ffpHOCSAZCgnaolzM6N6YdpDw2m/+Mly7yYM/9zkePL/JdLTP3njGow88S7vVodVvo70nm0y4/Tt/gLq5w6l/4xnED13GuCGTdI0d822O9ioeff/HlsrjXS3eo9EYYyYEgcLaele20WgShJrGxQ9i9l5FFGm9P1szWwgbbZxUWOtQwqBdgZSWPC/Y3FqllQRMSBFi+eL923/wxzxx7xKqfZFb9/Z469ZNrMnBFzTDklZbEIXQbtTE9kCrd3Z6BZL+ygCpNIvZBFtleK+wLmawcoE4Wt7ScTFPOddqsrZ5gX5nm+nkDVoty97oZYJ2gLGCRjvGFwcc7udImlzc2OD+3k5NMxfiuP/sCRoxIkxAaXZGI8LFCYyHypwiT5F4gkhijGKwfobbR0eIIGIxy4nSnLVWQGUcFkPuYF465jbHBiUrp05x+uwpvueJR4niCJdV/E+/9RruBB4aWWHIXcLqxqn6pJssCHyB94qDuWJWWog1BQFOaIx17wyqHdRe3mWJDgTOSarKUhYzoqhBtlj+hDefL2i1mwghGI9GBFGECmL6vR5FmhPFITLUeKU5f+4s/XaLYV5x784eV1+/go8bNYzWOrLpkP07N2isn+XO/oxefmfpPDzQHjTQucAaT2kKqDLCIMSUHmskCoULPcY5GroGI3ipkBICJdBRROksYayx0qC1JNTqWKi2XCStZq1fEILKGvKixNscqYNjuXmtAG232lShZi4VYRijlKYoCtrtPqOiFvmAY5HOKPKKbrfHdLq8y6IyEpcXeCoUAVqEtdOh8HgcaTo7HpwaXGXJK4UU+pi0VXNdnVK01/tI7Xjj29+k2D8iEh53AjMgIY8xAoJj6LIgEprFZE6+v0dns0e326UzWEFFCflwSnVQUkzmTK7dIn35OklZMfnqqyw+1kZ7zd0XDrh26xaVOQGO7SQm5O/Fe/FevBfvxXdHnATd/F68F+/Fe/FefJfEe8X7vXgv3ov34l/BeK94vxfvxXvxXvwrGO/qwPI3f+MXfTMOsM5TOYeWtc1jbj1SJQRaEGiJd/WwxliHcaKmUwvw3sHxIpQWAA5razWXs4Z/6+f/26UWsYbDobdLTLnFMdVAeIuXCo+kqCxayX+h8dPb6KW1tbWl8vjtX/tP/NszB4/AHyvBAPLpLrbIGPTWONy7xSydE/XXKX0FosEXv/Ac9+6OKUpHmueEiWfQVDx4bpXv/fCjIEN+4T/9naXy+IFf+GUvjo32hRQEEhASJwRSSgQKcJxupBy++ip2tEusDU6FmKjLdD7h3t2rhLrkAx96GpzEWUezoViMDvnvfvf3lsrjb/7uT3pCCFSCtIJQWJpxQoji63/8Fs9/8wY/8qPfy6X39UBYJgdzfueXn+MHfvxRHn7/ACkCrPUIBJXJ62GpgLJyVNbx7/3UbyyVx9/4D5/07UFAWFl8anjl+i6dbsjKWpNkI6bIcvJxRaPXwCuNNR6GNd2p2YPb9xYIoSjzkrkt2NjoU6aA8ay2TvFf/J3PL5XHg+fWvRASKTRVZVlb73HmzDbdVptOt8N0MuVgf5+v/vkrLAqLEhqoULqGYZRlhXeS2uHAHYN2631+Ubs/LpXH3/6V8/7ff2yfiWjypettvpOepVoIGmrKjz1+wFf+JOa/+Y0jHvvQEzz2VI/HHtxjcrTBUw9sMR9H/C9fu0a/s83LL17j/o37fPQzqzz5dMb//uWCC2sb/Orf/sJSefz83/unPuj0ETqsoRRKEQiJ9gIROGLliZRgRUsGcUiia5dNiUcJT2UMzjoEFu0c1h0LzoylwvFTf/mjS+Ux/50Nv7v5fl6/57lxf4Vev0ccpXT7kkBXuLIgMRYrF/igg5cai0AojROS/mCNKIhwLqyRgbknHVeYpMeTWyWDx/7WUnm8u3vevgblKgfY2txdCIcUNX9RCF0XL1mrMIUU9f6mt8eqvXpwXNtBcix5lbVA5ATyZ/HPFMl/Pr1/wfBW1GKaqnJUxnL1rbdYG/RYG/SJo+D/NaU+iQwb+RfWrW//K97XSjRXZsRCIr1GE6IcFNMRutkAFSB9jNceKofyJU8+dJkL212aDYl1FnkCREmjEeNViJTUUm+l69zE29JijSnmbOkpb776p3QxBLYEL4hCgXISXWQYmTCfTYjbXRphQLsdMd1fXqSTlAGFM5SiQkpFIwywuaASGp9HzA4cf/h7X+SvP/TDKBFw5aV9lGgwHWY4F1AaU+8vC4HzAoRGOPCFPRY/LBfOWhpJgsMStSIaSYCzhrwqGTTazBcZ86ygu97Be0lWVojKEGhAO1ZWmhRFhc00oSppJJJYayaHC9JsvnQe7WaTPM+R3tDvJHz2+z/Oqe1Nmo0GSimUUszSObOy5PVrN1ksCqDejgp0TTcq89owynkwpn6OTiJYAlDzEfO5pdme8/hFzbdf8EgJhVvni1dW+bMXDxmZPTpJjzBd59GtZzlo9DmYe968OWdxdJ/p3ojRwYKw22Wll/PJc/f5/a+3aDeWh1NUXhFKgZQKKQWRODZQA7R0RFLQUJJeqEiEP/acCVCipv4EiYbxHTpHb5CUC9yxmtEWc5wA+OhSeTjZ4Po44eXX7/LNFxeE/j5hJyJIImbDI0IJW42IuBdBS6DjClMtsKaq4d7T67SbMRhPK5HkiwUmrVg5t8Ejn3ls6c/jXS7eFus9SkkiGWBtiRcg5V+crK07Boj6WvQhhMcfm88ofSw+OV7Er1V8/rjAnCCNf8mGzdvF9y/+jkAFIdO8ZDxZsHc45PT2JlLUSCUh3Ns/eAJH4OM8jn/u7T/5Y5wBgCsqhArIF3MEJbEyZOkU76YgU1pySuAEjViwdXaTZ75nC1M45osppYkIT/CBJDJFx6o2DpMBTscgj1VqHoQUTGdTQjlhsRgiO12izoDKOqzPkKklUBF4TbvRxHtHpxnTasQIfwLRgdOUztWQWK1xWYGTDiKPpmS10+Xqm2+yMngQX2quvfZtAm2pqgIQGFfUgFw8pbBIqfBC4LTgBG4BVEVBEHUYjgtyD42GYp6W5KWpDw9Ckpemln6HUf1dkI4wCHA2RwmF1vXLU3uHFIa4ETPzx1V0yQgiT5rBxQvneeDiGR546DL97gAhagastRYRxPzIZz7Nhz5wwNXrN/nWd55HByEIRZHm4CzeOjyS8+fOcObMGd689jpHR6Ol8/jAluONccLZpEL3YtZam1R2QWkct99a487tAyQwmaZcfWvKS9e3uXjhDLfeuMI3v/1Nes0AIwW9fg8VK3ZmOX/88gHr4ZRPPLR88dZ40AFCHnuVSIuUHiUlgRBIJxFOkhkDQhAIjTEOLUAdqy3T8ZCV3TeJ/Qx53DWuqvJE2EDtLHEzRmiDTBTnwiYLb5EeDiYFg8018jzj9MopCqWRypGJhEJWVMJhwi6lanDx/HluXn8F6wOq0NIPBIjlFafvLgYt0AihqYwBpdEqxLmSMNQESuEFVMaDlwRaEmt/7BXij0+FtYJPSIlwvIPdgpOdeLM8RwuJd7XsVwUSD0gn61uAEEzznDiOmS9S3ryzy+5oRmU8aeb42vOv8OgDF7l0/jTSmRoLdZyDPEEJl1K+49oncRgUTkgCmxGYcb27XB4Qh5ZWFOD8CvsH+2TZkA8/2uSpR2KQAUJ3cHadb7zwAlm+zzNPXiCbLf9w+t3nWBiJ9ZpGb42t9z2L0DFOaJT0TO/fILv3Am8xxw9Oo61hqxlQiIiCHtGGpHAlNgm4ePEU84M5K40mi+yQWJ8AcxVGtCNJKSSxVQS+wikICwhaESZ3PHL5EdK3YsbTCZFoMCvuM5z0ca5JxRAVBHgkQTWg2zzDSvcMg+YmRXECmb6IcKbEC4/V0Epi5MLijGU4LMgWFc2wh8khuDJkK29iN8+wfUqRxkOuX1sQNRJMWNDQzRrYWxlya4j18o9c5B0/91d+iq3tLZCGMAwREqoqp98fkOc57d4aURyzvbXFA+e2+eTHP0LhJDqMmU0mzGaz+pQehcRRTJzEiD9yfPvb31k6j8/fPEcSxWyVMbdfjXnr9utkVcHGWou9mwFnNjboNiSNVhMvK1597duk6RH7+3sM2hGDbpfTp09zMNqn2cn4x9/6PdKiz66J+AdfafNDP7FcHklxSKBW0ZjaAOxY2/FO3RW1r47znrIyeOvR2oOsF71FWdEJFfHlx6le+XLNe5W1utidxC+gnNDrRVSVRyQhZQ8avkG5kIigj6g0F88+RNSKCD2UxlLECaPhCK8CxvM5jgGf/5PrvO+RHpNqwv4sZzME70/yMnsXIwiC2p9OCipjCUON1gGlNQgZ1O0PXTvY1W0Rj1ICHHjhwYv67ziLVOoYMFr7FHCCN+c4Kxh0elhXU2KUAOmPf5HHJ/ndnXucP3+eIk9pRCFba6ss0pxmGGLLBfOiwAiBljVy7O13x0ne4P/cDcArBALpcsx8H29nVB6wgsK3QIY0ex06qwmMR7SaDapSZNouAAAgAElEQVQ8I6sWVC7n1t3rvHbtFhsbMZU1WLv8UXM83KHdXEFZw0ajy2L3dVa3LyCTHsI77u7fRpoF1s6ROGZ5yr237iKkpiEsBIJOFBG4hPDyQ+h+BKFi9/otyhMw+bK4IEQcy78haoRU3mMrQavdpNFp8dnPfpqvfO2rIAUfePJ9vPK85dzpS6x2z5Du7eHwaNo8dvHTJNEqgW5B5d85CS8T3WYDKT2NJMALmLqCtUZIGXlmRUZlHL1mh/JgRnFfYM6e5ePvf5Br+3dYiILVQQfnBUpLdKww1oOrUDKgzJY/WT1y+RIbgz5JFCKCkH6/TxCESCGJ4oBWq0EYJzhfuyjmo/vYoiRIuoAniSOioPZXL22BUo4qX2Cs/ZfePv+fcWva5+Jmjyt3S+6OhiTSca4DEbDx2NNs97q89vrL3Lt/n06nA86RzmdoKVE6YOv0WTa2t/BKMV5c4cEzF+id8kzfikAsf8iYHe2ycuYBlJAoWcMg4LiVekxxgvq58m/3WDm+0XsHZcEgDFDNAcYf2x27ehZQlMsrgYXwQAhCoiLHsJETVYqdG2P2h55YKgRN0rL2CqrCmOG4YDi0HO4dcePqDT74VJdnP/pxdnb+LybZEeNJjrCr+Oq7lKTDcXHUKkAKB9ScOXnsza2lJtA1s09SX3OSUGKlx7gat/V2e0IKgVYS7wTVsRR32dCdFSodgLAgLN5WCO/x+LqNI8CUBThDr92kqjzb3QGLNEeoiLgVIqSo7UY5frG/zQX//yl68kikLynmB+QHdzFpihWCdqPNtbtD5nnJ+5+4zEq/TxgnKKmY6xl+XFLkOYfDjNEiZ103aTZDWvHyBllKgKkyep0mZTpkfHhANd6jtXqGpNVmsn8HbUtkmRH5iluLBfcqT7EYEQhBpCAJNes+5ZE799m8dBpt6v5rUSxfrLKwBBMgHXjpqaSgsI5GELO2NeDiIwqpA0aTWd1mo+LDH36Gy48+zOOXn0S4isLmJOEKq62z4GKEV3hRouXyL7Nmq0KpkEAGlLlhlhaISGCloCgq8BKjc8xEMAk6dJoBrZUtbvz5dYyHS48GzNICvK+/x1LgvKPdbKHN8r+XC2dP0+81MRishUbSIAw0OtRIr9A6xPvaOjZdpCihwFaEtf0fGIMKaxyY0rVMPCtzhgeHOLP88zI43afX9SycYXZ0wJnHGnzvxZyjnVPsHEVsbq8SJU+RpjnNZhNTlcynk5r7GgYM1lfIqpLBep+vfuHrfOSJVaLWWQ56LzI7AaBaJe13inTgRQ0MlwLhPZEOakdLPJmF0gmMdzScw2OwyhNUBc0wQChBqQJCM8VXjsIrhsXyn4cHSpvh2jFqFpCWOcVMsViUCNVkPy35xpVrbF/qs3l2k8xpXnjhVcajFGk90gZcv3qVjz/7YXI8ViqSKCBuxMgT2Em8q8XbWE8Y1EU3DALSqiIrbG2U7zzWOJJI1xsnXh63NBRVVeGNQ/qa/uywGGMRHgKl8QF4ufx/+ld+7dfxlUFJuHT+ND/2mWeRzhOFCZUWeOc4f/khvFIgHOsbCU4otFbcvL/Dy9+4QpZl2MIwG485fWaDT33yE6y0krpPvGSI42te3fs2+PQ+Pj2kKnMGa+dI85yF8Xzg0Q3S2ZD86CYmUqSFIy0cL772MhdPn6UoKrLFDloIzNBw58UbNPrLe6w8fPEsO/d3GU0OkdEap3oJSo5J7x9we1rSVwIvJeF4whmVc6gc96IVCBJGVVG3GCrLW4lgfPUKf/V0l9Nbp3jpuQx/AuOhaWEpIocqK3IEY+rTq80zOmurNDc0f/Llr0CgcXhW1tfJ0jnnts6hi4StxhP0VzaJkhZKa5ytvZ6t1e+c0paJ4XRMo98hy6BMPaOyIux2KVxFvx1iKoF1JWuuwyOPrDPYXmO0c58f/eyT/NmLI6SWFJlDpJDZjE4zpt1sgm5SzJcfFoaNFq2GYlEa2t0VoriDLdPa5hawtkLECWHUIG6U9Fe3yUxFu9XGWE2n0artUJ1jns3esXe4d+sO6gSfx5rd44HmmJ07DaxPEMHD/Pf/R8TdHc2jp29xuH+PUxurDNYG7O8eECqJtRVh3KLZ6rGyNmAyXbA3vkV7vWJmh8Qs+Ngj23z6wvI3szODPlmpqGSM0yWxr95pc5pjH/maBm+RUlC52trZy5iYnO74Os1zmygvsO01ioMZ0ln25zmvj2d8/5J5qEqysqKYZAVWNojymD6r9FbbHIyPOHV6i289/wZXJyW/+NQP83P/5k/xH/8H9Qzp/u4hn/r+jzMZ7vB3/vO/xX/0Sz/OUTbkDbOHVqBO4Dr5LrsK1qtnUkq8gCBQtY3k8QTcO4uxhlAGxyfg2tDfeQiwVMbW/4aXOPFO1UMIf6Ke90/9+E+gPQg8SaiZTsY4UxHoGNVuklUl3mmiMEJrRRAIUFB5T+4qLl26hC0rYpXwyksvcvnC5drc/bgYLxvee7AZtiwoixlBeUA7EhgN0+kcoQOCKMbYgl6vQ5FEpNMFw+GEtCx5/OEHoaiYZym9VkAcHw9yXcJ8vvzLrN2ImCaaZpDQbMSY0qMiQbMRkaZlTU0RDlFVqCpH4Wpsm4tRVqFbA4RUWFGCEWSTCUpssJhNTuRuqLMQE5RgFaWHqnJ0lCYbz+ls9qHh6a30uXrjJpUzxHHEBx54mmYzJk1HdLtNGnGIda6eQwgPKBDqeMF0ucgLS54bHJLSG7qNJv04YVIK4kiTWsNsYvClYHJnn1MPP8L+/n22Lp0DkWCrev2sWGTEsaLViFnp9Vn4CumW33qZ5RXOWZqtDoaQZntAOgWEoSpy0J5QtQlUQG8QIMqcaHKIjhKkCxC+LgRSSlqtFsYYpJQ0Wy2G4/HSeaz0C04NYD2coI3h8I5m/zAnmxbcuj2h3wkJA3jgVAs1fpmXbox54qmPEKqSUGS40rFz8Cqv3v0WTg548V7OuSKiHd3k9VaLy0vmsfvyH7L+9F9CNjaxtl7dtbjjelLDII43HUAojIPMQUNMaGZv0vD7KL2GKB2+c4rZ4Rhjh9xJK14bLt+ukB6UNngL0gnCQrPWbLK9tc21uzl7B7doJU0eePpDPHDxIrPRFH3c7hpNxscrzxYtLDJL6WpNN4mIIov4bu1511aOddH1UhAFEVVV4ACpJdID3mGMO/aI80RBjA5iECX1bras1/ecwYv6kZRQF/Mlw1UOpSWtsEkSRxyOjrj51k3CMMHqgD/4P79AJQMG3TbNJKbb6fD93/cx1lb7XDp96vg6XaClphEKtk9tHZ9wFCeoVZh0yPzgDUQ1IwwErdVTJM0+Kl5h5/YukYprz2MlyLwgSloc3LiHVBG9QY9svmA6HOIQHE0MZQVlICmbmihe3iJ3Nh6x0q+5nM7DqLCMxlO8AKyvV5wChSlKXFniVUC31aBQIY2mJWp1QQXkixmIBZM0JYgljUaIUstT288mZ7g2ex1NC4cmqxa0jCK/kWE7DtUJsbLg4HCMCGp6UHcwwAtDWhT0kj55mVJWlnZ7AF4gvMM5h9YnAN2qsPYkFx4jLG2VYPIKKUEriQ4E86FlY6XH5YsXePTJp/jGH+3R6nUwVb1q6JwhK0siGdFpRbQbMWZa4sLlH7m3bt/jyYfOE4Zt+mvr3L23x92bVzlzZpONQZtWq8Xrt+4SNztsbGxgOj1UENXmYc7Qa8VkWV7PELyi5scKTp86xWgyWTqPV+5LfvD9Ef/6MyOeOif5+78rSScCUS4oqpi0UowXc6JonSc/8GEqdYfHL18myF8nNTmz8oiXbn2Bnekhp1c3WFSWW+ND2lXMwfCQH/nJ5fKo5je59+oXOXXhe4j6F7A0j9tnAi/tMdzco6VDOYVBEvoZMrtKMX6O1bPnELJe/dXtVezgFIup5Or1Ia/uLd97F1iEteRFRVlWiMqzM7pDmu1jEsX6mYd47MOP8JFPfIbTZ05TFBVFYRAIdnZ2sd4fL19YiqqgcCXtRkgUFKjguxRAHEiF8GC8RViHwCOFI0m2ee6PvsUDKzGxljQGHYJ2E4lmMltQIZDC1wNPU4F3LOaGKy8ccOahAd2OQp9gdfVv/md/F+lyglDy4Wc+yOlewuOPPcbK6VN854VXCJI+Nis4tX6Gxx55iO3VHi2lGd7YYX804trNm4zHY8qqoNluYY2nqgwfevYZut02q489tFQe8uhbDOIIEym8leCbbJ56lEZzQK93m8loRJZmUJRYZ5l4R+fsw6gwoLAFlbsPgWE8zXnt1qT2NZcSoRTlCYCqd29f48ypbYQ2+KpkkDRY6cTcuz8mOx7qtMOE/ayiHC9YC2J+4KOP8ubVG8wXBaqdcDieMPIlp5qacw+cw4qC0JWcANhCt6sZqAbtosFGe507b15B7x2g9gWTN4ZcOneJ9Y+0+cY3nmMQrvCJj3yMhx96mMVsjgCs86RpymKx4PEnPoCp6kFUECdYu/znITy0mhEZlsAoJvsZN/emrG12OKU6iDAgH1se/cSDjIYzfuO/+of8tZ/5AY4OhiRhRaBaxJEjCmNajQZRpNkfHXF4kKLK5W8AX/rq8/zVH/tBKgxFVXLmwjkOju4RhRFnH3wMi+McITpqcG93nxuvvsFga4uyLFFeUlpPq9sjz3Ioc6QMSdoBP/3Tn+P3f//3l84jnRb8g3/kubhymq992zAcBfhyn7KYEPZjxpND0tk+57a3eeiBR/n4Z76HyhjWLj2Bx7A3vo7xMdbBlVu32V4ZUA0to8gxFytL53F9NyWZvM79q1fobj2EevDH8UISURHrYymZNSjviYWhww2++tznSRoCaaC79jCXXICxDhsFbH/iWVZWOjz/K7/O8I2rS+ehfInNc6qFQzqwpzLGcsrIx7TdNp986lOstbZZHfRqRJ8N2bl/m7LMeevK6zz64ClOndrk0vmLFPYGjQQSEnS64ARo0Xe3eCtV72n/xa42CKFI04yVqMFKI2Y2n3HttauEYcxg0GP9/CYj5Vj4inYQQxRgS4GOHFEoybKCTjuu+YpLxsHdWzzxxEM8+r4HCCLBzddeoiUs+4c7rHR6/KXPfi9SSC5dvMhweMSNW1e5c+ses2nKeLFg/+iQIAgIowArA3q9Hv31NmHSYJ4tf/0Km118VRdMKWqCDFKgGzErZ87SXdskW6Qc7tY0c1vmLErwzhEgiKImccNxcOsIrxPiRCJlvfZkT7L6JDUHB4cUaUAjjghURZAkNKKAaTrBGDBYJkIwz1JOu4xnu4YLax7T8lR2QtrNWMgZRdLETCeUY8lqP2Jxgin+/mQfbT3cn2C0YHUiWBwuKFKJm2bogyOilZCzF7dYiVY4d/o0URCQz2copZnNZrUlrNZYazDWYkwFlToRfEChCUXA3NSA3aPpnPncsh0pvHFkU0cxD/n2869y4dx5Ll5Y49JHfoD9b3yZoKxtWn2laDYSlJM45zHGYqynzJcX6eweHPL1517BBS2eeHKVs9sFjz94kW5vQFFZhFT0+wPSoqLRaOK0JEkSrLE460FKsjxHyHoKH8URMtB0u13Onl0ehJwtQoroYe4dnWVnusNGa8T6yiEbvQW5DLlyV7O/n3P//j3WV1aJGwlHh0ecP3eWyfyQPHP0el2G6X3KQjFfLOg2E+Z5Va/yLRvCMJ1PSUJFdnSLaH5EEQ4wvsIqGDQDYml5/GyPblORBAH9fkir1SIJW+SqYpIWRAjQIcYrKie4cvMWTi7fzhJ4qur45h3ELKoprYbGGwg1LBZDVhsbNVuzKLDSMp4ecHS0xxvXvsPjT1+g3VpldW2bg7t3kThCr0mHE2y2/E31XYYx1HvUEsHb/QUpBVGjzWoLmoEg7jWZj/cx1YLDvZTpaEx7a5XGRgvjHFopolBiA8+5jRZ5tsD7mLJaXgxy783X+Nm/8kN89rOf4o+/+HnWBz0SLYiF48Gzp4gbNRlFasnuG/e4vb+Hi5u02wPW4wYXyoogDFBK0ut16XTaKCXY2d0hz1N4+v1L5WGdR3mJqDwqUEhVq+K00iRJA6cTGlGLdneNyhhMXjGejVnMZ2SLKcwkt++NOBiVZFlBEnjiqJ4juBP0eGfzjHjQZbrImKUZiQyRwQQZdBgfHqJ0gux0KKQkU4rY5kT7t9lIj5B5gSkM3nsW1ZCj0HKUjwiKNqc3u9zdW96vuZKedhlhjsYcLfaJvaHKcqxOOLO1zd3dXWTQ4IknH6Gv+7TbLUxZ1Qo7rZktFoRhSNKIsdZgrcHjKMtaxLNsaBEhS0k+t8xNjvCeZlRzHGdZxs23DGfWTtPrdFjdWOHyVkjpQ6bpEePsiHLURIqQUCe4qqAqPEIqirzCnGAg5QT8vV/9LTqDDX5Ot3hgq0eoFGmeoeIOQaSJYsnO/iFlWbF6aos8zQjDABVGFIUlz3MEAqEVxjswBmsd3W536Tz270/4iX/thyjSij//9m1+4Wducqm3T0t5fH/Klb0z/PI/dByOD9g/us+qHzA82sWUOUU2xxQV6XxKlhW0+31skTKaTiksNHvLF6vNrQ77RwWmLDDpIfLeS3DqQxRS0YgN62s9TObZTadMqopOrNncephmpPCVJwgrjsZHdOME7SUtK3G5ZedoSFYsf8jwCFjkKJXQ6baw1ZgoiCmKgsBZZpM9kgtPMh0d0umsoVqKnd1d3rz+PFG7ImpoCluA8EznJUpphCvYaCUIu/zz8u4Wb+dQQhOGAZWx5CVce/Umq/E13nf+HNUsRUrN5rlz2LLAmorJ8Ij7Vw7Z+1rGmcub9M9v01zvk96fcOnCJe6++TKHd49YObe5dB7bZy/zzPf9IIeHJe97/6dodNpgLTi4OxK40ZzZdMreaEpROIRcQ0vJjdu3ETqg1W4xmexydHiI8BVCOppJwmZvUA9LlozFtMJbR6BjbFmyGnrMfEweJYQ6wVcWZYF5gShK3MGQ9izDLmYUZc7O4R7PvXqV3UnJRq/LbDaizA1FUaPjlo1upNg7nNBtN5BSYKVDWQPpnH5vwPBghJ9MUHlOFCdYB+OVR7heHjIdvklETeERzZg4y0jigFA6MJYT1Coy62jeW5B4gQsj5mOI+lsMVlqMbt1EVxlB1eRjz5xnM7lMv72GqTLiIEQHEmcq4laLQIWki5QgCGqkR2kIwuVPVoOoSZ4ZytwxTw1za1hrNKGCdG5x8yZxIvnxH/ooK2cuceXKFb725f+NF178Y5yKub77Mi2xyumV0+ynd7l7Z06gPSoExfI3os31FaaLkoODIb/69/9rPvvJ72VjsEan1+EXfvGX0Crkb/zSLxI3YoIoJI4aBEFCUZaURcUsTfFSYo0hOQZJS6FwvqDTXn4GkO73CZ1nPNnhg483WVvfQ4Wau+OKX/u7ffaGhkUmiVpHfOGLX8Jj+fm//m8znI85GM148/Yr3Lx/u+bSknD/9pjx/QmN1ZhWZ/kSNN6fsjpI2NpeJ60Er73xJZpVRbzxYc5d7nOwSJkuCopb9/HzI555+Ayr55vkswnNWHNwf0gjDJiM77DS6NFZJHjr2Oyt863nX1w6Dy8g29+nGIbYbEbWKcmGGbEJUQPNwWKfO3tXmezs8/CjHyKqtuhi6M2GiG7AcDwlCAyH928RhTGL+ZwkiVAqwpXL38ze3eIt6w0OvEcLQVWkrG+vECeeaRiw0m3WsnAJJpCYAookYgBUpuTPn7/Oyp0Rq+e2eWijw/kzPdaaj/KPv/QV8sXyq3E/8bnP8eIrdynLitI5jAuoJTI1s7DeovLs7O1gTIZ00IgThkcLUIp7OyNMlmPLknYnIVISZRR5npI0l99bLUYZLasIvUVrTxCmVIvbzG/s0tEhlJ5sssBmFltVyMmUeGFpWYPXsJjsYmYFOMUinRFFSW2IVBr0CQZjWys9pntzAjyNQIK0IBRZJnBKoMKQvCoIFbhQEBSGlw4mfOn6DsW4YnW1TzHPCJMuH5O7rLQErZYgzxzjyQm+jGPLwet79OMWWZHjckue5iS9BKljWu0mca9H4ScczPZoJH2EtTgMtjTHUFmJ1iHGOrSGqqzwBO9AlpeJvCpoHHuH6OMNKS8FUkkWU4tZFJx/cJXe1hqFV2gV8aWv/BNyUjLjqCpPJjPScsYgXqfUKRk5WueYYvk2wdZKm17HMx0vyBY5f/rlP+HZjz+LlZL1jQ3iKCEtSiwwGPTpuh7TyRQnFZUtCXTIaDbBWEvYahEHIUVRkKYLqnJ5xelKL6a30iJiizwb8vwLKxQ+wAcNaG1w9/WbNEKFVYYwTHjg3Fk2N7YQShEmDbJyhLEO6Qzrmz0mhxOy8RwtFK5c/ns6TRe01ltU3uGdpd9pk5e7+PQmhWlSVGUNeDYFzSRg5/ZbZEc7oBXTbIExlkYzYTVxrMcdXFGxM9phbX2dVru1dB4Ch/QOrRxZkRO5BpUtUFGMrUqChiDQAfN0j1de+yqPf8+nuX1wi6u7d0nyBlEroCgnRGGbMs9pxppER8dbSt+le96C2ovEeY8UgjCSqKCBwLA/WdDrt2hHAXlWIESINxF4S9IocRJu78+YjCa40vDxR74X4SrCRkIrCBjuHiydx/MvPId++Q2UCtBBhNLt+kENJe12mzCKkGFCJ+wjoxaVsmRZRthoUKUF+XyOqGqTmdkiZTEraISafmeVExzwkHuG7SjGlTVzr5lOEGaMryzOSXxeIUpDJDTg8c5ABVpKAgHhqGAtSMido1gsqGLHetQkTBTmBDil9X6Pw3nFRjdG+xIVaByK+7nDCE3cahGGEi8l2lsC7xgd7pAWc4Kkwe4sZToaEncEsiXYXF3F2wKpgn/Gu+X/O45e30feK5G9ilE2Z2PQxpiKLM9pr28RtSKIPXniyF1O7ksaKsD5ksVigQ4jCmPIxxNa7Q5CGoqyImlElOXyswghS4KoiVJgXQXCY70jSiS33swhU6yudHj+5RfodDe4f3CP0UGKbThs6egHm9hSMZsIFtmQfr9NEDfQQUoSnUAsFAhCrWnGPbKi4Ctf+RKz+YTH3/cUH/3IRxFCMptOWblwDu8cOoqYpnPyPCdPM0xZUbn61nF0eMjGZn07rSpHGCx/yPjpz3ToJp71rQE7w5KvfT6gbEdsXO5z8YENrrx2A2sdIRHnTp/lw089TaAUeVkQKcHCjEnzHBVGLCYT0mrC+ce3OdgZkp1gJqLjEJ3EbJzaphVqbDVh6+IZXNBmvPsWO0djihL6gWB9e4Ur33qVUAlOnb8IOqbZ6bKwFTLbRUeel964wtef+xa5jgmD5ds3eIFWgu1zW4zLJjujXVqtNq1Ok/TuhIZsY0uLERn39q9ydvoE0yJFDJpM0pRGVGKNJ7EZo9mEOGwyGQ+J23Pcd2vxls7gPURRA4SjJw1lZSgrT9jv8vzdXYrFEKMUznuaYcQHz50BU5F0xoRJQqPdZG1zg3tlxYvPv0SFQ670sSc44V298i3u3rjG5rmLaBFw9627VLbEmQLvHMiAMFmnCgdILWmECbEOa1OhSJK0ApI4YtBq8swTD9CIE4p8RqIz+s3l3+BPzWOa47wWHlkLJkUi0FK9Y2BUT9BTrDMIb5BCo5WiqRSPBE1eixZMijkBkrIsyYoM65ucAB1JXlV84Gyf/uo609kEdewfszs64Nr1m0yLCrIFZZrTxfHR7T7No5t80EpmtqDAIZuWZrVDJRuM7u0xTafgQ5rJ8l+x2y/f43yjzygtWOSWuNUk0TFR0CSKEtbXVrBiwW65QMgDDiY32O5/AC1j5vkcaw1vXLvJxuY2UbNDlVc4B7JIKYrlxSCNJnQSRSY0RRYy9TlCW+JE0lAKowJu7L3FWsPynedzjoY5Qmt0qogaATtH9wjDgH4wYPuhkNhbxodHVBNLWS1fvKNGm0AElFVJkiT8zOd+nkuXH+TmnVuMjoasb2zQH/TpdrvMplOkdfyj//G3GQ6HOO/5+X/336G3uor3nt/5rd/k2vVrfOIT38+jjzxBrJcv3j/5zNew7mUqr/nZT1b86MWUr7xQcst9mD/7s2ucP/8InU7EYw88SK/To9lo0Qp2SeQt1no5g42EzcWANC249foexcJBU6F9F2WTpfNIbcULr9/iyt17hEnIz37uv2RzaxshJJGAioB5uiDWihvX73DpgwPmi5T9vMBWjmDuEUby6miP68PvMLya8uIL1/nM9z3LX/7Up5fOA68xtiJzBbLRpCu6NFsdbGbpNwVUtfXHG/euYYXlxSvfQBmHsBVpVjD0M7yX3J3OCEPJeDRBVjlJWH73rgqGWmFtjjWgdYDSIYFX4CusTWl3NYtUICNNnmZMhymvSsFar0e70eagPMQUkpu7Yw5ndWNfSjC2VuItG75KCUJPZec89PBjtAPP/tEh87FlNpviTE5Td+mcG3AwHZOVC0qbEwUhzSDg/Noam9ubXD61QcMsGA4PUKGk1V5jZaW/dB6dqkI4gTUOaR22MnglqbDHgp9asv/2f9SLCO8ExgtK62n/3+y9eaxl2XXe99t7n/nc8c1TzVVd1azu6kndJJuTSEkmJUoyHY1UJFiKYEeGnCgJoBhB7AAJjMAyAg0xMiGJ4ziKJVGyZTKUOKhJiSKb3Ww2mz1U1zy+qje/d+fhTHvv/HFeVVMUY93nAG0JqFV476HePfe+dc89Z+211/rW97mCh5szbI41d4pRyRuzz7B4/3kTmDE5YxOyt95CW4PCMDPVINVw/MQJLlxfZdhu4ShFL80ZGcn03DS3bu6w183Jco3VBbEvOXPmEYTV9NIEbRSSyVeRhvRpxJJeqjFjw+bmHvVAUY00SZ4xHQuEq/Ap8N2cRO9hmg5ZYYmrTW7fvkWWa+qNJlYIiqJspKqiOBDxUKszZnGuQW4gVB7LYYOW7ZUEU5nLwnyT4WBII09wKoqqLNjcHVCre0RxFXdAWUozUIgc5YaENRc389ne2Z38cwFEanGtgwwE1uZ4rsep46c4/+rvI7EcPf8iKnUAACAASURBVLaMzlNsntHttsnzPmFgSIucTneP8XhMnhdsbd/h0LElDp84Ri2u029PPqTj5QXKH5A6FaTrMT3b5oPPOLy622Osv4dGYxo3MIhMobMe1bkLHIpeR7l3CaZT3t17F51eg8s3Nhh0x0R+yO76LtP1YzQqk29VzxyeZaYyhRc75Nbh66/fwb/Solav8tCJFaQeEHkOr37jKnutLrnVGKtR0gdtkSZHqoRRmnAj6RAqj+lGlSTPOLWyNLEfAI7roGQ57Z0MRjjKp98fEiQudjAiGY5JhppROmJdbVA1VS5fWCUDvMVin6J3jBe4JIVE6JxeKhDu5NjatzfzxiKExOQpaZHiOi5CCBzl4NgBKpbYuVl6owHVasCuhc00p98b4ZgxL9/awAYDDh9Zvs9xIKSgGkYUB8A1763fZZyPGd1ZZUq5hFYQSsNYlcB5hGU03uXX/+7fYnX1NnudNuk4xZGKUFpOTk+h0WzurrI+2KM2N01YqzI1M03lAF381iin5klG+bCkp5QWbXIsFtf1MBa0llg01mqE45IaRS4FA6l5bdDmZk/TTzLGyuDqkkrVcVwOsPtifnaKV28PWdtpMzMzgyky+vmA7ijj0cdOcG11AxU46DxnhCEzFmdccDR1WIxCimJMoSUGja6FhIFgcXGZm7dbVMLJt6OVSg1jchzXJdNd8swjKRICk0Km2PE08coC43Yb7Th4My4vvfoyD598B3ONGo7rUZ9ewAlqjDNTihAIkLKczJ3UBklOt59jpYv2FAsqYpBoBnuKbCixc0OGQZ/O0KGXWVzrY/IxRSFxpCHwQpSWSJHhOAHay1CRz/XuXZIDUOTGtQaD7T5h4KF8gR8GSCVRUuJ5TklM5br02h1G/QEXL19kenoaqXP6/T7Pf/GPcV0fLNQCn1AKRu02G0nOxQuTN+i8CqAzXNPGGp+h9TBRQXU+Jz9fYEnwnSqSjKXluzx84htE44t4joPpFTy6co0L9YKrhWWqVkWnlr3dLi67FPnk18fpI4eYrdTwXTBymv/9xRs0pmdodzo8tSypp5uMMoulShCEGJORjIfo8QCbaaztcfn1L6PiFGrgK5hdnuL2+l1agx7/xaSOCEutUsOxlkG/S+S4jPpdcq0ZdXNmK7OszC8y2tX0x4Zd06W+MM9wYHFiD8d3SLIxCE06LigyUU4GE8ABktC3GSpY8psIKXDRjJMxmALfFWhT1nLroSVwApTjMt3USGEZJyOMUXzofadZ30vxA8mh2XmMsWUzSRfYAxDcPP3+x3ju018CBBfffJ2aDMlsQWI1WIODIEt7JL/2j/iIDEmspePApk24lo74jKepHlpk/tgRpo/P4/gB9akpwvoUOJNfjL/cavH9lWmW3AZCFxRWYPMczxTUSzoikB6DvCTzSlPNdkWQeYJ2IHj+rsuddEgrSwiVQKAY9BN2djIEk6/ga13F7VbCOBOI3piHT5+i126z0R6y/twfMUgtx5ZX0N0B4aLAHe2x5Di8oXe5mPtIXZBqwbwQvKu9w3VVQcQFcRyzsDj5EMa7P/YT7Ny8QrffY64+S39zA+t4+FGMjEKGTp1RGvHQsbN0W23SxPLcH38enSeIPMGt+Pz2732a2fkVnnzyCaIoZGZmmrmpOvNTMxP74fkuqR1RrdS4s2q52x4ze6jC3iBHypRbWzv4WuHlc5gMvKZlMCjwvTFU6kRhlaxTMEoLRq2CXr9HXVRozDUYDievvU9XA440I5S0RPVZFg+dZGQyIuEQhC5nz54hdF06nR7SWHZvb7G3tocRGuUoHJ3giKJUk1GG7u42X/ncZ9nrt2hWJt8hoiXGl/ihi8lzssUpXn4t4/nzktb2HXzHBy2IGoL1vZc5vrRBPs4JJSiZEqnbPHxkim9csXQSS28wIGzWUHGPtduTn4/1tT53RBdHOIxFynjtCrXiGG0T0310hmTQY2Nzg3/yq/8jD73zr/HIO58lkgKrclLTY2v1VX7gnY8yysZcunaJauQiY4lJB8gDlLMQOYKQyDhoLbg7GJFlkmErw45D1vd2+ZV//KtYoZmuhJw8Os141MUNoDID7d0tPKEIvABBSiOWNKuG5UM58gC497c1eGeFxY9dPEfiCI3IUrSWGFPy7UqpkMoSOT7WWjzl0B+NUdJBSXBsQSVUJf+3FJh9ZsHCqgOVCWrNKaDMxYyFoSnQVqP3t/iWUqlnuLuD9BuoNOGrjLjmGIYVl5VHzjI9O48fR6TW4DuqJNFynFKybUKTi6d5A8FWXMHJMvwkR6kRDTFC13NyB7SUbPctIgfPWvZqLkMN24mhunKChxcN63dW2bhzG4smCB1qtYA8n9yP6+sdKDJMNiYbW7burjI/v8Bjj57jy3/yRUaF5HYxpipcXF+ii5R8fY0zrkNdCaSGzBhmrGbv7k3y6ElcP0Ag8ezkNc3DZx5lanqW8XBAq73H1t3bCF3gSgjjCmG1SlCbImysENYM3WGX97zTw5GSrXaLmWiGJ586R5Ja1tfvIoRge3uTztISm5vbPPvYMxP5kSYZeRHQag1Y3xwzX9Nor0KxK2g2ffYKB6st9WoFP7Bs7rSZalTxHMiLkrceT2KFJi0Kuq0RUVjDq2ikM/mWqBL71H2F0CW6YXd9DccTbPY7hJFPkg7xHInvuly9dInbV68hhCDbZ8ZcWJwmiDyGwyHWt0RxRJFYWoMeyQFYOHUB1mqyokRiOTJntqGpV/o8f3cDowLmzBRuFGMqgq2+xqQumQYVebSygPU9SY6P42qOPXSEzd1eeX34k6OArIkIPQfl+ggV09rcprc3ZpxI1p59H/V4nq2kx/HFJuPuNml3m+31DXqdLv3OLuPuLU4uTyGAD73rvfvMpWJ/CnJyPwTQ6Q9JTZPcuvSGu6SpJR1J8rHGdR2yPGd+yUHKhKrbx4hVnnpsQGPWJ/YEs02HSgUWpmNqcUEt0tRrGdWtyctqbzO3SdmAk1i0Efiei7AuWa6BANd1EE6K5yiUKFDCMkwyXOXgKInWBUszEumE+/Jo91R0TCnwMKGFQYzrSXRusAIysc8HbkvNSiNKPclL2Yi6F3Ip2eLLkWXq0DEWjy4xc/wQ0ghya/CDGMfz7qt7yAOQm0QrD2Gzgm6hEW6B445oSJ/KbJPU7iDjCsp12LrVZdDTuNKnjUurm9LLHSJRcqscPXyUO7du4rsGzzdUqy79weQ3Z1YYtDYYC2la0O0NKfI1FpeWeOLcOW7eWWNrd5dOMqA1BKkKVoYF/cICGdYalLWMtaYjA3qdDJ16xIHCG03+ufhRjWA5wJOK41ZjTUaRZ5isIE1THNdDSI84irHGYLwKZ07GCCwLCwuM8x4L84dw3YhOp8doNGQ0HlNkKVuD/sR+5GnBtWsJvg1ZaIY4ToLMBVXfpRZZ0jwklwXaWBxfYR2Yn57B2AJQ5fUa54BHUViWF2PqRGwO7xBXJr/lUivop5JYOqi04NUvfR7PEVidMHf2SVxPIaQl1xntdoveuI8MPQIvoNvpIGTBYDCiyAWOcBAuOI4lDiLcyuSLaqILHCkwiUZ6DsJzWDnk8oQJ+d1/naCNpjPoM28aWHuG16+2ORxIensFhYx4cUezuZsDDuMiIbZVfDz2tneJ48nPR6O+iO8phLKMCnCdJoXOkE5KMs4ZDRPubOxw6vTDfP3Na1x99QVGe208T1KresQ2orOzx9GjR3GUuk9mZzA44iCh0KINLC7PMRxpzpxtstfeoNfuo/t9AjdjekqweMgjigNq1SvEtZRKtYZ1faqyQpplDEYFo4Gm0AndUU6/43Iq/0ta83ZdByUFuRY4rsJTEovAmALpSApdEHguVkOuJQWa+dlphL1HHeuBKcgKgxIeWaZJ8jKTsQeoJY6yIYdPTZOPc4rcMCoMVlukASlkSeTuuPxx1XKlbpg//QjvPTpFJVLEYZPtosC4LoHnEdcqhHGVuFIlCIID7QAcFTBUGalTlkecFE4+/BBH3zFPXCnIrcdeT3P55tegESCLPiIf4dYr+JlhqD1sIfCE4umn3sONm5dxlaHu+UTNyRcRrfV9dscsKwDBeJxw88Z1jh49xqPnztHpdnnppa/R6fS4MvS5PNRIGeMIixIgpMR6Hu8+/BBalkLAa52E5AB44loYI0wFbCk+nRZjlDD4vqTSULiOg5KqlMOTgubsHKdOeoCDdBRCJlhNqcHpCLI8J88z0jylO5gcjeQmU5x7qkYYhXz55etI7YJ1cJspELIwPc9uu8VOP0GLCFdFpI5hyq8QOi4EHnmS0Mu61AofKyswUgx7Fi2HE/vhmwAvDMmEJNEa32SM+wlBtcbjTzxLOhoyspZrN6/x5pU3cKdLKGugBY3GFN21IdIXCGVRRZlcjIZDuoM+7gE0Tov5KuPWgKgZkhBhdYE2DlLC1uA2/qplcWGGaDdm42qPi9uSuWCa0V7CRz/yEe4Mvsj0yjy2n5Jvr7K+usWgM2TxoTq+mDxYBYHE8wKshsCOeOZYzNrmgK29Nv/br/xtUg2LS4d55xNP8vixGY4dX2Z55kmEo/Y5UDwSnZVJH1DoAmvsfdrciU0ojo+vc7R5A6dhEekQ0TQwJUrQgAVpoChcTM+n6Avs3hRGWKTUqLCGL10aUQUR1HGCCtIJSIsB8tU/nNiNtzV453lOEJQNFJ0XjDKNtaWqToBEa0tu9kVkpUJKh8JIPBWinIJCi/LEiOK+ekhRFDhS4R5g5VSuYG6+gc4sRW7ItUVKpxzwUA7SkTiuZa5ZY75Sp+KHNKsVMhcGnkQbQeC4eKoskwhZ0lHmeY7nTl6uEEJQCIERpZpHIhTXWgMW02XmnZS0GHPzbgt0XmbGAlxKFkVXwMgKcgNKCuJKjaMnThG6G6Ve4wG4aQutMdpgTKkXqrVGqFJ1/MbNW6RZxvHjR5iZnqJRqyCKAhV5OKbMgoQEhEAblzzRSKEQShLHFfx48ptTKBc/cPCkQigHKacRWIQ1aKOxxmJNySaINlAYRuTlcI4QGFeUuqcGrOuQ70NTwzCmUp080zxzeArHTen3xoyGOaFKyXMJUpDonMg45WcQCPLEUBQSX0nGWUqBRY0lkevhFB5SQaIlRS5pVkN2+5MHzUrg4FV9sALX8RinGcoLEa6L50U4VpHanPWtTRxfMVttIAwUaUZWFLTWh8TaIQos2VAjBPRbXaRSVCqTQ1rDsEEnS/FlwO6OZmaxwtpGl8GoijCS9c0NqA7prXbZ2GgRL/hUpzwCpbi+cZF6VEUKTb3uckcVBLUqWQ6OW/o6qQWuh+tIhCfx3JgzZx/j2MmUwXDEjZs3aLc7tDpttjdv88Tjj7M8NYu0UAjQWIbFCCiFMXQyBlHKEBZFcbDgjcQfZSA00hqkLWPPnxFBt+BqDYyw0mKyAVbsD2C3JAaJBoyUaCv3tVZ9Aj354i4OIof0wB7YA3tgD+wvhx2gxfrAHtgDe2AP7C+LPQjeD+yBPbAH9lfQHgTvB/bAHtgD+ytoD4L3A3tgD+yB/RW0txVtcuHNyzZNBhidYY2h0CWftdWlIKcxJeqiRA+UzzHaYIXFWondx3ILKe8jKqwA5SikVLznQz8w0Qz0z3z8x63WmuFwyF5rl1ZrD11IrDW8/wNP8f73vpvFhRX+4X/9a0xNzTO10OCpd38XczNzzM0uML+0Qjru40vDlQ785qe+yMbqLfLONq4p+NPP/auJ/BBS3EcWCiH29fi+5fH7r1L+tlQe+gte1L71IqacfvoL7W//3R+2r3xtg8efPEN31MfxPd7z9DNcvPQmV65cZzAcUWs2oZdQd3z6/YRjz55hfTPlZ3/mb9LutvnE7/0mhR7R7RsaYZXusMcT730fadLh//hHvzGRH//kud+07VYLz5U0alVAUOQ5lahKkiTkRUIUueRZxl5vwLGT51iernPn6hvk4wQnCkqV+7iK0xuSZwl9kzJdiXArdX74yR+byI9f+cd/34ZLR+jsbNFeu42z/gZGGFZ3xtxaH5BrjR/ELC9NYXXGu595ki9/7rOcPVpn9vQz/OEXvkqhLWsbe0jpYk2OtVDkBUWhubvTnciP3/uXn7Q/9qMfY35mmijw+Fu/+J9x8uwjKFvwhd//XS5eukSr1WKcJsxPzeAql6WlBnlWcO3mXW5ubWCt4ZETR3jikXPMzC+wePgwjsyxecrP/dJ/NZEf/+0v/gf20NFZ4mqAHzg8efYoUbXJYFSwur5HEMU0mnWCIMBxFFEc024PGfV6NBsV4kqEG1exSAb9PmhNUWQYXTDu9zn2zA9P5IfRmQWQVmCNJpeQZBZtFUKAowRapziuU2LttS71bguDQbHTGTIYJ2ghUK6H4zhs77TodPv4nsf3PH16Ij/+588+b6W8JyYjETj8OfoFYbHq/xsM8pZguuTbc+if/8BjE/nxtg/pgAFrEdYijUWbezSxBmP0vljqvrI6YDGlCLgx++RCFoxFSwX7qvHWgDEHwVcrrCkVVvI0oxpVGacZ9XqVw4eP0u5pXn/zS/zAx57gu554DyfPPEWt0cBVJSTw+Ze+gJCWw0ffwY1eysqT7yaTIZtf38a6k3NolB/4vff51nf4zkF6MnZVW14LBwARbW608HyP8XhIFPq0e11MUXBk6SgX3ryMH/gIWWJY0yxFa8P1qzfxgjnyPOO117/BaDRECEMQ+vQ7PXqjDrevX+IA6nSsLC9Tq1ZJBl3G4wFhEJBnKanjMjU1gy4yklGHer1JoVy6gx6HFxeQ9Sa+V5AWBYUxCCeiCCWZ42K1h/YiMj25+EDDK6joPpXYcuyhZfKlKq7QnEoS7myNGIxShPKIA4sUOadOLjAYfzdFr0MY15ieqnN7dQvXLVXrrVD7WPqS22dS+9e//S8QQrDX7tBzHdpbm9xVCqsTTJZSr0T4rsfrly5SiVOa9YjVO2vstnscP3ac7c4OQudM1WP6vR5KSbwoYGZ2hqPHj03sR7t7B2fd0KhP43shX+1eY2pumsUjhzh25jgb63fZ2VtlemqauYV5rBgz3aygkwHZaMAoGVIXkiCuoTwXaRWBcBl0OzSnJh/Tt6K8sMvQUCZbjqNwUOR5Dkg836Ukn7almpQt5eCkFFTrFcJqhUwXZdywloX5JrVqcCDq4m890paf8Hd8sEy2ZIn9xpZ/Yj+u/dm/9m+H+HtbgzeUQRvK7NruB+4yUJc4S4Hcn1SjVJmnnH68dyzWwH6AL7X5LAKnVKWf0DzHQRc5/U6XdJxQqzRwhCRQgm989QVmpud59tnvQnqXGXauEJmHUDoi1YrOOCVrrpAjWU1jMlMw6rdRro8e5YjaAZSQ9+3eKmzv///AL3HfygvlYJaMBVLBzRs3qdQipuZmwVpmp+c5fuQol29cZzgcIdOM0A3xPclOp4fjO/zJn/wRl66dR+sCJVyEtOzs7ODGHtmwSyOe/ObM0hTf9RBBgNUZaZIilcBIS6Vex+Y5ZCl5bgm8kMhxmK/Psb61RtLfw1Gy1G7MM5SwGGGQwpIWKVJNzn1Tq3iEMicKJL4fEc3P7N+kijNnFaMcxmlBv9+lFhQszNb40R85zpvnr3Pr1i2mputcu36bUkao5K8XUqAcgSkm/3ReefUVfD9Aa02Wa158/oucOnac2ZkZpKOYnZmhsJJhkXHukUe5dvUaw5FB+R5JMubUkUPEnmRleQGMS+C5DLu7zC8tMe5PPrSkbY9BJyTtZ/huzF4ccnujxWsXr/DEs49x5PAy89MnuHXzJjevX0cpxfEjp3EkWF2gnAArBNJ1CZUgGfYpdI4fujhq8kW1kA66KHD2h+lySxkTdF7yYAuH3O7vxPf1cYu8KBNDUZBo0LYUKc6z7D4DZ70RlJTMk5oQb2XOlnIiZ9/uZeTlYQ5IiTYGIWxJzHfvwfvh6js/dxJ7W4O30QVa51ity6/9VUgpVTLASbPPbV0eb63F7B8n97Nv2D9fWCQg7q2uB4h4f/pHX6BSrZKMx6AEibMN2rI+Dll49kc59M4PclmF2I5LMBD80W9+idbsWbZzn7EGYRwCMh5a2uXcSoPq1i43Oh2keCuTnsiELf0HEPeC+P8/3L0QB5rPASDPFLVajCkiPM8yHVepSIcZP8BJc04fPc2V2zfwghpxEJCPBjg65tCRaapTBe9811mUdXj5xTfopyNyMmbrM2SDlEBNflPs7KxRn57Hi+uMkhGeYxkMMtJ0QLeyQzoesHr9EpdvXebQoROce/RxRsMR89VZttIRIh/R6/aI4xjXi7FC4AgPKRWuPzn1qMSSDXZw/RAvjlEComqdIG6iggjX87lzZ5Onnn0PTt6HvIU1XZ591ymWD8+z9j/897z3lM8LlzO6eUmeVlJCuAgxOV3A7s4Ojz38EL7nMRyNWFlcYeHQYeYXFlGuot5ocOG11xkWKYXRnDp1DNc9ThRVeOlr3+D7vu8D1OKAIApYOnOOwV6Xr3zin/Li6hqe0PzgT/2difxQWYCQOyi1jU5zoqBBr5MjVI1vfA6+6VxA+ZKFxQVae3sMhyNOnLiFEjlxHHLmyaeRrosRgiAKKYqE1tYO8zNNsmzyi3V3t48VBY4AR0k83yupf9EUwoDOyXODb71yg45b0vhaQ4YhzfL9mFIKUkgpQWj0t8Sig5jYD+JCiPI+/pYQJLB86dO/zfGleY6urPDSq5d54tn3IaPoz/EfCSEONJl9z97ezNua/aWv5Km+53B54sR+RcTeH1+1pjy2VOApj7N2n0nQ2pJVkHL7Iw/Qe03SFEc59PsD/EBy9txxxiakLWexCyd4fXUDL7c0+5vEJic1isRUSBJDXqTkhcEEHkV9jq+/8CobazuMOyOSIieYfGDsL42l4xF5khPGPqMkJ1aKIE+wnW1CJehrjclyksJiPA+Q5GlG6IeEQUC1UqXbauG7lu4wJ/I9FuZm2bpzl9pKPLkfyRhdFMzMzpKPx7S21pDSMB4P+O3f+Qy2KOju7nDizEk8V3BndZWnz32IVmeHPM9xrWF6Zoa5qXl6nT5FMsQLHRzHJwgmz7wd5eB6VfwgxvNLXcEicxljmKo1cRxLUInA5qTZCMekWJ3gOIpeZ4+vXhrw2ILl2Yeb/NFrLYxVGOUiZH5feHsSi6KIw8vLOLIkXjv50GmOPXyaSrXChVde4fTZs3zyk5/iez/8fbzw/PO4viLwY968eIG4GrJy+DDVWoVk1Ofu699ke2uX3dYeXjXC9yaffB1k4HgSZQGTM9OM8JyUTqfPuLuBtRItCxxgt9VDOj7GRriepdKso1xLv71Ju7XN3OwcrrAszE5jdYGrJmfhNLJgPBoTeBFFIUjzArG/K8/zAuUosiJnfW+TWqVK5LmkSYrrufiVCHKNzguU8giUW04U2xxsQZEfgEP520x8x8TRUow7fPp3PsN8vYEJFzjzyGPUarX7z7lXuinj3cG3228vn7cox6+NsftEUG89ZtFYzP2mpbUGKRWlXutbK5NAlFSAAoSSZcDfV5Wf1LQs1bTjuIISGdMzcwydGdK0wq0r5/HJkGlCng1x8gzpwu6lV+mP+mQmxU5NcfjkadbfDHhsYYXlOZ91kfIVR1E7AMfKn7d/N9OucRSTZQWVICQMKrzn8SdpuAXdrXWeeeQ0d3ol0X9rd4DjughdEHiCalTHFSH1yjRVv8ar+iKnT57hllrjfc++n9de+SYzc7MT+xH4Hu29XXwV0qhNkQ3bbG7e5WsvfJlrNy7gOy79Th9cTX8wpBpN8/X5rxLGPlLA7u42R46fYbY+S9WPceSIYTKgHsdlb2VCc5QkiKtE1SbK5lgR4HkeBoOUgjxPkE6IyIZgUooiAaNBJ5h8hKnO8NpOh+9uGhxXMU4LhDX7JcHJ/bCCfe5un+bMFEsnjnLk5AkqUcArzz9PNa6wubXF0tICCstgMMR1FI8//hjVaoW4WqUxPU0aRmzcusn66k1awwwv7bN09omJ/UiVopdo0kLgqwqb20NWDi3TH90hG7VLR4uUnU1Fu5ehhUuuLUsrc6TG8vDjMXXXRyqHTmuPfmcPaTXLS4vIAwhlX7r0TV795nneceYhlBTs7u4igcgPUVLiBx5g6PX7OErhCF0u6p5HpV5jNBoxHo9x3WCfHkCQZQmu69Lv93n42ImJ/BBY5P1E25YLiBAYYfdH5i3SFCzPzbJTrzPTbHLt2nVeeu4PeeKD38fU0gJGSsZFhu+FKKH2CwfiQDXPtzV4F1mC1Tla5xhrAKesaVNSTpaBu/wSwJUrlzlx9Oj91cnaezXyt1Y7ISkbnwfQwisciQp9UAWOE/Hya2sYfZssT/CEQIYVEJaVs8cYDDoo45IlOdpkiLTg3//g97OzuU2v3eHWzqvEcchOd0T98Am2bl6Y2I/yLfwFN/O3I1D2n3K/Tv4dgsFBSyePnj3H+W++xrsfPsszjz+CyPdQuk2zVnCkUWPjhfPEGOKVQ3hWk5sU20/ZuNviyqWbnH3YoddtEXhLRME8ebrLn37pGxw9cZKhPsBWROf0On2M1kw3pnjujz/F6s3X8ZRDM6qwsbaFzi13bt7l0vlrSFnw+U9/Bhxo9fqcOLLEB77nr/Gxv1ElHRsyXIT06Pf7yAPwrAuRI5WL63o41hLWF5BSkOSWJE3Bunzz/G2+69E5IscgtSAMGxTZgLmlw0g3QlRdPn9jyIfO1tkeWN5cHZBk4B6gg9vqdRiNxxw6cphjJ06gxwn9dp9snPE9f/0HMcLwQx/9IMOddVaW5rhx8w4W+MmP/zi/+mu/wbuefRe3rlzmxOmHWTx8kn4noTm3zMzcNOIAn8tma0DggsISBz67vYSr65eJYhcpnFKm0DHobIArYboRU62G7Kxv094W9HfH1GoNao2Qk6fnadRqKKEZDltsrm1xZvHpify48s1Pke4W3HrzNlLlKKmQStE3umTztAVKWdJkjOf5OMrdj4eCvS1K/h2tEUiu7LWoXI1QTQAAIABJREFU1+sIIcjzHK018JMT+SH3g/e9O1NYW4oSo4lljmcLVi9d4OU/+AP22i1G7Q7V2Qa3L7/I6y9+nrvbfXBjzpx9gl/4z/8e1hcIIfdfc3J7e8smgn32upL8SO57W8YhCcKUxX1bdpVdx+MeIuOtYFQ2Ge5B60CUTdAD1LwdxymJraRFuQrHU8RRiBAR/dGYwTBHYpjxI3SrxTgZkicJRZKTDhNmG01uXrqK60j65NgMoCCqN9lRBzyl39L3ELz17d67sfd+d/8EiD/zVt9qnPzZqtlBmp4vvPB1vu+Zpzi5skDFlxw5dYi11ZTWRsKd2zfY3FylUmmSBzWKfhuBwPN91jc36fa6bG+9QBh6zMxMcf78JdrdLoPRiBSP6QNoehptUUCRjahUVthr7TI9M0Nnp02nPShVYUSKMRblSKIo2A9mBfU4ZG9rk899+l/Sam3x0R/6GXzfx6DY3N7BDyYnppLKwwt8PM/B2UcJCCHJshTGOUYUdPopG7t9ji/GOGENL3RRTsjhRgUviBDkGAFvrG5yaini9KGIV6+W5ESTWq1SI8sKNra2uXr9JrVGzJ31OwzHKTdu3uTRR87y7Lse4ZUXvo4fVjl+7AhxqKhELieOreAHEXGlwuLSCp3OgObcJnmSMj07S3EQTc9Kk9Gggy4KjICKF2FMjkktmDEV3wMpGPR6pJnBUjBMxijlIqWivSfpdTr42x7t1iaep3AcWFycoRrXJvbDkZpmPSJwxH7gdkAIrLAY5SBsgTA5tWoDmye4ToAxdp84rhSlsMKQpJrzr13lve95N45nEK7FHgBnIKS8X/YA3irt6oyFqs+nfusT/OnnPkvF83j0HQ/hhiG3NzbZWl8n9jwWajHtbsLVl7/GzYsXOP74uVKmTYkDbb7fXqhgWetACIOS4n4WbShPsE5TsiQl8COEEIzHwxLug0QIi7UlVPBe5n3vXwkLmvxdV10PT0Hmh+SVGrFvacQBvcEA162hbIIncmRe0Kg18ULN9mAPo3Kiqs9OZwedG2Sh0CLDEzGZKlBhhD7ANhDeYiIT3xKcrShpJf+M3T/u23/9FlLlfsA/YPNleX6WZ95xhNmKx1Qg2bizTpJavKjO9m4LbSVT0zOc+a4P8eY3XmR3NWF5uYlTrdFqtdCpQilo1CsU4z66FiJchyTLKKLJo5W2gulGA201gRfQ6Q4ZdncxSUGS5AgFcS3kzOmHuL56jak4YjPbwA0buK5De6fNfB2uvvll1p5+L1P1RVynZHATByirKdclqlSRSiBEGYAKbRkORyTGBSdiZukoQiVlSSWMka5FqojEuNSaTYo8wVjY2gowd0ecPhSUUnYHWFUDx2V7p8WlazdodTu885mz3Lh+hY1ORrU2xcV/9YcU2QjXFERVxez8MpGTs7ezxg/+4Ic5evJRFucX8KMqjblZGvNzjHbbeJ5DrT65spAVkrjSwBjNaDDEanCcghiJ77iM0gKd5cTVGcQ4JSvGKKMRyqfbGWL1GLD4Xsz6HUUYBVSqFW7d2MLzPU689+MT+ZEUksDziaoeyljGhUYK8IWHqTQw2RA9GrJ85HG2bryBFLoce9C6bEyaAq0N/XHC0vIikn1WQW3RxeSN9TLpfithFFKUimBK4NuMtSsXCaUhqgc8+dTjdLsD3nj9Ao51GI1ywjigUfdRyuXzn/kkP7Y4z/z8Qgmmm9iLtx0qWGYwAvVW4LYGsOg8B9fHpDlWlNvTL33165x56ExZT7Jmv/5d2lvDPAIlJfIAxSKhQE0f48jho0TNJnfeeIE71zZQ2uL6VVYOzxN5lr12m+4gwY0anDsxh6RJXF2gFk4xbA7J6ku8+/FHaGtLwxQ4O2M61149wMl466fdr3UIQFq4N17z7e/KCu5fNMqCEeWgki/Kppa1kGn954P/v8Hmp2aYn63hOzna7TG/MEcQxdy9vcWbr7+GspIbN+7ylfP/gkPTDRpRhc3WHq4W9PoJgRuQJAm6k0M8Q7M6R5pnVByLIyd3pNac4eaVixw+chjf95memmP1+g0WZ2ZIki66gHpcpWo2eWJ5gVpomYtCOglcuzsiyxRTlRqBb3ntlRd44p0fwBM+j5w+y15rb/IToiQGQV6YEqXiKIa9XV566QUcv8Lj3/uzPHRmisgd4KkEL1BgEwa54f/6rT/AVwrPraCEIE9G7Az7rF8Y8d5Hp7m5Obns13Zrj7XdXQI/ol6v8f73vI+F5SW+fn4dWZ1lPOjye7/3z/kvf/kX0FYzPTfFM8+8m8Eo4e//g3/I9OwcJu3z7/3AD3DssUd54r3fzdqNy9w+/xp5ZfJGsihytBV4XkBjKkIX/VLPdJyiTZlY9ZyckRmRpmMqcUCWjhHaIgpDkfQwpOTJNuNxydWPCHD8GmOd8vMT+rG72uX7P/q9jLKERhyxMDeNFhLX83j5/Hmub2xy4+o1rm/mbNy8QFx3WD4U4zgWx3pISrx9qsfUaqX4y9LyUS5c/SbDdHJBZmkLpFXYffWdwzXF0lRMRVlcU/DeD7yHT3+6j9aKf/bPfotWq0UYhuS64NiJY/xP/8uv0+l0WFo8zD/4e/8Nv/GLP8tHfvhjfPgnf4rsAEnGv4MhnXJ1MdaWaJJvGTQqRkNuXzjPmXNPkiUp8/ML+L7HOEnvv4DdR6pI5LdlMZMHiRzLqNvm4me+ibE5rrGEDvhewLg7YmNrHcek1P0YIzy02uHI3IDl+Tprq3e5u56xW5tj6twZVnsuraDU9kuTHu5BClffDsq+v5t4q+xRqgVZ7u23HSnR1uxLtSl8pQgDxcJ0iR4QUnJltUWRT34+Nnc7rPdzsjwl6Losa83sjMR3JeQJJhmRpxF+0MT1Q5Tifoc88EP8uEbVm6Jai7HDPp5QKO1iHIt0J8fxamNZWFqmVpsqudF9j0OHVshGI7TWaC3odvpsiAzfs4xrEedXd4mqVZqzITOHDhOFMBz0WVpYotVpMddc4NbqKoPB5DzJIMnzDM/xKKzFFprheMBg2Kfu1zBuBUdpqrUpXN0m1xmR75MPhlRUxtbtCyyceJQwjvHCCKs1uTHc3UmZr02ONsl1QeAFJMkIUyR89rNf4Kc+/qOceWiJjXGDa5cvI6xmqlnHCEst8plqTPHVl5/nxGMfYKoZ091d448/+1lu312jAOZnmjheiCkO0FjfBxAUOkeacuAliCOEydHDnCxNydKEPHdpNqq8733vYvXqRdZXd5HCL8dYrEApixUJUjpI5TAed9Fqcj9eeulVGvMnuX13jXecOMSZYyu4YYzreczUYrYDnyj0Wbt9nXOPPI4QDgvLMYPhHuloxKDfpyg0qS6I3ZjmVJMizalVZ9hpdyf2Q2AxQqIo8NA4u7fp7OTImVmu373L6+dfodAZl86vljq9FnSRolyHjY1dwiBi9tQMaZLzcz/z09hRytVvvsyjZ49z6PiRif14ezPv/SlJazTGFJRJ936QUaAcj629Fo/FIY6n+PhP/yRZv40pirI0cg8fLg1ID7svQCytOFAXf1QIFIZaIPGReFaS6wLPVyhhiVyFMB6V0MdYQSvp8fQjxzm1EhHPH+GTL0pml0+Ti5DhqEduaujhkPHuNkJOjicuOxTfeazm/iP3s3OLkpIoUGQ5pIVhZa7GyeUpHAWerxiNxriuS5JpVjcnl/0yUvLcC68zGGksgsNzdT7+Ix9kqlJBF5rxOKVSneH42XNUBIy2bqLcgJn5ZXIDThCQD/cwozZzLlT8EE8ItvstpJy81rzX7jDbrNFudxkOS2RApVJlu9cHYZFC4ngBxqlhwoB2IoinplmYa3Di6DKrl69wZ3WD7rDgmblDjNKEcZqSZZPfmADaWoo8w3VcsjxHAnmhiStV3KiBxUVS4PkegahikyHWJuSF4O7qGk3ZZu/OJaZXTqEcH+EVhEhubq9RHCB4B57P4uws/dGQwXCI70fcvrPF+7/nu8kv32XOTUjmG5giJ6iENOtVrNF0uz3OPPVOHGmQjkM9luy29vj93/99Kn7Af/Qf/x2S4eTXh1BeKR0gLYYCneeliLjjQuTjBiE2NfR6OfOzMXNTdYo5n8sXdpH+LNqzuNKSFxJhnTLxomDU23lrIG8Ck27MZndAjuLajWtMxwLfrxGGHvV6wOG5BrZYZq6R8Ow7nyEOa3gBDEd9uv0O129cZzAYwHDA7EyDSiVi3BvjyCpSTl5GElgKW8ItfDI2r7+K7zpkRcrv/O4nOf/66/QGKSMkbrWBUoq9vT2qjo8uBM899xwf/sj34nkeJx4+xk/8zZ/g03/w//C7v/1/88Tjj/HRj01WRnqbM297v9xxb1S+VLCwGAOD4YAvvPw6H/uxn2Ll9ALXLr7Gk888y1e/9BwY6Pda9Ac9Wrs9zj56dh/vbSgKizpA8A6sQWcpmawwNuAKy9PPPMrsVIUs6YF0GQ5HvPjiiyhHgZR89iubvDTt0Lc3eewDP0cltGxsXGbTxEg7JJUhfmHodCa/KcqAJMryGfvwx/3NiNiHmdj7JRVB7HvMNn1AsL475MNPn2R6qoJSAiEU7d6Y7mDIYJiWHe0J7aM/9INsb++yensLqywD7TIy0BAe0g0wQuEHEUvzU2zdvkWqC1yTU5MZniNwhztInWN1Sp7l9No7pFmCIy2d1s7Efqxvb5BkY8hzTp9+iPb2JrLIGfcH+J6HVSBDSTsP8MeSbDQgrHmMO21eeH6b81+5zbiboY3hM0c/w/FzDyHVLqTpgXYASWrw/BxEwvraBkcPLdIb5ASVGRIbo61lt9NjanERJQTS9BC+jxNa5h9/J1euXWe+2KZz4yuM7Dy5zsmzHG0VV3cnR0UdW1phfXuHkyeO0ajXWF29w9qdNd549XU+9tc/zHjvFncuFywt1jhy6iTN6Tle+ZPfIez2mFmcoT9MeeJwDc85x5WLb/BL/8kv8drLr/CHv/MJjE74qV/45Yn8uNdkVUqWyYT0yPMx42SM71bwHIeqP0UcevR6fa5fu85CI+D0qUN87guvcPKR4xjpkacGpMBqjRJQrceYA9San3n/9/Lqmxdo+IKZ+Qq9zjrj8U3SQhJ4Lo4wyCBiaSrkxoWv4XoBu7stDh0+SicpaDYXWVwMcKXLzHSN4bCL0QNmooi93uSh0GiNSwYCxsJnr3qStRvXufjZT6GN4OmP/A3iKGRh6Sgzh49RrTf5p//dr/Lin3yRLM/59V/7X/nn/+cn+P7v/zC/8B/+PLkd0x20+PGf+BE+8YlPTOzH21zzfqtDK4XYB8lrrCnxs4dnY/7TX/xZpmabFMLl0OknuH5zlVdeu8D6+gaHawqdjnj16l3OPfbY/Y6vlN9eQvk3W1ybxptaoX58nqFxS0XqQ4uI6To1T4LRNISEuym51rimoJv67G7u4rqG4vUXaMQwN3uUN07/OK4piPfW2bv0POzdOMjZKKe87iff9q3a/f7orxUSKyl1+8KAwFOMU43nOjRrMaHnIyUo38cIhRUWhOQgaPPPf/45jh8/ShA4IEtx6L3WiPqMQjkurlKMkoTt1VsMWtsock6tTONmHUyWgemRGYjiCmlnCKLA6JRcG8ajg5QrLIPRgHw84uLlSwz7A0IFrqPwQh/luwzHCTZPOXJkkeXDR7m7scPdjTbttR7DdgrG4vgu3c4u4/EKygVPlxOIk1qaFeR5jrUCrS1JMqbd7nP1ynWmjzXIi7I5l2YWS44YDpDCpdPuMj9/mMriIdp3c5RsYfq7aBmCMWVz7QD97G63Q7vX4cLlS1QrFc6dPcvW5hb2NcMjZ09y/fotpptzrN25zfFTR3EwXLt6nczO8NMf+TAXzr/G1SsX+X/Ze/Mgu+7rzu/z+/3u+rZ+r19vaOw7QBAUN0ikRFrUeGRZi63YI8kjb+M4cUrjJLYzM2XPZP6Iy07VOKkkNa44yUziOHI0tseW5UXWQlqiKIoitVALVwAEiK3RQO/db7/bb8kftwHJLid5rUo44yqcKlQ1ulCF8+5999zzO+e7vHLpEqP1TSamJceOH+Op177NAw89MnYeWhs8X9zmYCjhSla0MzhKgozRBUp4KOHo9gYc2dPk2JH9LK30IQ7o9TTKq5BkXZQU5HmBJ2WJGBkz0qxg//xuAnLCyEd4Ebvnp6i3psiBpLvJYJCwub5CnmWkRlCtVDl77hVurHVI8pyJxgTSwZEjRzh8+DCzu/bSbM8zyna25L+lWGKFZGrPMSZnDnL8nrfR7fUIqzHLN29w4coVriyvMjczw57pKpP1kMEwocg9VlZW+cynP8PP/oc/RRRFRFGINuWJZtx4YztvKzHWYBFYW5rMOguBCvjqV5/mAx/8Yeo3b/DKC9/izJmH2FzZ4D/5+Z8nG/WYrMQcvO8gNk/obKyipIcTdhttwo6wce1IEsWCPUd3szaChYHi+sDjeq6Jm22ioCQUnHr/L2GcADMi6SVIMcJ3PTrWksmULJ5E5gG14TpLX/8syeVvErrx8bN+4COV/M7i2m0Lbbntz3ULzy3Aeg7lKer1OnnRpT0RU4lK1IwUjnqzSVR11CdneeXiEmIHD4WzJVt1uj3JxGSNtbUhm92Eve0GlWqNiYkGySijZguEb3DOMFUNwFhSC7lxeIGPUSVxSuBACZK0oFofHwrm+z4LCwtUwwDleRgniOKYlZub1FsT7D98iFdfu0hvax0lJinShM5Gzo2rWwxv9HAOgorHsQdOs+fQbuqVKoUW1Ot10nz84p1mmizPyTKDsYZur8frl69y5eoC4ewJkiSh2W6SFRaBI3CWQX/I888+w+Ubaxw6cohrxZCN6wn7qlsMc4P0PIjAt+OPTWqRz+HdM4yGAzybcuHyZRyCud1zDJKM+06f4Lln1omjKnFcRwrHzZsrNPfOM+hvkRUFE+0Z9lhImpPMzO+hu7XOO3/kR9lz5MTYeQBIqXBObzcb5bUMwxBTOCwSq0G7jEoAc7t2oVRGFEgevPck568vkaaOYWZxKqKwGmwJSpCM/zZL0xRjLRmSTmJRXQ0moT0paM3PkLVq5N0hWbNKkqUsb3XZ2Nyk2+uzvNRFKo88zRAIzp8/z+7duzlx/Bhvuv8hlleWd3Q9HJQjX2sxeOAHBJN1Ztuz4KA9O8++Q4fod/v0NtZAwUS7SWHKaYPnS7Y6Hb705WcYjQYcPXGC9swMk9PtsXN4Q4t3bnKS0ZAkN2RFTjocYXXBl5/7Iq+88BK//ft/gfF8KDIkYKwkKQq0tXQHlo9//nnmppocOnicjUG6zXQqjWF3gms+cfpN/Pwv/mP6wxFpmrOxvk6/32F1bZlrl56iu7ZGtz9ko5/ghCIk54M/8CjWOuJKzEanzyuXrjOo7iPy9zG8eQ6x8TqRNMTR+Fv8ydlJhJTbIjrbGgeiPJUI57aXdOWD4qRAGkPkDHvaNfbMNNk126blF1Rcxj/82JPcffQg73vwKLV2mzhaHzuP48ePE4Q+lVqFlZV1tFGsbQyp3XuQSqNBKJZIt1ZZePU5ZiareJ5gq2fYu/cgeZIx4UWsb26RuyEboz5ZofGDgE5SsKc1/sy72+uxsbFJWvEZpAm1+hRXrpR4+jzXLC2vc+TE3Vx75UVaUYWrL11g84YgIuY9//Dv4WoFzak2ziqKYkCzNkGrPcf5l7/J7PyesfPIcsH6epeV5TXi2OP82TWefuorJElCd/OPcFbx1vf+farVCrJ/jaa5QWd1jcXP/T4q2aRwgjkp2B05ZM1D5wbnMvxAbXMYxotHvu8RNtc32FxdwRYjmq021UaLaiC5cfEc+3c3uP+eg6wvrtBbW2N5MecH3/9+puaOMOx0uL5wk9XlFRqNOmcefpSnv/AkL331WR77u29juHpl7DxuNRRal1jp0Jdo7Sh0jq/iUoBJKFqTdWqh5L//zf+d3/hn7ydLRgRS0W5O8uTTz3P+6ipveeRNmLzA5jn12C8lM8aMfq+HNobClc/Fk0+dQ2V93nz3Yf7Jf/XPsa2AYjJhc/k6YtAjyiWV3FGtt5mdkZjCkKQpVsD8rl3kec7Kygqf+tSnyXYgGGa1KXWVhAAhUVicsFgrSgEuV6qcBrUG0/UpZvYe4dB9b2H66H380b/+n9m8eR2BIYx9/vJzn+OXfukX+cCHDoIU/PAH/t7YebyhxfvffPR3mQ1SLr1+HaMNgzTD8yQKw+pWgfID4iLBkx7zVcXQGnRlmkEBu2em+cDf/yHuOn6UIjd85fkXyhkcAt/3dqQZ0d9WVJtsTRKEEQ+euZ9aNQYcyWCTQb9gOEpYWl5hOBoxTBKSPMfzfIw1tLIRR+5/hEs9xVduGqzIOHz8IC99/Sbdrc2x86jU4nIPcAvaJ0qdYl3kpfws5vZCx2kIPInyA5oVxd7ZKb529iqe0Lz/9DxSOi5evsaFqRhlDWE0/q0NwpA0TSjyLdI0JwhCiqJAG2i2J2g2K7S7Ec3JKsLlFInG82OKIsWZlK1eH61z4koLvZVQrUyQ5DmBJ4nD8e9Lt9MhjmPyImGYbFJrNOl1RjRqIb3egF6Wo/2IzsaQG9EGvTznx37u53AUVFp1ljavYXVB6HnkWtPtdJEqxhpLMkrGzmM0HNLtrLO2ssq+/bu5sbhIv9dBCnBJj+vfepKV0w8xNT9PsHIF9Cob6+v4Kqcy0SAbpRgNVmcoStd2hyMKFGk2/glg78EjTE3v4jUH6bBLvVrFD0N6gxFfeOpZfu5nf4T3fPBDfOx/+G84dbjGzfURD/7d91CrV8BTxGHI1YuvEwaKhQuvsnDpItVQkva71PfMj53HLbU7IQRCCtIkRXmlsJO1FilLiGq312Vt2OFtb70PXWgCX2K1I/B9rFNoqwiiBsILyZCk6QhvB/t9c0sy2mhMnlMkGZl2LG0MWbm+QXvfAepTTYTyiPs9NnoZ/eurKKXwKU8PcRRTOEOaZ3R7PSbqdYK4gt1B9ycBcQspJyxWlnVIfRd4ziHKEajT5YlFCI4eO8pd9z3AF69fI/IUjVqdl198hSf/8gv85E//FH4l3hFf5Q0t3u9637v5+lNPcmDfPBXfozCWIhsivZjWZJfY00xGHlEYEVdrEEZEM7sw0ieMI2aabVYXV8mFIUkTpPJQSpEbyw72ldxYWiIvcoyFG0s3WVi4xNTMNLV6nYmJCcJqRL05yf79+7flZy1mmy6EEOht2uOnnnyOpz/3MQ5VUqYakvOewKuP33kDKG/75OC2qUbaYaVDFyWTsNQBFuAsgVKc2DvJzMwMdx07wq/8q49zcrbK68sRwpVLsVcuXUM5RxiMfxyVsqQNR2FEFIbkRUGWpvT6Ga2ZFlOzdbpbW1QrIYVxpDYn8iU6T5AYZmenMc6S5oLp2TkGI02aDwlDSa6zsfPY2FyjXquTphocTExNcujUaS69dI6G04wGKZrrrC91aNViwlqVoA5OeKysLuGcIc0HiIrCD6pkmSZJR7RnZ3c0W725uMjqyiJ5pmlPTbC2voHn+2BBypDB5iqLly+ily9SH1yFqZjBcISnHL6y6LDcmwhnMbnDDwVBKAkin5euj389Jicb9APF/L59bKws4wc+8/v3ETfqLF1fwG+0mdpziKs3Bjz3ha8zCOd41z84yvL1q1g74uTJ4/S2Nlm4fJb9e/dy9NgBahN1WjMzFPn4eXhKUegEKR3WaiQGiURJta2lX2BsyZ+IQo99e6eRRiOkTypCrm5oMoJSWhuJ8kNExWK1ROvxF7iNUGEMaOeReyCVoSgsxgv5rX/9O8zvP8Cpe0/xrh/4fuqNSYbJiBdevAgIrCvIshRrLZnOSdKUPMtZ765TnzA4sbNS+NdJcd8tV/E37d+cc1TqNR5+7FGe/OSfEEQhjXqdLE154okneOsjb+PE6VPk+fhj1ze0eF9a3KRx4BTCbS+EcChjUDjmD5ZLD41lJCRDKSgKjTfQKAVimHN15WUEEqnUtiiVKym70iJ2oIV730NvJapUaTQazM3PYQqL53n0ej3OLZyj3qiSFznnz53nwTNnmJ6aAiEYDUd4vkccR6RpwptP7eP+X/8Ffu9jH+PsSy8it7udcaPemkDhKIoco3OyYYKTDi8APwy/y1nIlPRs52hEgn1TNb7w7ZdBaKYmIjasjx8EEAnqjSorm13CYPyW5hbZKUtH6DwjDEM2eylf/vorfPAHT1CNWuzdd53nv/Ic0xNtmoeOsTUckeSaRq2OLzSjtMBai1U+7Zkpdu0/SG/tBqkd/1hsdIGUMDnZZtDvU52ocej+u9l//Bjnnv8GjdhnNOyz++AeVtZ7RDXJn/7pH3H6vgeY338MhyXLEm4srTIx0cTzfLQtEAK21sdHvbz+2kW6/R6VaszCtZssLXcx1kMJDyMi0pHm6itf59XrF3jz8f2YpMlTL19gX1Altl0asY/2QYgKSoEpLM4ITJFzz+7x74uKAvT6FoPBkOEooVqtkCQjlBQkwyGvnb9B3LjGQx/4aV5+8QX+u9/4bxkMB6wsd/DDCntaM5w8tY/ZGZ9hNy0JXdaUMNnZ3WPnkYxSlGdwwiGlLXWIdPmZAHw/IPA8cl2enq9cvUnFtIga06yMfP7PT3yGuekZ2lMhOh/ithFcXlTH30HHu7rZIcsydGHJC402kv4o5Wvffok4ipAvvMiffeqT/Oa//B85dOgA3//OR3n3j7yXz372cV584XWsFWhT7jG01refr4mRpV6vj53HLcQcfOdUcusZuv07IW4T7WQ5E2VkCvbedZTm7DR5r0MlrmBGmo2NDS5evMjJe+5meXmZdvvgWHm8ocVbKIEyDqstnpJgDEaKktGWFDihEEgQJQTaVwpncnS+bZNmLMrzKfR24Zfb/9aTeDsQHvrzP/0EOk+5901v4vCRo1y+tMDa2hpzc3O8/bHvo9Uql2yzM7NUKhWCIEAIQWdrqyRv+AGeCphqz7CxXCCFx8b6BnEcE8fjz3jDSox0BiHBKjCZRPpAFOzXAAAgAElEQVSqHKPYcvlXdj261IGRkpELuL454rXrNwh9RZJreqMUhCH2gvKa7DD6vT7GGiLPK5e1CCYaDbY6HQrt4YcTNOc0U7Nz6EFKrzPAhiEqCqhWqmS9NSrVGjNzbRqZR5JZ1jc3SEc5Nhz/esRhiLClTnutViPwfbSz1NoNTr35XlCChdcvEymfqdk5hkkP58NEs8kgScmKjCDwUL7H5cuXmJubYziUFLq4/bCNdT0GGVmmUZ5mfbOH0QIlAjzloYuCSqCxWQ+BJs0y0iRj1O0gpg1eGGGtRm3LfeaJwRpXLqZRO9JtrtUnyVsFcX2dwfXr+J0um50twtBjdmYajObGtavUoxrHj59k4doVWhMVev0+ttPh0NGjVCoT5A3LzavfAlMQRhH7Dx/d0W5GKUFeFHhOIGU5NlBKIaUstbC3v69OOxJjyUYFTy1dpJ+e49rqgEMH97J7dprhXO32uMVoh0WhdsDAHRoonMRZKAoYjAo8P8a4EYV12KIA4TAOzl+4xMraOh/4UMbxu45gXcS5cxe3HY0saZbd1vEuioI0HZ/5KrC38ZPfkaIQ3NYZ3Ja4vs1yluXPyoHUgol6BXwIQp/A+Ow/uJcDB/dR6IxWa2LsPN5YSVgVkJMhggirNVhQziGdQoYxZvsB00Ve7jGkwhq3bcsoMZhyWSBAef72g1BaS+1kbDLobvHHf/gHfPqTf8ZEs0W3n5OMRoRhyC/+0i/wkz/544RhwNTU1F85Du3evXv7rVo6dGxtbvLRj36MZ7/0LFtbHWZnpvD98TurKA7BWHzfQ3l1rMnLMY2vsNpincHzFXjlaEMIQTfTDLc6bA2HxGEJDczyApwh8hXDNEWqEpM79vXY7CGVRYQhuYM0GyKlJI4CFm5sMTtVpdZuMLtnmqTTIekPSbRBO0GWpjT3TFOklij0KLIeSVFQb0uEUSTF+MJUSkqiMCSMY0bJiE63S2EKbBRSadTRWhNVKhw9dhRrDHmes765wmuvXcR4MY1WA2s1Ni/o9rZwGKrVKkmSUqnsQL96mKCLAiEUo1GOc6WdmTEWXIEvHXq0xfTEBDrLGfX6DAd9vKagUAKdFui8QEiHpxRWG6wF6albw7exQkrF2vJ1+lubWOe4vHgTo3Na9Sq97ojOVp9hv8vmVkFU8Tl79iUO7N/LZHsKX4GxKc5BtTHF9O792KSP55X65taNP3uXUhD4PlEUAA5XlJ2nMQbP85DbmtrSQaEtnh/jNxtEaUZbDAgCiaCgUvFKnLd1pbSw84HxxwTS80oFP+eQxqF8n8Ggh6P87jincM6QFQahDL1hwWefeIq5XTPMTh0gjuPbdnSe75c/W4tSiiDYga64NdvwZBDboMHvjltosVshbNl5SwfSAFYzOdkkSRJA0J5s0263EUC8E935sf/l/wdhrcH3PPI8xxqDdeU4wCIxToMUeJ6PkJIoDgg8nzTNUErirCUZjgCLVJIgCMq3pi7K4/EOwP6V7ZuYZxnrqytIWTIu82TEb/zXv8q/+LVfR0pFrVYjjmOq1crtQq6UR5INWVm5gS5yWrWYShywe/c0vu+xa9eusfMIfEG1XadIMrQumKhH5QtdljPuIs0RzjJRr5b55gVXNzcR0lKr+ARCUjjHtxfXqcURuTXc7A0wTqJ2ML5RuPKlsY2FbjSqZHlp1PrxTz/NBz7wXu46cpgT91g2lhZYvHqVm1dWmN2zn8EwATGiPmnwwzVmGzBlQjKT0jg5y7lz488065Uq6+trxJWYQmsazRZ14VBKsLSySSWK2XPwAMsbW/QH/ZJR6kEY+jRbE2xurlKvVbFWc+rUXYBgdXWNRr3BKBlfRS/PNLqw6LxcctqiIA4kwhkkBVhJ0V3BzB7mwsJlKnGFN++2xKLA5g6svu3YV1hNoUtJB5s79A7QJmdffIGFq0t889svsrS2SpJn5IUuVRWFY+9Um3u3epx5+AGEc7z+jW/y8jOfY9fueY7eex9JKkhHQxSGreUbSF/iByEXXv42Vjj27jk5Vh7Wlc+YMeCcuG0EDpDnOZ4flHZfZkhpSegzyCzWSmYmWzg0zpYEHW0KlAyxRpdFfAcSuTod4IzBWIeVluldLWpJTDLKyLIMoSxaFxTWQqEhyYEmw0HAUr5KtVotceq3apA122g/syOosdYaz/O2OSYlVOy7jWJujVBuNX7mtm9lWdI3N7eIlABdNqPPP/M8//Hz/xEHjh7hPe99Dx/6Bx8ZK483eGwiwUmiSgWjNUKE5ezMOhDe9jbZ4XmS3FgyneEBuihKCzWdo7UuMcCmnFsppcAatBm/9ba2nHGXUR5xbmGqy6lDuexLsyFJOmB9w3L9+rXbAPow9KhEQfkn9IkDH2PLo/na2viz1emZOnOtLdLckQ4L7ISHCgKy3FEPHdJ5bHUcvtRYPHCKPHcoTwAeo8RQq0Lm+9QrHoWG1XWLH/us7YDJF0Z++UBYjdaaiWaLiWaViWabS1cWuXZjjT27phFehBdWiGsNpFwizxO0AyEnEUxQpI7NTpd+39Hpdzh+eBdKjX8c9aUkiCPyIsUZR6s1yY0bi0RhgLWGre4m1UqFbreHtYZ6PUbrclm2sdkhUCHCCsIgZKo9S6VSo99LKHRWqliOGZ4sl8i+UiAgNykBBrGNqrBGIHXBa1eu0e9tMVnLOT4lMdojG6V4HiAlhXZEUUSlVsEBaeGxg68pX3nmWbY6W1y9sYgK/O1lVlkUtHGs9gcsLK9wxpPMzM4RKsFwtMGw1+P8q+cxySXmd03RbE4wMTmN8HyMKdDZaFuhc7wwRuP7fmkXaSxREFAUxe0iZR0UwuFLiecpDAYlLEppQl9hrVfqfiuPNBtgREYYxBhn0TvQWKlE1duds9YaqzVWG4yvMVpgbCnoVlriWqzJ6XU3sCZDxzFhGJYdsy6w5lbu2zdkB2YdSqnb48kSgfNXSYK3vQZuI+C+M1pRShKEERvrG/hS4QpDs9FgcfUG337xHMtLK2MXb/G9eLfdiTtxJ+7Enfh3Gzvfbt2JO3En7sSd+Hced4r3nbgTd+JO/C2MO8X7TtyJO3En/hbGneJ9J+7EnbgTfwvjDUWbfPiXT7luPyVNNKAYjUbo3EcQ0usNKTJHUTh0HuBuYSO9khVgjUVsL6YdFs9zKM+RZxqcj3OW5RdvjgUpOPPODzkhSiKINpY0zQiCAM/z6HZWqdfrhGFIv9dHOYV1DhH61Bt14jik3+vRarXY3Ngg65eojqIoUNJRiQOe/NTvj5XHqa9+0XXT8hPJvFyTW2txtlRLk87gTE7CAKMdoKjm5vZmXEmf3JOkKmOi6+hJiVEG31j8apXlH/uZcSEW7v9tcX0LBlVmu43QwWEdfOvpT/PUX/4F73jXD3H/I+8skQXI2+grMaZe79/5wUfcvn17sQakq/DCN75KNtKEXpVOd43cFlQbVXbvmiLPMqyzFIXm6NG7uXlzlW998+y2lG7OgQO7SbMhlWqFxuQElUaFv/z0k2PlcWyu4ZTTWGeo1atonWGEotae4dNP/D7tdg1t+0jrEK50hTJGIpC88urrPPfcKzz99PN881svs77ZwbmSbFX1oHCC5Y3u2Pfl1g/WWj7+8Y9z7do15ufneeoLT/LQQw/xEz/xk3ziE3/McDDksXc8xtWrV9Fa8+73vuf2/WL7bhkj+OJTX+bP/uxP+fmf/wgn7zo+Vh6//a/+F+cJCaYUp5JKbSupgdOa1Fg6w5TJiSbv/P7HuHTpHNcvXSMK49t0b8/zcNYSBqWpuDGadJQghOBn/9EvjpXH//rFF50QYM0tD5dt20BKVqPDYZwFPyTNCnxhS1f3bdSHJyxW59hCgxsQSktvo8NQgx/G/JMP/+hYedzTbLlrZFRaTSrNFt2bq9RbMW997O2EgWB1HZ69OGLv9IDu2oh8bZGkv4Lv+0RhQF4UTLQmmZyZohZU+PY3vsGu+XmuXVtASkG3Mxorjze0eH/t68vkQ4mzHtY6wthQ5AaBxWEAiXBhievetkcSSuAQCOG2/whAkWcZoYS4quh3LOwAPxv4PmmeMhwOsQIiPyzhV9YihMJTPr7yENZQFAWFsdSqFbK8QIkSD53nOUEY4buAXq9XugM5i9mBOpkSPp5SeNLhsgHWGDwB1oJHiClSihzwHNIopAqInClhUM6itAIn8HJNfWRJajHKWmRuMP74ULCxw92iRZW2WI7SPGL52mWqAnwsO9FV/+sxOTmJUh69Xoe5uRbCFyR5Sp5CtVpDFglSKtJsRBwGSBUglaTSsBxv7WZxaZHORo9WY5peb4ssH2FMQRDHDNPxcd6pNVQCH+c0mSkYDAy1hsdjjz1Iq90EpxFOIZwjGQwobEat3iTLUo7fdYDp2SmS0Yjzr73OZneItQKLwFgNO9TQuBXOOR5//HE+8pGPcM899/DmMw/QaDQIo4Dp6SmM0ayurYJwvO1tb8VZi5C39G0MzklWltf4zGee4P777+PI0cPj/99VwVQ0hdCOwuYEUpLrnFGekVlHRUlCFZENrnHplW9w/uJ1lPIRFHh+ycJUniT2Y5y1aKNLzR4pyXYAWfS35Zbttt7PbRNyV8oiOxy502Xz4IM0BUqA5wmKPOfa66/R62xi0pSTd59grbvB4qXLRBN1FhZvwId/dKw8TlTr7B8pep2UTrIBjYCTpw8xGPVoVhrUZFm7Gq0Ka+zCm72L4OzjJJ0VjCmIg4DBaMjpfWdwaYJCsLq0XNLud/DYvqHFO0sCrHFgPXAeSuVYVVJNrZOw7UspRKkehhA4JNa5slghQFiEcHieT5FneB4EoYc1O2AUdrpU2k1coTFGg7KkwxF+FHL8yDGiMKCzuUkgFTaUBEJhCk0ySsnJieIqm+tbNCen6LlNClHgpMFpQzIa/+p7BQRG4IQlix1JmqGkxCAQGqy0WM/hJwYhfJTxGCiHVeCsQFqBpaBRpLRaLdayjIo2ZFt9vJ3ItY0ZllKnoXyZlh2nkoKbly9RlYLRVqfEtn6P6FPPU+R5ThSFJXa/0BhjGI16eH5IoRMqXoAUkBcZFb+K7yuWl28QhjEHD+5iOfJoNadpt5tcW7jCyuoaKEl7cnybq9xapDa0WnWMURgFp+69hx/6D36YbT4TmJKsMRhmGGGoNnyEFAgFU9MTzMzW0HqIu4UDdppS8uJ7h+ZubGzwW7/1W0xNTfEzP/NTHD58mOWlJaSUPPzwQyileP755+kP+lSrVbb6vZICjmGytYsvPvVl1tc2ePjhh/G98R/9Z779NR48+gAePonNOLnnAH4eIA2MzBBfSTwlmG74NEPFdLNFmmUIWwqteVJii4IcbuuJFEXBcDhgYXV8HW1PlTo/UpQOWrdOqsKV8gUASjhwGo+SyOSMZmV5kWtXLnHh3KuYIqdIEu69/25GznLz5iLHp+9lc3N8A+LkwDzTnR4zeYFMLaoWsq8xw4oVBJ5i5FsqvmQ69PDqkiLyGdz3Pg6+8jkudFdZ0YZa1WOQ5/h5Rq0e0+0OEcLiqfGZnm8sPd5KjFZIBcgMazWNliBNLHnqI4VDyO9YownAkCNxpVvM9hEVHMoH6RR5JgjjvLQrGzMqlUo55rAQFootlTBXD3jvybvZ1SyZiWa+xcXFiCVnmGy3qChNGAa8eHGZXqfDbNVjpilZqbQpGlUqUcT60jrJaHxSilFlF2ILS+hqhCbE5AatM5xJ8KWkQKJVgBIhUkZ4KKzTFDqnqi0TRcHh5R5HzhzgyuuvMVzdxIxSfLWzzvtvUkO7NUpxzmGF4/GP/k8svPgsXiixokWlVqURwZHjR6lM7UKEjVJvToC0bkesNYDrVxdoNBpMTDRYXryMh8FTmrgVgCw4enQ/YRCytTVASUW/V6CUYXZ+mn6vx9rKMu2pKTKjefSd3899/QGf+9zn+fCHf4yz514ZOw9hLFZ5dDs5vWHCR//gf+N97/0BiiJD0mc06iKR+JWY9u59pZ41jtAvP7JJE37sgz/E0SNHeNePfARPhYg8p9Vs0OuPr+b33dHtdvnkJz8JwMbGOk88/mleO3+O1dVVDhw4wLPPfpl73nQPWhd86ekvcvjwIe666xSf+JNP8O73vodP/PGf85nPPM70TJsTJ47+3zin/s3hF4bFvA9egC8sr146R0V4SCHpdXuEgUc1DvHqk6x1NM6vIRWlgJxwZNsKhikaYQzKONCGahBzaNf4Outf//ynCcOQuFKjNTlNszGDdgV4GulXMcaifI97ThwDHMPhkD/6+Cd4/eyLxKGPh8A6gR/GICXaCpABkXBUdqAJdGFzjZfSvJT6rUbsx+P6i68xH8dMv6zZoz3mXIyeuZeo0WB18SJ/lO3lwD1v4sGrF5jQmmsOzGBYvsisozHdpFYLUXL8kvzG0uOdRkpVDqmcZMJUyEcZLiyww1KNSnLLpYKy2952milVWMsO3DqHL0sjUytgmDiiaPxCIRB4nodOMgajDm0qTAU1Ll9aYLneZmNlkVbF4+G33M2pqRAjHJ1On/bUNIN+wg2Xk+UF65tbVNozhJUKNxcXMVjC1vjOMYX0KXyH1CHWGpROS2F3p7HbjkOOktWGZ0AU2LxAuwyTp0Trfe6qTPDI3tO8dO5lpkYjrq+sI8MYN+jt6N5sX/Lv0iPeHpC4kn3qK4/XXn0BNxpwuL2HOIro9tfwvDqHzjzK5Mw+nBUYAOcojdh29vVKhhmNmuTKpavUKh6eL4giHxCEYY3lpTV832f55haeFzAx0UAowUbnAtrkxHHM8soaE+0ZhoMhRVFw3333UhSaleXxOzyxTXHWgPAE8/NT4BLS0Ray6gjjAGEUQoTb1Gi97RhdvuykLGUbTh4/TCVW5LnGD9S2kub3Fk888QQ3b95kenqalZUVPvCB9/Pk55/kkUcfIfAD0izlxo0bnD13lp/8iZ/gtXPnmZ6eptVqsXv3Pp566jdRSnHq1F24nVRuoF6bQCmHDBxB4cjylCCKkc4y3Z6iO8hY3+rjWw9Zb1Gf3svhVsDCtatkwz6RlKS6oMgKpHMgFUoJPKlgBz3GTC3B6D4m3STrdNnsb1AYDYFAigDfD3nrw29jV7NS0uVzwcz0JAuBz3A4KE+FVmONxWmNcJYiT2+PAscNHSvqUZ08LUi14GZngKv43IgEF0zCpPSJo4S5zQG58fATyeGVRRb71+gPRojpkGpf4oyj5xyeH1BrVkEUBDsQDHtD0SZKKWxoMdIwWa3w4L5d1NMAb+DjeRInt70Xt3UCAKSQSFE6OwqxTUMVAilKVTOlBAifNB2fZtuYm+Tt73wHew/vJ2hX+dAjj/LgwYM0KxX8iTqt6RmGwMraGocabfzMcvnGOmcvLzFCEs/uIvcq9FOBQKN8yfzePeTOUIjx87BClJ6TBlyuyT1DLnOkywhNhhwN8EYD/LxAZikmHaB1Rp6PIO3h3bzMqUhx3+EDbF56jV1pjur1EMZCb7Cje3PLbq0UAdv+MgtbjgmcwBqDdAVhc4r1Qcaxh97Bm971Yxx55P3kSZ+NaxdZv3IeOxwiBegduWjeviA4A73OgGSU4XsRngoJ/Ihed0Ca5KyvbdKeauP7HsPRkI2NDUZJinWSuV172Lf/IHFcwRpLv99namqK9fV1BsPxvTSFKP0akQrpSWZnJgCNcsVtuU9ji5IubgusyZBopDAINFiN0Rm2GHHq5BG0TpGeINtWsvte4syZM2xtbbG4uMjBgwepxHVO3nWae+89Q6HhxIm7qVYbPPbY38FYqE9MkueWU3e/iUuXrtHpbNGarPPo970VIXd2KJquTNAY5LRHmgnh4ysfYQXKCa4tLvHJx5/iS1/9Jsur61y8usBaZ4vTp+/m/gcfYHZ2loYf0gpjWlFMq1oj8rxtFyxBszG+FGunu0h/tEIyWqbfv06W3gR6+EIjbcbBvXOcPHyASDiqniQOPMKowq69B9CmLNS6yCiypFQGtJq11eVtYbvxi3ezVoXQoT2LtAWr/Q00OWmWczUf8ZWNTZ65ssRSZxlV83GVKu9Kr/L20YAjoaI5NU3Tefh5gZKlwQpKsP/QPjrd8ZuuN7Tz9kPF4aBKy49JCg2pYVe9QracMR1XkGhGUjMoBFoqhAJhwDiBVB5GWjzp4VmHcRpjAae251/jj03e++PvJKjEnH7wEBU/IHviOb7y8lnWOgm7hn3qfkBqcsxyn/xal2OHj7A4N826TpmUgO9zQAaE+Kz21m4jQR558MROGhpwAmkylCk/T8yQyY0O/s3rsL6G7g3pb3XoKA9ZryFqNUZOULM5M8WQdxUbfF90lCC/xJvbk8zsPYLq9flit8fEYGe31hizbScntheSEikUGzcvMex3uHnlLDLpU5toEVdq7D3zLrwwQKdDfuef/gzH7z1DY2qO15/8A6q7j3D0kXczu+cQwNhLTIfhytXXqdfr+H6EEhGyGZbKca5Uj/T9EN8rLbeq9TpBJcZiERJUEHDw4EGcFRy9+xQut2ysrLC2eR3nxh9XOAS+cAxGIz744R9iphFy4/WzGK2Zj/eT6xxhHa7YwLoEqyXJ0OJLgR969BLN2uo6C9cX+ee//PP841/5ddbXOoSej9ih0e2tOHjwIL/2a7/2V343PTMLwD333INzjrvuOrXtbKO466TlV3/113n11VdJ04xDhw7yn//Cf8aBA3t3/H+3JqaJvADhHMUwoRnUkFISxTGvXOlTn9xNJDO0jRkmGl8n+NWQvUcOMzszxWf//E8oMFglSsVQHFZCZzRAFeM7HGXqMFmWUaRDrCmo1xN8XyNVyj2n7uFtb32USwtLXLx8mWarSRD6XL2ygFIhzYkmNxaukG/vUQSOerXCg/fdB85QZON/P7I8w1M+Dd+RZD18LyAMYzwhmKo0uLx4jX5hWVpaJXdncZ7h3DQMfIUYJjQ3l1GxwgMyUyA8R61aZ329S6M5/sn9DS3exmhOHtzPRKVGZ9TjxK42Nzc3yAGZezQCSFzOcichSy2+p/A8xaAo6MsCWwmRwiCV/o4+sy0d2KUdv2x6sU932GVkYVe9QW9rnVRnrA/7bF7sE3oSG0neMreXpZvL+EXCnvsOYIYpoS/JPQh9hY/Er/p4VpQvD8eO3uAAwmQIITG+YWppk7kbS7jFRaZCnyCO6Sc5V4cjNm8sIao1sqRE2exuVjjUUPRXFxlgaNUi/KTHwyeP8IVnvrETnR0sIJxha3mJhcuXOH7/g/hRhcUL5/jSv/0/SIdD0sEmE9UG9UqVTJR2cRPRLobdLZxwRM1pDjz4dtoVzbmXX+G5v/g9fvgj/yVOSMZdwVRqEb1BBy9QNCYm2FpPSJIUpSTFtghZHFeYm5sjiCLCSkyic5TiO44szhJHFbR1xEFMFMRcev0SOzoICIi9kEJa7r3nGBvLi1y7egWLRXuC+d17S1TMxiWcS3DWo7M8oBr6VKoVvnXpJt/+9ssEQcxbHmxx5t67+OxfPofRBt/fgX38d6f0//ACtLY8K5WiVZIi1/zBH3ycF194ZVsBz+fMmTMcOLB3p2sIACaEhyfKUwi+V471pGRQ5ATVFtVawubK64TVwxzZs5ssy3DGlpg+6+ilCUtry4TVCCkojauThMx6xNH46pfTtZiRdGR++Wnr9Xppfyg99u89QKfT5/EvPMOTz3wJIeH0iUN87Utfo96oIsnIiwKEoFKpYE0ppTwaJVhjdiTUlfYHJbCisIzShLhWw+YF/X7KwDmSPMf3Q0SoKFyG8gVK+kSVBgs3Vti39yAj6dEbFNg0weiCIFQEfkih/z2deQul2Ld3F+2JBtrs4qknv4RQkloUUWvXsKMecVChwNHvZFSCCmme0EDBSLOpc1QkkIEEJdiGnsK2u864sbbRZXVjjVh6hElKkQzp9nsYCaIa0M9THJKtfp+gGtJSIfnNLdppH1GN8OfnCOIqk81J0oURDkkYxGgcg3QH4woBmAJXgOdyJq8v0ly6QTtSNGsVNlfXqTUigtBnpePInKGzukwQxsSRj67lXFi4xrQIcMrR6yxz8NRJTJFjdvBQSOCbX/0SF7/xZa6cf5nO2vupV6q89NRncN1VlBcSC8vU1CxWKAqn+daXPsvdb3k7VhfU4oBhd4ug2mDynncwnzouvvwNsv46cXNu/MshxLZcsAWrWLqxjsOg7YiJyTbT022CwGfX3DxOSLSzDLspgfIJw6DEIEuJ1pr19XXqQZU0zbhyYWFbiXG88JTDOMn9993Nw2+5l5deepErC9ep1Os8941XqTcaxJ7g5NG9NGoxRVawurLEVHuWWmH56Ec/wZVrN9i7e5Za5HH61Ame+uI3KUYJnve9dd7fLTH61xuE8tfbLi5C8tzXnueJx59E6/IE5YDH3vH2bY33nf//SgqULF+QnlLoosB5AZvdEZNzR2g2Gjx+4eu0WhOcvu80wyxnNBwRegpjLcYaVpeWiSsRyvfwPIVSHjI3ZEl/7Dz2754t9xGU72JrLd1eDz8ImWs32Vi5SbMWcdfRQ6xtrBEEAWEUU2s0kBSsLC+hpCxVI4Wg1+uxsbnB7n27d3RiFs7iewGD3oi1TgeZZVSSEKNLY3WTGzyTEU9UMDbHjASVapNud42NzSHV3XtoVmpcPnsOVzhq9RpTU9O4NKW/A1u4N7R4I+B3n/08bzlwhIfedJIP/8RPs7S8RN7dYthbItM+oe9xMJ+gs9YjzT36YobKtgj8q68vkBlBbzOjkwywnsKvhFTqBUcPTI+dxpmpXdQOHSOSHpWowu99/uscnN/DY/PzFJsJN9Y3eKW7yrU8ZUoXDJIRetly/cVXUUWXiWOH2PfIQ6x7HrVwgtgPif2AGzevEzD+xQ+0ZpTn+Fub1K8s8KZBj0ymHDpxjPMXrtI1Q+6+6y4qScbmSxvUPcFkbMjNiEJlrEWQjjLsyk0ax09A1VIoH7RFi511eA88+k727N5DHIac+/PfRVqHUwFzc/VP+PMAACAASURBVNNMzeymUD6NXbsofI/e0gpLL32L1cvnsIRE1VlGo3WS9Rs0D5zk1Lt/iqmTD/Hn//LXmT71MD/wwZ8aK4eiKDh9+jTVapVrl64gpEYIQ6NWJSmg3mxy6vRRikyyurZZCvt7pbZ7GPjElQphGFGNawgpeObLX+apzz6OLzPYwS7CF5KJ6Tr/9Ff+UzZvXOWjv/OHRI0J9h48wKc/+xVa7TZCJsxMBtx91zEeOH2MQfEVbp5PWbgueOXCOsurW0jl8/xXnuWe+x/i+9/xMI9/6ukdjfe+O/4mydHv/L2Uql1f3+If/Rf/jEF/QJqmZFlGo9Fg3/7d7N+/l1vbjB1tKwGpHAiN70uscXjKw6iSazHMF3nlG0+xcPkVXjt/D/XWPEdPnqDf67GRJeDg4Nxuml5IFJSL1SzLyPOcSrNKozq+SYZo7kVrTaAMypW8ikpjEmc0zck2J46c4M0PPEgBJCZnrZ9w16mHWd9YAQqKdMjlC2fJkwFXrlxBpyOUUhijd3RiPppE2H5KoSPm6zMUQjAocmaPH2N9s0MzjImkItlIqLcm6Kxs0ZgWJL0tAumxcXWJ2mSdq69fJqxWibTlyvkrbF1fxvf+PTVjEA6KwvD1i6+xNurzyz9+hn5vQHeQ0WzEbHQtcb1Fd3WN6akpvNDj+UtdQjwa9ZCoXmG0OQINNRnjhETkEjPSbHXGn1kd2bMfqUoD1Uxo3ve+d3Phq8/TDmOup5Y49Gh7knkpGfX7bAz6aD9kaXWZwDPw4iW6QZ25Rx+gkNCMQpLugFPz+2hMjO8cE2cFnUyjuuv4N68ye/AAr3c3kV7IlcvXmZ2Zw+QFnW4Xaxx7dzW5uryGlxfMT8bMNqHDkHbbZyCr1Pfu40JnE+E8vHxnHZYxhqlde8kKXXqDKh/lK/w4JK7VqIS10noqTahP1OguL+EZzUA7Dh86Su5ZnIvxrMFJmNx3hLn53Uw2x7d1arVaAPR6PQqjmWhVaU1OoE3Gws0erek21XqNTtYnrgRYoChyXC2iMdkk8EOkAINl4fI1zp89S6NeocjyHeHejXEcP3mAeiXkhZeuMejnyNjR6fZBBLSn9rDZW2K9vwGhxFW2+MF37WGw1efLzxh++w8vU2hNHEd0Ox363S0E20dz9//HIyc4e/ZV/s3H/i3XF24wOTmBsSVBplav8Mgjb+U7HbdlpziF2b0N+sspThqiWognfPADltcMZy+9yuL11xklQ55+5otooWi2m0xVdpOORuRpijQF1TBgslXHVw38bTu5tZUl9NbG2Hnkwy02N9aJKlXCW+OzwCfwFEYochzK6pIHsk0YW15dASyeKrW0sywljipkaUo6GAICrU2J6BozFv+v9s6sR5LsPM/PiRN7RO5VlZW1dXXXTE/PwllIeihK1E4PJdKGZAKWAQuCoMWyZFiARBuWLwwIhi4MQ/ad4RtDlCVBgE3Lhm1ZJE2RkjhcxFk4PTPd0/tW1bVn5b7EHscXOcOhCVPKIokxG4jnB2Seijj5RsV3vu99x2PaTk4wnRBOA87XFvnh9QuIWplPnRygopTpJISuRHctNEOnP+6gpwrXlsS6Yu+kTdALmExD8jAgVzm2YTEYfpceWOpCQxM5OXBjd49PfO6PWWusUi35bCw8hNvtQC7o7WyTuC5CF1TLNlEYMR7PalJKKOI0ZLFeJ4pCDMNiuztmO+zNvY5JHEKSkWiKVCUkYUASBpwMB/SDCN8xeffWOc4Jh+MkRroWd3d3kZpECo0wirjx8kWUUDzxUx8BBIk1CwZIgvn7vMkS9GmE0etztlJC03L8ks/R4RHra+tUKzXGowlHB0dU/BJLiwu49i6u7SCyFFOziMIpSMGNvQ69/SknWYQSkBqnCKcAsmTKC//rExxfewVdaiih4fs+0rRIs4SSIcgNhTZOGIchGysNpsMJURaTK9CdOpgmM2EQSE2y8tiTTIbzP1Sl1NA0Sa/XJ8sFhiUxHYtxZ8zKapPqQnV2OKkipEhI4hTbMpGWwCmVyDIYjHqUNI3n//TLHB3cx7UEpmFTrsz/EHE8jZKtcff6ZY739vBKDnkekqQjtu8dcNwesbjo4Xgho/EYu1zGcRMcy2R9NaC20EC3ckwTJqOQG29cozeMqXo2afqd8s9/qwcfBsMBn/3s53jppZc5OGhTKrn0+z1WV1dYXl7ie7/3e96M+3o7Z/E0lBcULaOJMGNMy8PUBJmSTIZj/uLV6wx6Y7JMEIRTgnBCt31Mz5Fcv3mHlZUmizUPVfPwHB3ftTEMnSROaC1XCU/RBbS3v49nCJLpiEm/x1e/8pc0W8ssNRc5t9pCqDICgfHWHlQ5UZ7jWwqygDiNcDyPv/HeZxFZjsohTjOiBJLkFN0mWLSeeJzXL7/OII0Z64rBksXqeMqCY1FttTg66tLe38cko+R6LK6vUjIt3ltu8ljqcdQLqZVqXAxO6OcJeZDiLDrkp9gf73DZJCfPFUKAFBp/9soLJFHEhbNn+cc//BM0UsGdG/eIzQZn1tZRWUxz0kZVfXr9LiVick/DccosNcoct3P2j/o4qY6V/vVf/xZlDGzLpt/rM0pD7DinKg1MW3DU7iF1HU86BGWfdBJz0O3QXGyyUKow6ncYT8dYpsmNF17FbFRZePoReipis7lBszZ/jTcMJiwedXhac3nvVouou8OTT13g6o1bLC0u8OLLr2BYFo8+ep6ToxNu3N5DCg3XdanUFkhVgtBLSH+JP/rfLzEoV6gtL1A+20Q25xcr8pT/9K/+CU4SUTJ16gsrqDTDsmxKjk2lZJGkI1bOPc5DzXNopRbB4T69/btU+if0woAzrXWqtQpoEgEYSnH+Ax9mdHg09zIefvg8r7zyCrZt4TgW3c6Qg4NjXNdn65GHGQwGdA7uI3OFbtrkSmNjfYN6rc7BfpdXXrlEmk44d26Vw91bmLqEVBLECXE8fzlLIvn+H3ovmRpz8/Z1+kOF5UhK1ZT3f+85ojSmWi/hl3wyDO5e7/P935MgtAbj6ZD1lg9Nh1ZjiZ32CUmgaB+08VyN8Xj+7opvjiJNo1kWZa74Z//0X7C4tECrtcL2nS4XL15ifaPJE088xsc+9mvUG7Vv69uyrslB7xDheNSrklbDRzMdmqsLTHonKJXjlioovUyGS28S8d8/+T9BCR59bItWVUOTAl0KdEOftVhOJuzevM3axvzdL+MwIko0FmplXEsjiQfYsszu7Vd4vmTzoec+goWG73nkAvq9Dr6hMLSMKA5ZX2lhS8ntm9eJxgPCKCSJc159+VV27t2aex0/qJfh4g4/tnKBM7/wqzjnN/G/eIXeH/0pP1N6jMGNABEvYT/8FIvCwjVN0lggyjW67ymx8s9/luyrVzn5g88wunebP3GHfJYRqMmpJl/fUfFWzEZa32pHy5UikXBtextsE6dWZrFe4+pX79LPJPWKj1etMB1PiOOMmmOwWPaIhEQ6Bgf7OeF0ysMbawxPMZRi2xbTwRhN0zA1A1wXw3VQkzG5gEEwQUiJROfgqMPxoMfG2iqeaaPl5VmUkWkShRH3L11n/ZGHWNpYY6m+hCXmH2/VkgQvjFg1bZaqDQI9AiHYOrNFZ9BHSI0omXVPhNMAoSnKfokomv1wU5UzCXMs1ydJEwQQpynmSp2sNH9qe+f+bVZKLu3jgMbiMp6eEUzHKBVTcjREnuL6Pu7SCsJr4JWqeOUG1YfOzzoH4hDLstHN2XfOarKKPIfyQnPudfR63VnnkCZQamaRMBxMqdeXSfKM9tEerlD4joPlSFQusCyLS69d5LWL19g6dx6hOagkwzQyHMPCNFwylb4Z9jrnfUEQJglZHtPuDBByETBQqcL3NBzlYkqXWmkBx7RIU53DI9DlImmmoecDLMNC5RrVWpmFhRoH7TbtTufb8n55G4GuW1y/fos/+9xfcPXKdXy/RKu1zMraIcfHKa7r8Nxzz1GtVf+f07OnoV6xELpHbnpolsQoeeRINrfOcuXSRYbDCa5XJowTjtpH/Pnn/pT3Pb7Oj3/4ORoVF9uYhTcLIUgShZQaQpjUq01ca/7WuCzPidOc5KSHa0kG/QHb9zLq9Qr9Xo9ev0ezvkCcpUzDgL39XfJwTKwr4jBkfXUVz7KZDoeUSiVarRYHR21uXrxMMJ2/0eBq2OUDeZmthy/w2E/9BK9cvci7f/4nufLl1+nsn7Cbj+gGU/7o0iU+Yq/yAW+Jaq3B7ajLIHB47rCLSBLKP/shor98ifd99Q1wF/lc7xrhd6u3CUp8LQdSKSj5Jbw8Jx1P6QyHVBY8So8vUt8vc+PeHZ7aeghhW2/6IUjiFBoln62zq9xvb7OnZ7jrdTpRxDSZf3OORiOiyXSWVK6ZZK5PtdWit71Na2mJQTBLTzeERhYHVHwHoTLIExzHZjKdkOc5vufRvX/I/Vfe4NnFJZLBhOlkQKU2X91bixPqUtLyfZSQlOoLHO4eQSZJk5hSuYS0ykwmUwzdwKuUyXodyl4Jw7CwPIvhdIfDo2N0FWKnMeQZuV8Gc/4a7/G9Wxy326QqI4oGlA0HTWWUfR/bd7FqVbzFDXKnhuvWkPrsAFlKB83SsJyv+3vfOvgRAqk4VXn18uU3WFlpkSQJQRhSLlfQhIPvlTk+aTOdTHBdB9f1yJViMpliuhOyJKBR97CtWVmgWq7QqJWIphl5moLkVOngjq3jl+uYWYzQHMaTMWZsUo9L1Gt1stxgMp4isim+a+D4Vd54QzCeaAQDn7MbDTSpcOwyMnRnk7EqQkqwrfnX8VdxeNDm47/ze9y/v0uvN2TQH3H+kbNIPccwNUzT4Jl3P/21g7hvR7wdw+Y46FJzXGSeIDGQSkNkOf/6X/46X3z+Jfb3Drl04xZ3rrxAybX4uY/+IOvLdUSeotJs1hamZpOrhpR4jkN1s0V+iqGlMIywSzUypTjpD8kzqFQXKVVr2IbF3vY2upT4folOt8P29g4qnhAnin6/z0Kpgu96hFFMo7nCcDhAaJLJqM9pLGcMoJwkZNMRtqMTBhHSc8h1iKIp3WzC8wwYnV3jf+wfYw4yzquIm8sN7A88ye//1r/lRw4z/IdWOfOb/4Da2Q3CP/5jvtQN2DlFkPo7LN4aQs1+347j0GqtcX7tHAumz05nwMmV25wMTnj2TAXpWnzyjdf4+z/9dxh0+uiapP7EQ3R6HUS9RGlaxytP0OOEThgQJvPXTXRpklv5zDwnE5iVCrW1dfqHJ4hJyP7BIaZl8cjjz2CXbHbbJxzu7aJlOZVaA8e2gRyVSbbOrCH7I658/su868M/ShjNX8OLpmOebnhsrSyTlxx8p4HtlOgd9dg+2mVxsck4zOiOR6RCsdvusrxYJZxOOe72GZxEvPt97+c9Tz/ML9oevlGj5/n8h8kYuzq/EdOdKzewFpew0Ol3OniajrHQ4I2dA6K9AKd8zBM/ssl7mo8g3/Sd+drxV/71Bz3ir+yK+Os4s7aILiWSnCDWaSw8gl8eYbg5xzd2ePqZJ8nzmP1uH8ey2Vxb59UXXmI8GJLGCXvaEYvNJoPhgGmQUym5SE2j25uAPv9T5PzDK2iZjunYXLiwxcVX72CVTc5e2GKlrPD1EQYOq+eb7HePGUQp//7fHVCuNInCA37w/Sv4hoflNPn07Ut4VpUIEK6LOoV3xdej3jJhErO5hn/0K7/OcDRkaWmB6XTK1WtXQAuResrm5jof/ODfpFTy+JZdwr6O+nITv7mIEgIyQadzgu2a2KbFBx55hh949L0YpuDi61/kg899iC+/+DKPP/0UpCEaOdPRCNMw0KSFzGHU6XFycsLuQQfHMPihh79nrnX02h3s8RRDasRxiLRKnPQjpmGP7dv3uXvrJpbvs7W1xdHRIb3uEVJThCEoNI7CKZ/61CfJc8EnP/3n2F6NYDJBSlCncCXd3NjCqC0RORb3Xn6NWrXOzWvXGD65Tv9cg1QkWN0D3rWySX/zmN996UV+sZNSef4E8aXbnGyWecE1ePJql8Gv/BblX/57rH3sl+HXfpVqef7um3dUvKWUpCpFCLBsm8Ggz6XJ6yxVamzfv0vJ9KnWGmSaZK21zPZJn89+8S95aO0M9Wadqze32dk9xLy+y9/6ofeg3zpivzchHE8onWLMNglT/FKFxIrJs5QwGLGzu8vu3j6rG2usTqeE05BApZR8l+wgJYhSRBpDf0BtbRVTF+SmRDc04uGAkcrodtsc9Tpc4Om51pEriaeFhHnMolWne3TI7Rs38H2PC48+xrXbd5hGHTzTxvAUJ/02SmmEUcpSs4UnMpqVEkGvxweffTftkyk3whQZxShn/k3Q6xxQ8TX6nWPidEI7gOlJwHE/4OzWWSxdZ3DQBrJZy9A3dQ48fRva11OrNrj41ZvkuYZfr6BJRU5EFKf4fhnLtLm/e4REkomMKEoZjCckaYLjuRz3T2YmZrUGAsl4FGAaOqYpTyXe9YUK/eEJ9foZqo0yiIRoOkGlBo36Ilbew7IMdveHHHanDEYD9na3mYQJkimacKhXV9i+f0y1WkNKnTSOmQQh1Wr1W7o2b4m3lJLXX3+dfr+HImc0GmCYGpqmGI0GbG2dAwx+/Mc/xLfaGviNhFFAkMTkKKRmYXo203DKcDLEKdugFJNgQiZsRlPY2Wnz7PtcyGOScMpkMqUXRkzGAaZufs3+otUok+Xzd3mc9LqcXN5Hajm2ZTCZTonihGq1xtmNFehB2usznQYz73BDp318xGgYsbG5xc79+xiGi1JQqVQwXR/HsTHNmCiK515H+ce+j2x1jSBPeXXnDgfHbU4OD+hs77C7c0BuCNxSiWff9/30Bx3GmqBNOlu3An0/JzB0Lskhe3s73P43t7ifR5TqVTztu/Q/7yRN0UxBlmf0hj3SZEKlXCUhY0CObuSMOwe0KxYLpoGpm3z+9Wt84YVdSo5JpzcFaZAS88EfnWD7Jr1bKc3mAqE+/yawdB1LGkhTAx3SaMrh0SHHkwFL+Rr1xiKUE7rtY4JowjQKsRyHJMhIo5iFSpWzZ9YJgwmvXXuDIIrJZIBCo7E0f423ZFRIkiHSdTCFjW/VWF0+x3F7F9MXlCtl9o/byGlCybJZqFTpj2KkVeJwMGVtoUwvCLFrPpNU47VpzuVhiLCroM0v3lOlGBwcMO10yYTgvT/6UfzaItM4o3v/LumgQzDoz7zGVY7gW+ta+OvY2d7l3t1dGgvLtDbq3Lx1FV3PKFVsyqUGd+7c4+bN66w1V8mznPFwCrpJMB4h7YytzTVyJbAsA1AEwRTbKoMA3Z6/jGS7JkE0ZTyZUKrXaS5X2dvtcPXVa1w4s0a9cQ5pmMSHO0wnE3qHe3iOzlF7l5KlMezH7AQnXLt6HcuxSOIckYFr6ZDPf3AKfF3ZAwzDoN0+5nd+5+MzH5o8I4ymnD9/Dt3QME2dpaUmjz/+JGfPbb75CTnwrfWWv8X9nftUq1Ucx4UsRkOg6yYn/RHmYglyMGUJmeVE4zGmYXG0u8dwMKLT6ZIkCZoQ6ALKdoaW57Oeb6XT6c1/VuV6LmEQkqUhslamVq0yHE9w/RJhlDCZTAnjmEF/hGVZ1Cs1dncPyVJJEN7mpNNBlza2bZGrfObeKQSWV8F05n9D+cxXv0LwpZA4mBAEAd1OjyAIicKINElRgO86/O1f+hWuXH+VSThlWyocBJaCWw2LvpKMdq6TLTSI+wlGGrLcepToFPvjnXUVzAQkCsPUSJMc3XSIkoTD40OiJCaKApQQ9CcxTUviSIUsw3CS0DvKKT+sIewQSxMcjg02z25h2TbPv3SR8Sla44LRhFG3T7lSYTTsc3z5GsFeGykEX3rlEjXH4omtMzx+bpWJyvnKa2+gdJvF5QVWW2tcvn6N5y9+hUatim14eM0m9fU1lvxFpDG/SIynXX7y+97D0fYu+1lCptukC2Xqzjl2dw9JtBLD3MRcW6Z1dg1zOGanG4FpEGuKmw2Hz3kGk1hj0BUIs4zTcFk1DGRp/jeRn/nYb9Le28YrlSjVGgjLQ1Ozf7J7uzf4zB/+Piqd8qn/+p/ZOPswG1vncX3//5r6+05w1O7SWisjZcS9ncvU6gvkmU33OKR81mI6GeN7JUQumIym3N/d5+d/+Zc42t/hS1/8PL3OASurLXxf4fiK1koTz/HIlMbi8vwPVdur0h1MufLGlzh3boOthzZ59l1Pc+mNq/zBJ/6Qxx95jIV6nU7niPFoQBhGnG1VsQ67SC3j8ms3GY2nlByTjcoT/MmnP0M2SXjs0QaTdP7WyTzPieOYl19+mRdfuMgnP/kp4jihUimz1Kziug61WpVnnnmGzc1Nth46R2t55Rs+RfLtPmhNOyOMeygtxJQWhmaTZznLS8scd04YjEbYvkeoUm7evoWl6cQnPYw8olVzMQxj5jSpgWbYjEYh/XFAp9clSucvdxoZ/MCHn8PUTbonHZrN5uzczLW5/sbrbN+9g1KCTqeP7/mEk5havUz7uMN4kqPIMUw5m8QFwihFodCFfqp9fPvWLTRNIN88vyuVfZaaCxiGSafTIZiGjMcj9m++Tmd/j+5gzH9hhC00bCHQdkZgWuRaTtDv4SqLjbVFhJ4hT/Fsf2eHdISaxZkpDceeGUql+SyRRer6m1tMoQkDqc88ksc9iCIFRoznmNTrTRb8CnE3xMk01CRlKsCvz38QlAN1zyMZjxneu8/d7XuM04zEcKisVLDTBE0zyDOFFHD2zAav3ztgcDJkt3OVe/fuoOsavVywsexT8Rq01rZI05g4m//qe80qQQaeW6FaqdGZZtiGxp9fuc6Lt24jyyVOcp1eucLY8+nbPkFNB9MgEYpU18gxCLBQ0kQyxlIjykKgnPkfIp7n4zz8GIqZT4ZQb4YGCEGjuc65J9/Di5/9HE+vr2IYGkky/yvmaTD9EmF/iG06lD2TNE3IsxRdy9AUnH/oHCqf4lgOhq2TaxmHu9sIFI16HduRhGHMeNQmihXHJ2PqdQPHtRmO5+8m0HWNL37+RW7cPODcuXXOr3lM3RGVho/0oXOyTxROMA0d23ZIc0iznDNryziOQZ4LhCF4/MKjKOXx7vc8RffgiMnwCK86/xCXEILf/u3f5vOff544yimVKiwuLuHYNuceWmNtbY2NjQ2effZZPM/7JgL07T9cswSG0zHVik4qE4SK6XWm9DoDVBiCJzkcddhrD7CtJUrlMroeoQuBNA0cy0YTGrnKwXDY2WsznISkCpJTmPC0j49YvXAOXUharWXCMOTGjV08y+Jwd4/mwhJSNwjjCdMgQNMzGhWH2zd7SL3Mua01TkYB02lEEgRoUkMh0PK3o9LmQSmF4G0nQk0K8jwhilN0Q2I7JkIr8R9/93cJpgmonESTpCpnnOezQaJgTKrPWqa1Scbh/glLi0tYxndpq6CmZ0jNIM9SDBeyTCNLZ+EL+uzUgFwpKtUK0oBJMCQe6GRpjlHLMF2Nqu2TT3Iu792kbpbYPT7CbRrIU0zQKaFh2xZJMCE3YPXCw3jjFv3hmL27dxF5ji1mNylVCtNxKDfqTMYhSuVUlposLiyiVM7SxgaG5+OWyyRpQnaKH0tlZYsvD3rYykZrj+mGCr+6yJc6Y9qtVaxGHVkt0697jIQgc13GSs6GcFSOLXX0XEdi4WQxStfRhYXQNWS1fqp789ZGlEK86SI+O5bULJtH3/d+rtx8HaXg7KNP8Fbi0XeaLMsQUsd2XWzXpN3ukqaKMEi4e+cWur5JuVxi0B+BkJTLJW7duMHB4QFRFPLUM49hGga93pDFpWWiKCKMU+I0IDlFPJ0uBQc7RwTTjCtv3OL9Tz2HEAn9UQ9dgJIaKlcsLbUIwxC39Oa4t+diaAam5YJmsLy2iobGmY1VwlHAJ37/9+h353+IZFnGF77wBSzLolbzWWmt0lxusrm5yfd93/toNBp43sz/+TvRVfJNUQaeu0h7t0dnOMTScky9gqZBksfkkcnO3UOmscGde3d51/lVTLeEkDogZyWFaUSORi/o0h0EDCcR6G93n81DmsVocUyW5wgF27ducX9nG0uXVByPcqvJmYc2mUZjXn31NSaTAM+sIIVBqVLjoXObrI8DMiX48iuvgqaTKw0pM8QpwhhgliugoZBSYlsmiowsS9Glhl0qUSrNutoEEYYuSVI1C14B8kyRG2AgcDwbx3YQwiBJMgx5in16ihV/2ygnIZ3MzHHiNEPpE5Dm7PQ4jzGUQAJH/WMapSc5HFcwa0fUl3Uy6dOqrnB39z6RyBCmSVlPMFdMson6WublPNRrNXZP9hkMeoSuZHVzi/UUxv0xKyUdmeQsLCxyOOrjVhtUfZcfeMrHNiyCMEchKPklHNfBLfnkIuGk2+VkEGE781/S5sbTfDruQa4Ik5AgVcSZIv6pv4uj60yzhCCJMdBQ+SyHMFUZUtNmWYCmTqhSciQyzdCNGonWoCstbDl//+zs5rwt2G+FYSilUEJQXljiIz/9C9y9fJlgMsUrlU/lBTGvoJRtD3epSZzEs9Fuv4SUBtVKjSzLcFwbI51F3kVRhOG6XL16FV1aNJdWOD7scv7CefxqnfFkPMu7DEJWFpdx3fnPAMJYMo0VUtfwHI/eNGGhUebCxib99iGojMXF5tfivLQckjQiCBSpoSMdg6XWIrqlsVBfRuUa4/KEn/u1f8jR/eO51/Hxj3+c3/iN32Bzc5NmcxHff+ue5uT529f1O12++kZefPEiC9UKtYU6555cY3TSJhilmL5B7piYQ8njrQ2OjBGTwQTLdjnY6ZBpgiDJCNOZg994HKGUNouFE4JoGiNPIZo7d24y2t9HCcgFqFyxemaNVKX0em2u3wh57eolpv2U4eCENI25dukaaRrzoRZ89r9dZt1apLWxjm873L5zH02anKI7DwDbNjFNC8s03hwos2fhKXnOcDj+2kDY2toa4/GY0WhEGL7t5Z5noGkSiHB3OgAAAwVJREFUIQSeb1Gu+NTrs8CL5BStk+/seLzUiLIcyxYIbWZ2n6UxQmoYlj5L0ck0qpUlrty8x739+1TXBVgRMjfY7e0TWym6bZLngnE8RqqZC9xpLB0d06K6sEC1UaN/fETv4BjbdnA9j8S0qa8s0VhZYef6NSqeTyogjEIWazUsW2C4HkkYMw1DMDT2ju7S7nZZaz2MLee/pG5wwiAaIDOFgSIJAkSWoSWzm58FAaZS6LZJHCcIMTvslZo2C3BOjZn1Jm++yqWTmWeLdHHiEWzNP+35jbwlCErNEuL9ygLl+iJJEnHqKJY5SaKIXHkkWUal7JImOb5fRSAYDHvYjoVp2liWhZSSdrvNxvoZJpOQKEpYXWuiaTrlWoWVjXVG4xFkGZYQGOb8h3Zf/PKLTIOINFXYVZ8wyfErdWynxP3dV8mzhPF4SrlcptvtYjk2aSJYWlykVHFZaLUoVWoYuoVlWgwnIZphoCUG9bX5a+8f/ehHWVh4u+XzrT3+VrvgO4UIdU56Y1LPJklTRDUgsUzwNEzfQTsyINT5ysXLSOkStNs80fDpTKZkSFSumAYxCB2haaRJMgv3kBL9FBOF62srOJZNms3q5IZhoEmByGFhoYHt2HhCw8z6uKYJUkOzm2hZzPpak1bd4t7dPpGd8O5HHqNaK3P9xl3CSJ0yJEOg6xJNSpSCIIhmgdxKIaWOaQryXBEEAUIIyuUySg1J05kBlumZs3Qqw2RldQHL0pC6wNCNWTbBvKs4rf90QUFBQcH/f97RGLSCgoKCgu8MhXgXFBQUPIAU4l1QUFDwAFKId0FBQcEDSCHeBQUFBQ8ghXgXFBQUPIAU4l1QUFDwAFKId0FBQcEDSCHeBQUFBQ8ghXgXFBQUPIAU4l1QUFDwAFKId0FBQcEDSCHeBQUFBQ8ghXgXFBQUPIAU4l1QUFDwAFKId0FBQcEDSCHeBQUFBQ8ghXgXFBQUPIAU4l1QUFDwAFKId0FBQcEDSCHeBQUFBQ8ghXgXFBQUPIAU4l1QUFDwAPJ/AFzOZiTUuKJqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05b1f0f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An important way to gain intuition about how an algorithm works is to\n",
    "# visualize the mistakes that it makes. In this visualization, we show examples\n",
    "# of images that are misclassified by our current system. The first column\n",
    "# shows images that our system labeled as \"plane\" but whose true label is\n",
    "# something other than \"plane\".\n",
    "\n",
    "examples_per_class = 8\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for cls, cls_name in enumerate(classes):\n",
    "    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]\n",
    "    idxs = np.random.choice(idxs, examples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)\n",
    "        plt.imshow(X_test[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline question 1:\n",
    "Describe the misclassification results that you see. Do they make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network on image features\n",
    "Earlier in this assigment we saw that training a two-layer neural network on raw pixels achieved better classification performance than linear classifiers on raw pixels. In this notebook we have seen that linear classifiers on image features outperform linear classifiers on raw pixels. \n",
    "\n",
    "For completeness, we should also try training a neural network on image features. This approach should outperform all previous approaches: you should easily be able to achieve over 55% classification accuracy on the test set; our best model achieves about 60% classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 155)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  hs  1500  lr  0.006922009920220811  reg  3.392601183470151  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "0  hs  1500  lr  0.006922009920220811  reg  3.392601183470151  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "0  hs  1500  lr  0.006922009920220811  reg  3.392601183470151  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "1  hs  1500  lr  1.053724044524556  reg  0.09914420991404721  decay  1  train accuracy:  0.2959591836734694  val accuracy:  0.282\n",
      "1  hs  1500  lr  1.053724044524556  reg  0.09914420991404721  decay  0.95  train accuracy:  0.2813673469387755  val accuracy:  0.289\n",
      "1  hs  1500  lr  1.053724044524556  reg  0.09914420991404721  decay  0.99  train accuracy:  0.28183673469387754  val accuracy:  0.265\n",
      "2  hs  1500  lr  1.593443417330588  reg  0.26798621972061104  decay  1  train accuracy:  0.1676326530612245  val accuracy:  0.161\n",
      "2  hs  1500  lr  1.593443417330588  reg  0.26798621972061104  decay  0.95  train accuracy:  0.1473061224489796  val accuracy:  0.124\n",
      "2  hs  1500  lr  1.593443417330588  reg  0.26798621972061104  decay  0.99  train accuracy:  0.09979591836734694  val accuracy:  0.112\n",
      "3  hs  1500  lr  0.23645412822368647  reg  0.7800617946675162  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "3  hs  1500  lr  0.23645412822368647  reg  0.7800617946675162  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "3  hs  1500  lr  0.23645412822368647  reg  0.7800617946675162  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "4  hs  1500  lr  0.0073420487737853955  reg  1.614580895172121  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "4  hs  1500  lr  0.0073420487737853955  reg  1.614580895172121  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "4  hs  1500  lr  0.0073420487737853955  reg  1.614580895172121  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "5  hs  1500  lr  0.0061172557987027995  reg  0.002326041865910338  decay  1  train accuracy:  0.21191836734693878  val accuracy:  0.214\n",
      "5  hs  1500  lr  0.0061172557987027995  reg  0.002326041865910338  decay  0.95  train accuracy:  0.2043673469387755  val accuracy:  0.179\n",
      "5  hs  1500  lr  0.0061172557987027995  reg  0.002326041865910338  decay  0.99  train accuracy:  0.21548979591836734  val accuracy:  0.21\n",
      "6  hs  1500  lr  0.1411656724909486  reg  0.006435046360988215  decay  1  train accuracy:  0.5460408163265306  val accuracy:  0.527\n",
      "6  hs  1500  lr  0.1411656724909486  reg  0.006435046360988215  decay  0.95  train accuracy:  0.5433673469387755  val accuracy:  0.524\n",
      "6  hs  1500  lr  0.1411656724909486  reg  0.006435046360988215  decay  0.99  train accuracy:  0.5463673469387755  val accuracy:  0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:101: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = np.sum(-np.log(scores[np.arange(N), y]))\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:98: RuntimeWarning: overflow encountered in subtract\n",
      "  scores = scores - np.max(scores, axis=1)[:, np.newaxis]  # for numerical stability\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:98: RuntimeWarning: invalid value encountered in subtract\n",
      "  scores = scores - np.max(scores, axis=1)[:, np.newaxis]  # for numerical stability\n",
      "/home/reut/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/reut/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:120: RuntimeWarning: invalid value encountered in less_equal\n",
      "  dH1[R1 <= 0] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  hs  1500  lr  1.622146978839315  reg  0.7884413049529618  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "7  hs  1500  lr  1.622146978839315  reg  0.7884413049529618  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += reg * (np.sum(W1 * W1) + np.sum(W2 * W2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  hs  1500  lr  1.622146978839315  reg  0.7884413049529618  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "8  hs  1500  lr  0.4100555764872635  reg  1.9341542391282138  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "8  hs  1500  lr  0.4100555764872635  reg  1.9341542391282138  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "8  hs  1500  lr  0.4100555764872635  reg  1.9341542391282138  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "9  hs  1500  lr  0.10855954724582804  reg  1.643272746226144e-05  decay  1  train accuracy:  0.6160204081632653  val accuracy:  0.573\n",
      "9  hs  1500  lr  0.10855954724582804  reg  1.643272746226144e-05  decay  0.95  train accuracy:  0.5853877551020408  val accuracy:  0.561\n",
      "9  hs  1500  lr  0.10855954724582804  reg  1.643272746226144e-05  decay  0.99  train accuracy:  0.6119591836734694  val accuracy:  0.566\n",
      "10  hs  1500  lr  0.002411290290775852  reg  0.007500321603591762  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "10  hs  1500  lr  0.002411290290775852  reg  0.007500321603591762  decay  0.95  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "10  hs  1500  lr  0.002411290290775852  reg  0.007500321603591762  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "11  hs  1500  lr  1.2454223237344482  reg  6.719002024859813e-05  decay  1  train accuracy:  0.8132857142857143  val accuracy:  0.564\n",
      "11  hs  1500  lr  1.2454223237344482  reg  6.719002024859813e-05  decay  0.95  train accuracy:  0.8910204081632653  val accuracy:  0.597\n",
      "11  hs  1500  lr  1.2454223237344482  reg  6.719002024859813e-05  decay  0.99  train accuracy:  0.8487142857142858  val accuracy:  0.559\n",
      "12  hs  1500  lr  0.13930010457537795  reg  1.5088751911504472e-05  decay  1  train accuracy:  0.6462040816326531  val accuracy:  0.588\n",
      "12  hs  1500  lr  0.13930010457537795  reg  1.5088751911504472e-05  decay  0.95  train accuracy:  0.6172244897959184  val accuracy:  0.583\n",
      "12  hs  1500  lr  0.13930010457537795  reg  1.5088751911504472e-05  decay  0.99  train accuracy:  0.640734693877551  val accuracy:  0.59\n",
      "13  hs  1500  lr  0.30046200774107623  reg  0.01152529775658834  decay  1  train accuracy:  0.5091836734693878  val accuracy:  0.509\n",
      "13  hs  1500  lr  0.30046200774107623  reg  0.01152529775658834  decay  0.95  train accuracy:  0.5249795918367347  val accuracy:  0.513\n",
      "13  hs  1500  lr  0.30046200774107623  reg  0.01152529775658834  decay  0.99  train accuracy:  0.5178571428571429  val accuracy:  0.499\n",
      "14  hs  1500  lr  0.4367786178695316  reg  0.020209298283248373  decay  1  train accuracy:  0.4849387755102041  val accuracy:  0.477\n",
      "14  hs  1500  lr  0.4367786178695316  reg  0.020209298283248373  decay  0.95  train accuracy:  0.5000204081632653  val accuracy:  0.491\n",
      "14  hs  1500  lr  0.4367786178695316  reg  0.020209298283248373  decay  0.99  train accuracy:  0.47375510204081633  val accuracy:  0.458\n",
      "15  hs  1500  lr  9.510081294241752  reg  1.3546642100293802  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "15  hs  1500  lr  9.510081294241752  reg  1.3546642100293802  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "15  hs  1500  lr  9.510081294241752  reg  1.3546642100293802  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "16  hs  1500  lr  0.7378765400030985  reg  0.008311660960942307  decay  1  train accuracy:  0.5020408163265306  val accuracy:  0.493\n",
      "16  hs  1500  lr  0.7378765400030985  reg  0.008311660960942307  decay  0.95  train accuracy:  0.5310204081632653  val accuracy:  0.502\n",
      "16  hs  1500  lr  0.7378765400030985  reg  0.008311660960942307  decay  0.99  train accuracy:  0.5056938775510204  val accuracy:  0.47\n",
      "17  hs  1500  lr  0.03030107758755209  reg  0.3924041644831519  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "17  hs  1500  lr  0.03030107758755209  reg  0.3924041644831519  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "17  hs  1500  lr  0.03030107758755209  reg  0.3924041644831519  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "18  hs  1500  lr  0.03378175583192007  reg  0.006018774956326217  decay  1  train accuracy:  0.5158571428571429  val accuracy:  0.506\n",
      "18  hs  1500  lr  0.03378175583192007  reg  0.006018774956326217  decay  0.95  train accuracy:  0.49642857142857144  val accuracy:  0.478\n",
      "18  hs  1500  lr  0.03378175583192007  reg  0.006018774956326217  decay  0.99  train accuracy:  0.5125306122448979  val accuracy:  0.504\n",
      "19  hs  1500  lr  0.045222895173098125  reg  0.1540805130989323  decay  1  train accuracy:  0.2756938775510204  val accuracy:  0.29\n",
      "19  hs  1500  lr  0.045222895173098125  reg  0.1540805130989323  decay  0.95  train accuracy:  0.20053061224489796  val accuracy:  0.207\n",
      "19  hs  1500  lr  0.045222895173098125  reg  0.1540805130989323  decay  0.99  train accuracy:  0.25314285714285717  val accuracy:  0.273\n",
      "20  hs  1500  lr  1.2417747445837704  reg  6.205820480980416e-05  decay  1  train accuracy:  0.8443469387755103  val accuracy:  0.579\n",
      "20  hs  1500  lr  1.2417747445837704  reg  6.205820480980416e-05  decay  0.95  train accuracy:  0.8916122448979592  val accuracy:  0.577\n",
      "20  hs  1500  lr  1.2417747445837704  reg  6.205820480980416e-05  decay  0.99  train accuracy:  0.8461224489795919  val accuracy:  0.562\n",
      "21  hs  1500  lr  1.0724418627075574  reg  0.0002043620903864293  decay  1  train accuracy:  0.8049387755102041  val accuracy:  0.556\n",
      "21  hs  1500  lr  1.0724418627075574  reg  0.0002043620903864293  decay  0.95  train accuracy:  0.8612857142857143  val accuracy:  0.593\n",
      "21  hs  1500  lr  1.0724418627075574  reg  0.0002043620903864293  decay  0.99  train accuracy:  0.814469387755102  val accuracy:  0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reut/cs231n_assignment1/cs231n/classifiers/neural_net.py:103: RuntimeWarning: overflow encountered in multiply\n",
      "  loss += reg * (np.sum(W1 * W1) + np.sum(W2 * W2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22  hs  1500  lr  6.163023593392501  reg  4.262821344855317e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  1500  lr  6.163023593392501  reg  4.262821344855317e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  1500  lr  6.163023593392501  reg  4.262821344855317e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "23  hs  1500  lr  5.840366494676413  reg  0.2830158076149142  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "23  hs  1500  lr  5.840366494676413  reg  0.2830158076149142  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "23  hs  1500  lr  5.840366494676413  reg  0.2830158076149142  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "24  hs  1500  lr  0.011629809277380842  reg  0.10318498553007052  decay  1  train accuracy:  0.18724489795918367  val accuracy:  0.188\n",
      "24  hs  1500  lr  0.011629809277380842  reg  0.10318498553007052  decay  0.95  train accuracy:  0.144  val accuracy:  0.117\n",
      "24  hs  1500  lr  0.011629809277380842  reg  0.10318498553007052  decay  0.99  train accuracy:  0.14516326530612245  val accuracy:  0.139\n",
      "25  hs  1500  lr  0.002066548942109967  reg  0.0017224257655053907  decay  1  train accuracy:  0.10187755102040816  val accuracy:  0.098\n",
      "25  hs  1500  lr  0.002066548942109967  reg  0.0017224257655053907  decay  0.95  train accuracy:  0.16285714285714287  val accuracy:  0.162\n",
      "25  hs  1500  lr  0.002066548942109967  reg  0.0017224257655053907  decay  0.99  train accuracy:  0.17195918367346938  val accuracy:  0.147\n",
      "26  hs  1500  lr  0.00723548879420383  reg  0.3723450610072617  decay  1  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "26  hs  1500  lr  0.00723548879420383  reg  0.3723450610072617  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "26  hs  1500  lr  0.00723548879420383  reg  0.3723450610072617  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "27  hs  1500  lr  3.6045672717512836  reg  3.143182548171387e-05  decay  1  train accuracy:  0.6556122448979592  val accuracy:  0.484\n",
      "27  hs  1500  lr  3.6045672717512836  reg  3.143182548171387e-05  decay  0.95  train accuracy:  0.8432448979591837  val accuracy:  0.535\n",
      "27  hs  1500  lr  3.6045672717512836  reg  3.143182548171387e-05  decay  0.99  train accuracy:  0.7073061224489796  val accuracy:  0.522\n",
      "28  hs  1500  lr  0.0039045511908867903  reg  0.41962325526471467  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "28  hs  1500  lr  0.0039045511908867903  reg  0.41962325526471467  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "28  hs  1500  lr  0.0039045511908867903  reg  0.41962325526471467  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "29  hs  1500  lr  0.005122546228897555  reg  0.0008338977781327262  decay  1  train accuracy:  0.21291836734693878  val accuracy:  0.209\n",
      "29  hs  1500  lr  0.005122546228897555  reg  0.0008338977781327262  decay  0.95  train accuracy:  0.16716326530612244  val accuracy:  0.161\n",
      "29  hs  1500  lr  0.005122546228897555  reg  0.0008338977781327262  decay  0.99  train accuracy:  0.18185714285714286  val accuracy:  0.18\n",
      "30  hs  1500  lr  0.4917235324167973  reg  6.569398793730002e-05  decay  1  train accuracy:  0.8022040816326531  val accuracy:  0.583\n",
      "30  hs  1500  lr  0.4917235324167973  reg  6.569398793730002e-05  decay  0.95  train accuracy:  0.7971632653061225  val accuracy:  0.6\n",
      "30  hs  1500  lr  0.4917235324167973  reg  6.569398793730002e-05  decay  0.99  train accuracy:  0.8023061224489796  val accuracy:  0.583\n",
      "31  hs  1500  lr  0.027046028391450292  reg  0.0012673495307035918  decay  1  train accuracy:  0.5100816326530613  val accuracy:  0.504\n",
      "31  hs  1500  lr  0.027046028391450292  reg  0.0012673495307035918  decay  0.95  train accuracy:  0.48377551020408166  val accuracy:  0.474\n",
      "31  hs  1500  lr  0.027046028391450292  reg  0.0012673495307035918  decay  0.99  train accuracy:  0.5061020408163265  val accuracy:  0.501\n",
      "32  hs  1500  lr  0.7935085112546687  reg  0.7176399790370109  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "32  hs  1500  lr  0.7935085112546687  reg  0.7176399790370109  decay  0.95  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "32  hs  1500  lr  0.7935085112546687  reg  0.7176399790370109  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "33  hs  1500  lr  0.25057840047144525  reg  1.4467833793905787  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "33  hs  1500  lr  0.25057840047144525  reg  1.4467833793905787  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "33  hs  1500  lr  0.25057840047144525  reg  1.4467833793905787  decay  0.99  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "34  hs  1500  lr  5.050831390373565  reg  0.0023024420685384818  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "34  hs  1500  lr  5.050831390373565  reg  0.0023024420685384818  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "34  hs  1500  lr  5.050831390373565  reg  0.0023024420685384818  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "35  hs  1500  lr  2.149394485030444  reg  0.015881214504534842  decay  1  train accuracy:  0.3873265306122449  val accuracy:  0.378\n",
      "35  hs  1500  lr  2.149394485030444  reg  0.015881214504534842  decay  0.95  train accuracy:  0.4392857142857143  val accuracy:  0.442\n",
      "35  hs  1500  lr  2.149394485030444  reg  0.015881214504534842  decay  0.99  train accuracy:  0.39077551020408163  val accuracy:  0.376\n",
      "36  hs  1500  lr  0.4517741287085165  reg  0.0005996266274838653  decay  1  train accuracy:  0.7418367346938776  val accuracy:  0.595\n",
      "36  hs  1500  lr  0.4517741287085165  reg  0.0005996266274838653  decay  0.95  train accuracy:  0.7335714285714285  val accuracy:  0.606\n",
      "36  hs  1500  lr  0.4517741287085165  reg  0.0005996266274838653  decay  0.99  train accuracy:  0.7462857142857143  val accuracy:  0.581\n",
      "37  hs  1500  lr  0.26611426946848993  reg  0.43993149091314754  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "37  hs  1500  lr  0.26611426946848993  reg  0.43993149091314754  decay  0.95  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "37  hs  1500  lr  0.26611426946848993  reg  0.43993149091314754  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "38  hs  1500  lr  0.0012933939074205136  reg  5.9954464946353685  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "38  hs  1500  lr  0.0012933939074205136  reg  5.9954464946353685  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "38  hs  1500  lr  0.0012933939074205136  reg  5.9954464946353685  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "39  hs  1500  lr  0.17836387219163993  reg  1.9619915167666964  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "39  hs  1500  lr  0.17836387219163993  reg  1.9619915167666964  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "39  hs  1500  lr  0.17836387219163993  reg  1.9619915167666964  decay  0.99  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "40  hs  1500  lr  2.0345047339689537  reg  4.560822439000271  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "40  hs  1500  lr  2.0345047339689537  reg  4.560822439000271  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "40  hs  1500  lr  2.0345047339689537  reg  4.560822439000271  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "41  hs  1500  lr  1.5332709031148004  reg  0.03638615867025239  decay  1  train accuracy:  0.35077551020408165  val accuracy:  0.355\n",
      "41  hs  1500  lr  1.5332709031148004  reg  0.03638615867025239  decay  0.95  train accuracy:  0.40085714285714286  val accuracy:  0.405\n",
      "41  hs  1500  lr  1.5332709031148004  reg  0.03638615867025239  decay  0.99  train accuracy:  0.3676734693877551  val accuracy:  0.37\n",
      "42  hs  1500  lr  0.015705349658884378  reg  1.847439886625753e-05  decay  1  train accuracy:  0.44812244897959186  val accuracy:  0.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42  hs  1500  lr  0.015705349658884378  reg  1.847439886625753e-05  decay  0.95  train accuracy:  0.3889183673469388  val accuracy:  0.388\n",
      "42  hs  1500  lr  0.015705349658884378  reg  1.847439886625753e-05  decay  0.99  train accuracy:  0.43659183673469387  val accuracy:  0.418\n",
      "43  hs  1500  lr  0.007854613128907307  reg  3.6781302903192756  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "43  hs  1500  lr  0.007854613128907307  reg  3.6781302903192756  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "43  hs  1500  lr  0.007854613128907307  reg  3.6781302903192756  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "44  hs  1500  lr  0.015642295289609025  reg  0.0008008257668319866  decay  1  train accuracy:  0.4478367346938775  val accuracy:  0.437\n",
      "44  hs  1500  lr  0.015642295289609025  reg  0.0008008257668319866  decay  0.95  train accuracy:  0.3804489795918367  val accuracy:  0.374\n",
      "44  hs  1500  lr  0.015642295289609025  reg  0.0008008257668319866  decay  0.99  train accuracy:  0.4326326530612245  val accuracy:  0.419\n",
      "45  hs  1500  lr  1.052399782656655  reg  0.001168398710328293  decay  1  train accuracy:  0.6645714285714286  val accuracy:  0.566\n",
      "45  hs  1500  lr  1.052399782656655  reg  0.001168398710328293  decay  0.95  train accuracy:  0.7073877551020408  val accuracy:  0.592\n",
      "45  hs  1500  lr  1.052399782656655  reg  0.001168398710328293  decay  0.99  train accuracy:  0.675795918367347  val accuracy:  0.585\n",
      "46  hs  1500  lr  0.2109885773461353  reg  4.3604839315472325e-05  decay  1  train accuracy:  0.7037551020408164  val accuracy:  0.61\n",
      "46  hs  1500  lr  0.2109885773461353  reg  4.3604839315472325e-05  decay  0.95  train accuracy:  0.6716122448979592  val accuracy:  0.611\n",
      "46  hs  1500  lr  0.2109885773461353  reg  4.3604839315472325e-05  decay  0.99  train accuracy:  0.6935714285714286  val accuracy:  0.604\n",
      "47  hs  1500  lr  0.003383432083878616  reg  0.01410934013046635  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "47  hs  1500  lr  0.003383432083878616  reg  0.01410934013046635  decay  0.95  train accuracy:  0.18246938775510205  val accuracy:  0.179\n",
      "47  hs  1500  lr  0.003383432083878616  reg  0.01410934013046635  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.079\n",
      "48  hs  1500  lr  0.8916884770588731  reg  0.00030771284022101285  decay  1  train accuracy:  0.784469387755102  val accuracy:  0.577\n",
      "48  hs  1500  lr  0.8916884770588731  reg  0.00030771284022101285  decay  0.95  train accuracy:  0.8270204081632653  val accuracy:  0.602\n",
      "48  hs  1500  lr  0.8916884770588731  reg  0.00030771284022101285  decay  0.99  train accuracy:  0.803795918367347  val accuracy:  0.581\n",
      "49  hs  1500  lr  0.005082406713948229  reg  0.005592363767635877  decay  1  train accuracy:  0.1976734693877551  val accuracy:  0.203\n",
      "49  hs  1500  lr  0.005082406713948229  reg  0.005592363767635877  decay  0.95  train accuracy:  0.17208163265306123  val accuracy:  0.159\n",
      "49  hs  1500  lr  0.005082406713948229  reg  0.005592363767635877  decay  0.99  train accuracy:  0.20446938775510204  val accuracy:  0.228\n",
      "50  hs  1500  lr  5.908239604371589  reg  0.45084728546200864  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "50  hs  1500  lr  5.908239604371589  reg  0.45084728546200864  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "50  hs  1500  lr  5.908239604371589  reg  0.45084728546200864  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "51  hs  1500  lr  0.38132001528230725  reg  0.010478227496734336  decay  1  train accuracy:  0.5129591836734694  val accuracy:  0.524\n",
      "51  hs  1500  lr  0.38132001528230725  reg  0.010478227496734336  decay  0.95  train accuracy:  0.5213877551020408  val accuracy:  0.515\n",
      "51  hs  1500  lr  0.38132001528230725  reg  0.010478227496734336  decay  0.99  train accuracy:  0.516673469387755  val accuracy:  0.508\n",
      "52  hs  1500  lr  8.724607702364139  reg  0.01595688085400246  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  1500  lr  8.724607702364139  reg  0.01595688085400246  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  1500  lr  8.724607702364139  reg  0.01595688085400246  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "53  hs  1500  lr  0.005137041738293634  reg  0.0019721274055262794  decay  1  train accuracy:  0.19438775510204082  val accuracy:  0.192\n",
      "53  hs  1500  lr  0.005137041738293634  reg  0.0019721274055262794  decay  0.95  train accuracy:  0.2601428571428571  val accuracy:  0.261\n",
      "53  hs  1500  lr  0.005137041738293634  reg  0.0019721274055262794  decay  0.99  train accuracy:  0.20234693877551022  val accuracy:  0.207\n",
      "54  hs  1500  lr  0.6447942758040108  reg  0.0025790719404728203  decay  1  train accuracy:  0.6114489795918367  val accuracy:  0.581\n",
      "54  hs  1500  lr  0.6447942758040108  reg  0.0025790719404728203  decay  0.95  train accuracy:  0.6370408163265306  val accuracy:  0.587\n",
      "54  hs  1500  lr  0.6447942758040108  reg  0.0025790719404728203  decay  0.99  train accuracy:  0.6230816326530613  val accuracy:  0.558\n",
      "55  hs  1500  lr  0.0013739737186517318  reg  0.019989747816569276  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "55  hs  1500  lr  0.0013739737186517318  reg  0.019989747816569276  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "55  hs  1500  lr  0.0013739737186517318  reg  0.019989747816569276  decay  0.99  train accuracy:  0.16048979591836735  val accuracy:  0.137\n",
      "56  hs  1500  lr  0.0073179693993295275  reg  0.0013313488652304216  decay  1  train accuracy:  0.2350204081632653  val accuracy:  0.251\n",
      "56  hs  1500  lr  0.0073179693993295275  reg  0.0013313488652304216  decay  0.95  train accuracy:  0.21261224489795919  val accuracy:  0.216\n",
      "56  hs  1500  lr  0.0073179693993295275  reg  0.0013313488652304216  decay  0.99  train accuracy:  0.22102040816326532  val accuracy:  0.228\n",
      "57  hs  1500  lr  0.012444381738988241  reg  0.0010958812342847  decay  1  train accuracy:  0.39085714285714285  val accuracy:  0.382\n",
      "57  hs  1500  lr  0.012444381738988241  reg  0.0010958812342847  decay  0.95  train accuracy:  0.29189795918367345  val accuracy:  0.296\n",
      "57  hs  1500  lr  0.012444381738988241  reg  0.0010958812342847  decay  0.99  train accuracy:  0.37851020408163266  val accuracy:  0.37\n",
      "58  hs  1500  lr  1.0705174195378788  reg  5.73406316760025  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "58  hs  1500  lr  1.0705174195378788  reg  5.73406316760025  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "58  hs  1500  lr  1.0705174195378788  reg  5.73406316760025  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "59  hs  1500  lr  4.966490189000982  reg  0.10593562002116312  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "59  hs  1500  lr  4.966490189000982  reg  0.10593562002116312  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "59  hs  1500  lr  4.966490189000982  reg  0.10593562002116312  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "60  hs  1500  lr  0.009122566927149306  reg  0.0031229308267428685  decay  1  train accuracy:  0.2779387755102041  val accuracy:  0.292\n",
      "60  hs  1500  lr  0.009122566927149306  reg  0.0031229308267428685  decay  0.95  train accuracy:  0.22153061224489795  val accuracy:  0.232\n",
      "60  hs  1500  lr  0.009122566927149306  reg  0.0031229308267428685  decay  0.99  train accuracy:  0.2683061224489796  val accuracy:  0.287\n",
      "61  hs  1500  lr  0.0012148177622471044  reg  0.0008827085009240093  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "61  hs  1500  lr  0.0012148177622471044  reg  0.0008827085009240093  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "61  hs  1500  lr  0.0012148177622471044  reg  0.0008827085009240093  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "62  hs  1500  lr  0.01955411107065619  reg  0.00038499546023702813  decay  1  train accuracy:  0.4793877551020408  val accuracy:  0.47\n",
      "62  hs  1500  lr  0.01955411107065619  reg  0.00038499546023702813  decay  0.95  train accuracy:  0.4375918367346939  val accuracy:  0.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62  hs  1500  lr  0.01955411107065619  reg  0.00038499546023702813  decay  0.99  train accuracy:  0.47383673469387755  val accuracy:  0.461\n",
      "63  hs  1500  lr  0.11721090746507716  reg  6.024918754148546  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "63  hs  1500  lr  0.11721090746507716  reg  6.024918754148546  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "63  hs  1500  lr  0.11721090746507716  reg  6.024918754148546  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "64  hs  1500  lr  1.8687386007380535  reg  3.17229775631265e-05  decay  1  train accuracy:  0.8020204081632653  val accuracy:  0.508\n",
      "64  hs  1500  lr  1.8687386007380535  reg  3.17229775631265e-05  decay  0.95  train accuracy:  0.9021020408163265  val accuracy:  0.562\n",
      "64  hs  1500  lr  1.8687386007380535  reg  3.17229775631265e-05  decay  0.99  train accuracy:  0.8230816326530612  val accuracy:  0.55\n",
      "65  hs  1500  lr  6.23771419795609  reg  0.21586047565077762  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "65  hs  1500  lr  6.23771419795609  reg  0.21586047565077762  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "65  hs  1500  lr  6.23771419795609  reg  0.21586047565077762  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "66  hs  1500  lr  2.6349644831655414  reg  0.9418090353606008  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "66  hs  1500  lr  2.6349644831655414  reg  0.9418090353606008  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "66  hs  1500  lr  2.6349644831655414  reg  0.9418090353606008  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "67  hs  1500  lr  3.544102665851339  reg  0.0031107472369454807  decay  1  train accuracy:  0.30781632653061225  val accuracy:  0.307\n",
      "67  hs  1500  lr  3.544102665851339  reg  0.0031107472369454807  decay  0.95  train accuracy:  0.5082857142857143  val accuracy:  0.485\n",
      "67  hs  1500  lr  3.544102665851339  reg  0.0031107472369454807  decay  0.99  train accuracy:  0.3890612244897959  val accuracy:  0.394\n",
      "68  hs  1500  lr  0.4817646069519853  reg  0.0026611372826849103  decay  1  train accuracy:  0.6182857142857143  val accuracy:  0.573\n",
      "68  hs  1500  lr  0.4817646069519853  reg  0.0026611372826849103  decay  0.95  train accuracy:  0.6314897959183673  val accuracy:  0.58\n",
      "68  hs  1500  lr  0.4817646069519853  reg  0.0026611372826849103  decay  0.99  train accuracy:  0.6251020408163265  val accuracy:  0.588\n",
      "69  hs  1500  lr  0.0011039552783881491  reg  0.08447342282036477  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "69  hs  1500  lr  0.0011039552783881491  reg  0.08447342282036477  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "69  hs  1500  lr  0.0011039552783881491  reg  0.08447342282036477  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "computed in  12329.623196601868 s\n",
      "0  hs  1000  lr  0.001278432609672209  reg  0.4008404208009969  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "0  hs  1000  lr  0.001278432609672209  reg  0.4008404208009969  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "0  hs  1000  lr  0.001278432609672209  reg  0.4008404208009969  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "1  hs  1000  lr  0.018708936166181512  reg  0.00023196722224098925  decay  1  train accuracy:  0.4715714285714286  val accuracy:  0.461\n",
      "1  hs  1000  lr  0.018708936166181512  reg  0.00023196722224098925  decay  0.95  train accuracy:  0.42012244897959183  val accuracy:  0.414\n",
      "1  hs  1000  lr  0.018708936166181512  reg  0.00023196722224098925  decay  0.99  train accuracy:  0.4627551020408163  val accuracy:  0.449\n",
      "2  hs  1000  lr  0.24466357678602257  reg  4.584385095645264  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "2  hs  1000  lr  0.24466357678602257  reg  4.584385095645264  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "2  hs  1000  lr  0.24466357678602257  reg  4.584385095645264  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  1000  lr  8.51687148138178  reg  0.3957267590616846  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  1000  lr  8.51687148138178  reg  0.3957267590616846  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  1000  lr  8.51687148138178  reg  0.3957267590616846  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "4  hs  1000  lr  8.55107916145851  reg  1.8466163111920576e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "4  hs  1000  lr  8.55107916145851  reg  1.8466163111920576e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "4  hs  1000  lr  8.55107916145851  reg  1.8466163111920576e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "5  hs  1000  lr  0.14927698957172178  reg  3.252376614519886  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "5  hs  1000  lr  0.14927698957172178  reg  3.252376614519886  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "5  hs  1000  lr  0.14927698957172178  reg  3.252376614519886  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "6  hs  1000  lr  0.3417274762920247  reg  2.7768028816831936  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "6  hs  1000  lr  0.3417274762920247  reg  2.7768028816831936  decay  0.95  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "6  hs  1000  lr  0.3417274762920247  reg  2.7768028816831936  decay  0.99  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "7  hs  1000  lr  1.3574899054613125  reg  3.63010658244171e-05  decay  1  train accuracy:  0.8166734693877551  val accuracy:  0.563\n",
      "7  hs  1000  lr  1.3574899054613125  reg  3.63010658244171e-05  decay  0.95  train accuracy:  0.8770408163265306  val accuracy:  0.588\n",
      "7  hs  1000  lr  1.3574899054613125  reg  3.63010658244171e-05  decay  0.99  train accuracy:  0.828734693877551  val accuracy:  0.56\n",
      "8  hs  1000  lr  2.8296483370778325  reg  0.001788702212049792  decay  1  train accuracy:  0.49387755102040815  val accuracy:  0.469\n",
      "8  hs  1000  lr  2.8296483370778325  reg  0.001788702212049792  decay  0.95  train accuracy:  0.582469387755102  val accuracy:  0.526\n",
      "8  hs  1000  lr  2.8296483370778325  reg  0.001788702212049792  decay  0.99  train accuracy:  0.5566326530612244  val accuracy:  0.519\n",
      "9  hs  1000  lr  0.0011896753775131996  reg  2.9136272120152076  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "9  hs  1000  lr  0.0011896753775131996  reg  2.9136272120152076  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "9  hs  1000  lr  0.0011896753775131996  reg  2.9136272120152076  decay  0.99  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "10  hs  1000  lr  1.5218125083870215  reg  0.14044911190013284  decay  1  train accuracy:  0.25851020408163267  val accuracy:  0.261\n",
      "10  hs  1000  lr  1.5218125083870215  reg  0.14044911190013284  decay  0.95  train accuracy:  0.24959183673469387  val accuracy:  0.253\n",
      "10  hs  1000  lr  1.5218125083870215  reg  0.14044911190013284  decay  0.99  train accuracy:  0.23173469387755102  val accuracy:  0.224\n",
      "11  hs  1000  lr  2.5502380195941097  reg  2.9266243203098425e-05  decay  1  train accuracy:  0.745265306122449  val accuracy:  0.528\n",
      "11  hs  1000  lr  2.5502380195941097  reg  2.9266243203098425e-05  decay  0.95  train accuracy:  0.8681428571428571  val accuracy:  0.575\n",
      "11  hs  1000  lr  2.5502380195941097  reg  2.9266243203098425e-05  decay  0.99  train accuracy:  0.754  val accuracy:  0.509\n",
      "12  hs  1000  lr  0.06436475687688488  reg  0.00023870131319430487  decay  1  train accuracy:  0.559  val accuracy:  0.54\n",
      "12  hs  1000  lr  0.06436475687688488  reg  0.00023870131319430487  decay  0.95  train accuracy:  0.5424081632653062  val accuracy:  0.527\n",
      "12  hs  1000  lr  0.06436475687688488  reg  0.00023870131319430487  decay  0.99  train accuracy:  0.5550612244897959  val accuracy:  0.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  hs  1000  lr  0.0010098414502212646  reg  0.41553564366788354  decay  1  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "13  hs  1000  lr  0.0010098414502212646  reg  0.41553564366788354  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "13  hs  1000  lr  0.0010098414502212646  reg  0.41553564366788354  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "14  hs  1000  lr  4.9112440362850505  reg  0.004788972641221635  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "14  hs  1000  lr  4.9112440362850505  reg  0.004788972641221635  decay  0.95  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "14  hs  1000  lr  4.9112440362850505  reg  0.004788972641221635  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "15  hs  1000  lr  0.09205172806285476  reg  0.04835277183577006  decay  1  train accuracy:  0.44842857142857145  val accuracy:  0.436\n",
      "15  hs  1000  lr  0.09205172806285476  reg  0.04835277183577006  decay  0.95  train accuracy:  0.44087755102040815  val accuracy:  0.435\n",
      "15  hs  1000  lr  0.09205172806285476  reg  0.04835277183577006  decay  0.99  train accuracy:  0.4420204081632653  val accuracy:  0.423\n",
      "16  hs  1000  lr  0.19992111953578573  reg  0.00047763851720953004  decay  1  train accuracy:  0.6748979591836735  val accuracy:  0.603\n",
      "16  hs  1000  lr  0.19992111953578573  reg  0.00047763851720953004  decay  0.95  train accuracy:  0.6485306122448979  val accuracy:  0.596\n",
      "16  hs  1000  lr  0.19992111953578573  reg  0.00047763851720953004  decay  0.99  train accuracy:  0.67  val accuracy:  0.591\n",
      "17  hs  1000  lr  0.025219310871482013  reg  6.19303797428908e-05  decay  1  train accuracy:  0.5024897959183674  val accuracy:  0.496\n",
      "17  hs  1000  lr  0.025219310871482013  reg  6.19303797428908e-05  decay  0.95  train accuracy:  0.475  val accuracy:  0.466\n",
      "17  hs  1000  lr  0.025219310871482013  reg  6.19303797428908e-05  decay  0.99  train accuracy:  0.49695918367346936  val accuracy:  0.488\n",
      "18  hs  1000  lr  1.1169057794290238  reg  0.000573933793654484  decay  1  train accuracy:  0.7274285714285714  val accuracy:  0.576\n",
      "18  hs  1000  lr  1.1169057794290238  reg  0.000573933793654484  decay  0.95  train accuracy:  0.7674285714285715  val accuracy:  0.584\n",
      "18  hs  1000  lr  1.1169057794290238  reg  0.000573933793654484  decay  0.99  train accuracy:  0.7303673469387755  val accuracy:  0.573\n",
      "19  hs  1000  lr  0.0019060038906370095  reg  0.00154665873363317  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "19  hs  1000  lr  0.0019060038906370095  reg  0.00154665873363317  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "19  hs  1000  lr  0.0019060038906370095  reg  0.00154665873363317  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "20  hs  1000  lr  1.9466083904851934  reg  0.7247194094883626  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "20  hs  1000  lr  1.9466083904851934  reg  0.7247194094883626  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "20  hs  1000  lr  1.9466083904851934  reg  0.7247194094883626  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  1000  lr  0.6825277732016201  reg  8.720166512060375  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  1000  lr  0.6825277732016201  reg  8.720166512060375  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  1000  lr  0.6825277732016201  reg  8.720166512060375  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  1000  lr  0.02781503508897023  reg  0.00016958916323448194  decay  1  train accuracy:  0.5123469387755102  val accuracy:  0.511\n",
      "22  hs  1000  lr  0.02781503508897023  reg  0.00016958916323448194  decay  0.95  train accuracy:  0.48497959183673467  val accuracy:  0.487\n",
      "22  hs  1000  lr  0.02781503508897023  reg  0.00016958916323448194  decay  0.99  train accuracy:  0.5080204081632653  val accuracy:  0.506\n",
      "23  hs  1000  lr  0.006582426816530951  reg  0.005420889995975101  decay  1  train accuracy:  0.2183469387755102  val accuracy:  0.227\n",
      "23  hs  1000  lr  0.006582426816530951  reg  0.005420889995975101  decay  0.95  train accuracy:  0.1763673469387755  val accuracy:  0.165\n",
      "23  hs  1000  lr  0.006582426816530951  reg  0.005420889995975101  decay  0.99  train accuracy:  0.20859183673469386  val accuracy:  0.208\n",
      "24  hs  1000  lr  0.05352464699313045  reg  0.04091984379641313  decay  1  train accuracy:  0.4578979591836735  val accuracy:  0.459\n",
      "24  hs  1000  lr  0.05352464699313045  reg  0.04091984379641313  decay  0.95  train accuracy:  0.448530612244898  val accuracy:  0.435\n",
      "24  hs  1000  lr  0.05352464699313045  reg  0.04091984379641313  decay  0.99  train accuracy:  0.4563265306122449  val accuracy:  0.455\n",
      "25  hs  1000  lr  0.007900363272428266  reg  0.5301173634057909  decay  1  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "25  hs  1000  lr  0.007900363272428266  reg  0.5301173634057909  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "25  hs  1000  lr  0.007900363272428266  reg  0.5301173634057909  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "26  hs  1000  lr  0.014439090609139896  reg  0.2325865349432712  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "26  hs  1000  lr  0.014439090609139896  reg  0.2325865349432712  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "26  hs  1000  lr  0.014439090609139896  reg  0.2325865349432712  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "27  hs  1000  lr  0.6675902497135932  reg  2.416990812781505e-05  decay  1  train accuracy:  0.8130612244897959  val accuracy:  0.585\n",
      "27  hs  1000  lr  0.6675902497135932  reg  2.416990812781505e-05  decay  0.95  train accuracy:  0.8262857142857143  val accuracy:  0.564\n",
      "27  hs  1000  lr  0.6675902497135932  reg  2.416990812781505e-05  decay  0.99  train accuracy:  0.8193265306122449  val accuracy:  0.572\n",
      "28  hs  1000  lr  0.4477695800322948  reg  7.984791718531074  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "28  hs  1000  lr  0.4477695800322948  reg  7.984791718531074  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "28  hs  1000  lr  0.4477695800322948  reg  7.984791718531074  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "29  hs  1000  lr  0.11907206443698684  reg  0.08573649476520076  decay  1  train accuracy:  0.37620408163265306  val accuracy:  0.361\n",
      "29  hs  1000  lr  0.11907206443698684  reg  0.08573649476520076  decay  0.95  train accuracy:  0.360265306122449  val accuracy:  0.36\n",
      "29  hs  1000  lr  0.11907206443698684  reg  0.08573649476520076  decay  0.99  train accuracy:  0.3545510204081633  val accuracy:  0.345\n",
      "30  hs  1000  lr  0.02535632312994078  reg  5.838799892422458e-05  decay  1  train accuracy:  0.5036734693877551  val accuracy:  0.495\n",
      "30  hs  1000  lr  0.02535632312994078  reg  5.838799892422458e-05  decay  0.95  train accuracy:  0.47651020408163264  val accuracy:  0.47\n",
      "30  hs  1000  lr  0.02535632312994078  reg  5.838799892422458e-05  decay  0.99  train accuracy:  0.5006734693877551  val accuracy:  0.491\n",
      "31  hs  1000  lr  2.2162645314477882  reg  0.0025082694640904987  decay  1  train accuracy:  0.5502448979591836  val accuracy:  0.517\n",
      "31  hs  1000  lr  2.2162645314477882  reg  0.0025082694640904987  decay  0.95  train accuracy:  0.5838979591836735  val accuracy:  0.541\n",
      "31  hs  1000  lr  2.2162645314477882  reg  0.0025082694640904987  decay  0.99  train accuracy:  0.5330408163265307  val accuracy:  0.489\n",
      "32  hs  1000  lr  2.538774622564669  reg  0.006785132020064723  decay  1  train accuracy:  0.43785714285714283  val accuracy:  0.445\n",
      "32  hs  1000  lr  2.538774622564669  reg  0.006785132020064723  decay  0.95  train accuracy:  0.4600408163265306  val accuracy:  0.472\n",
      "32  hs  1000  lr  2.538774622564669  reg  0.006785132020064723  decay  0.99  train accuracy:  0.44118367346938775  val accuracy:  0.434\n",
      "33  hs  1000  lr  0.3172096205781601  reg  8.873762975638792e-05  decay  1  train accuracy:  0.7433265306122449  val accuracy:  0.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33  hs  1000  lr  0.3172096205781601  reg  8.873762975638792e-05  decay  0.95  train accuracy:  0.7197346938775511  val accuracy:  0.602\n",
      "33  hs  1000  lr  0.3172096205781601  reg  8.873762975638792e-05  decay  0.99  train accuracy:  0.7434285714285714  val accuracy:  0.592\n",
      "34  hs  1000  lr  0.00543238045106467  reg  2.2918634297665497  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "34  hs  1000  lr  0.00543238045106467  reg  2.2918634297665497  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "34  hs  1000  lr  0.00543238045106467  reg  2.2918634297665497  decay  0.99  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "35  hs  1000  lr  0.004808470276207038  reg  0.2991160971156418  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "35  hs  1000  lr  0.004808470276207038  reg  0.2991160971156418  decay  0.95  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "35  hs  1000  lr  0.004808470276207038  reg  0.2991160971156418  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "36  hs  1000  lr  0.11283256346979177  reg  0.12551677625190594  decay  1  train accuracy:  0.28377551020408165  val accuracy:  0.289\n",
      "36  hs  1000  lr  0.11283256346979177  reg  0.12551677625190594  decay  0.95  train accuracy:  0.2924285714285714  val accuracy:  0.284\n",
      "36  hs  1000  lr  0.11283256346979177  reg  0.12551677625190594  decay  0.99  train accuracy:  0.28977551020408165  val accuracy:  0.271\n",
      "37  hs  1000  lr  0.021389281105245187  reg  0.44386984593418605  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "37  hs  1000  lr  0.021389281105245187  reg  0.44386984593418605  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "37  hs  1000  lr  0.021389281105245187  reg  0.44386984593418605  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "38  hs  1000  lr  0.011451231970362297  reg  1.0672861266637113  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "38  hs  1000  lr  0.011451231970362297  reg  1.0672861266637113  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "38  hs  1000  lr  0.011451231970362297  reg  1.0672861266637113  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "39  hs  1000  lr  0.44627734311651024  reg  0.004002184682260183  decay  1  train accuracy:  0.567265306122449  val accuracy:  0.523\n",
      "39  hs  1000  lr  0.44627734311651024  reg  0.004002184682260183  decay  0.95  train accuracy:  0.5961632653061224  val accuracy:  0.58\n",
      "39  hs  1000  lr  0.44627734311651024  reg  0.004002184682260183  decay  0.99  train accuracy:  0.5897142857142857  val accuracy:  0.577\n",
      "40  hs  1000  lr  0.0035480126822932286  reg  0.0003641356008021699  decay  1  train accuracy:  0.14916326530612245  val accuracy:  0.121\n",
      "40  hs  1000  lr  0.0035480126822932286  reg  0.0003641356008021699  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "40  hs  1000  lr  0.0035480126822932286  reg  0.0003641356008021699  decay  0.99  train accuracy:  0.14840816326530612  val accuracy:  0.114\n",
      "41  hs  1000  lr  0.4121884123034452  reg  0.0009153791321732542  decay  1  train accuracy:  0.706265306122449  val accuracy:  0.599\n",
      "41  hs  1000  lr  0.4121884123034452  reg  0.0009153791321732542  decay  0.95  train accuracy:  0.704469387755102  val accuracy:  0.597\n",
      "41  hs  1000  lr  0.4121884123034452  reg  0.0009153791321732542  decay  0.99  train accuracy:  0.7021020408163265  val accuracy:  0.575\n",
      "42  hs  1000  lr  0.03726090251467665  reg  0.00021033632079518855  decay  1  train accuracy:  0.5286326530612245  val accuracy:  0.526\n",
      "42  hs  1000  lr  0.03726090251467665  reg  0.00021033632079518855  decay  0.95  train accuracy:  0.5140816326530612  val accuracy:  0.504\n",
      "42  hs  1000  lr  0.03726090251467665  reg  0.00021033632079518855  decay  0.99  train accuracy:  0.5278367346938776  val accuracy:  0.513\n",
      "43  hs  1000  lr  0.037615198080227785  reg  0.979312676107385  decay  1  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "43  hs  1000  lr  0.037615198080227785  reg  0.979312676107385  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "43  hs  1000  lr  0.037615198080227785  reg  0.979312676107385  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "44  hs  1000  lr  1.940235296757817  reg  2.40925975701967  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "44  hs  1000  lr  1.940235296757817  reg  2.40925975701967  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "44  hs  1000  lr  1.940235296757817  reg  2.40925975701967  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "45  hs  1000  lr  8.645075866734842  reg  0.24933028665628698  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "45  hs  1000  lr  8.645075866734842  reg  0.24933028665628698  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "45  hs  1000  lr  8.645075866734842  reg  0.24933028665628698  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "46  hs  1000  lr  0.04439408676953637  reg  0.031209657558101265  decay  1  train accuracy:  0.46861224489795916  val accuracy:  0.459\n",
      "46  hs  1000  lr  0.04439408676953637  reg  0.031209657558101265  decay  0.95  train accuracy:  0.46077551020408164  val accuracy:  0.457\n",
      "46  hs  1000  lr  0.04439408676953637  reg  0.031209657558101265  decay  0.99  train accuracy:  0.47151020408163263  val accuracy:  0.466\n",
      "47  hs  1000  lr  0.3714472038222038  reg  0.004523017930352041  decay  1  train accuracy:  0.5831836734693877  val accuracy:  0.573\n",
      "47  hs  1000  lr  0.3714472038222038  reg  0.004523017930352041  decay  0.95  train accuracy:  0.5867755102040816  val accuracy:  0.564\n",
      "47  hs  1000  lr  0.3714472038222038  reg  0.004523017930352041  decay  0.99  train accuracy:  0.5857142857142857  val accuracy:  0.542\n",
      "48  hs  1000  lr  0.1657336944560018  reg  0.0006683825560164441  decay  1  train accuracy:  0.6486530612244898  val accuracy:  0.598\n",
      "48  hs  1000  lr  0.1657336944560018  reg  0.0006683825560164441  decay  0.95  train accuracy:  0.622265306122449  val accuracy:  0.583\n",
      "48  hs  1000  lr  0.1657336944560018  reg  0.0006683825560164441  decay  0.99  train accuracy:  0.644469387755102  val accuracy:  0.593\n",
      "49  hs  1000  lr  5.404387823718322  reg  0.00041210781297948553  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "49  hs  1000  lr  5.404387823718322  reg  0.00041210781297948553  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "49  hs  1000  lr  5.404387823718322  reg  0.00041210781297948553  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "50  hs  1000  lr  4.252360982097578  reg  0.011065408297540233  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "50  hs  1000  lr  4.252360982097578  reg  0.011065408297540233  decay  0.95  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "50  hs  1000  lr  4.252360982097578  reg  0.011065408297540233  decay  0.99  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "51  hs  1000  lr  0.9109203341615681  reg  0.06962570051295894  decay  1  train accuracy:  0.2977142857142857  val accuracy:  0.34\n",
      "51  hs  1000  lr  0.9109203341615681  reg  0.06962570051295894  decay  0.95  train accuracy:  0.38246938775510203  val accuracy:  0.375\n",
      "51  hs  1000  lr  0.9109203341615681  reg  0.06962570051295894  decay  0.99  train accuracy:  0.33093877551020406  val accuracy:  0.324\n",
      "52  hs  1000  lr  0.048401752853728046  reg  0.03197665648358209  decay  1  train accuracy:  0.4728775510204082  val accuracy:  0.473\n",
      "52  hs  1000  lr  0.048401752853728046  reg  0.03197665648358209  decay  0.95  train accuracy:  0.46655102040816326  val accuracy:  0.466\n",
      "52  hs  1000  lr  0.048401752853728046  reg  0.03197665648358209  decay  0.99  train accuracy:  0.4751836734693878  val accuracy:  0.47\n",
      "53  hs  1000  lr  0.11981987171956106  reg  0.5099740929048421  decay  1  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "53  hs  1000  lr  0.11981987171956106  reg  0.5099740929048421  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53  hs  1000  lr  0.11981987171956106  reg  0.5099740929048421  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "54  hs  1000  lr  0.48293102972091545  reg  0.01016490003096971  decay  1  train accuracy:  0.5129183673469387  val accuracy:  0.494\n",
      "54  hs  1000  lr  0.48293102972091545  reg  0.01016490003096971  decay  0.95  train accuracy:  0.5119387755102041  val accuracy:  0.498\n",
      "54  hs  1000  lr  0.48293102972091545  reg  0.01016490003096971  decay  0.99  train accuracy:  0.5219183673469387  val accuracy:  0.503\n",
      "55  hs  1000  lr  2.507821118119415  reg  2.188247301799312e-05  decay  1  train accuracy:  0.7584489795918368  val accuracy:  0.532\n",
      "55  hs  1000  lr  2.507821118119415  reg  2.188247301799312e-05  decay  0.95  train accuracy:  0.8721428571428571  val accuracy:  0.546\n",
      "55  hs  1000  lr  2.507821118119415  reg  2.188247301799312e-05  decay  0.99  train accuracy:  0.7718979591836734  val accuracy:  0.51\n",
      "56  hs  1000  lr  0.001063977080135381  reg  0.059992657124373336  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "56  hs  1000  lr  0.001063977080135381  reg  0.059992657124373336  decay  0.95  train accuracy:  0.10253061224489796  val accuracy:  0.079\n",
      "56  hs  1000  lr  0.001063977080135381  reg  0.059992657124373336  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "57  hs  1000  lr  0.2225619594641762  reg  0.0021352766844273097  decay  1  train accuracy:  0.6274081632653061  val accuracy:  0.58\n",
      "57  hs  1000  lr  0.2225619594641762  reg  0.0021352766844273097  decay  0.95  train accuracy:  0.6170204081632653  val accuracy:  0.586\n",
      "57  hs  1000  lr  0.2225619594641762  reg  0.0021352766844273097  decay  0.99  train accuracy:  0.6265714285714286  val accuracy:  0.577\n",
      "58  hs  1000  lr  0.9942798485808267  reg  3.596815970268019e-05  decay  1  train accuracy:  0.8154897959183673  val accuracy:  0.568\n",
      "58  hs  1000  lr  0.9942798485808267  reg  3.596815970268019e-05  decay  0.95  train accuracy:  0.8594285714285714  val accuracy:  0.593\n",
      "58  hs  1000  lr  0.9942798485808267  reg  3.596815970268019e-05  decay  0.99  train accuracy:  0.8278775510204082  val accuracy:  0.585\n",
      "59  hs  1000  lr  0.0022844843241050868  reg  5.775055448749693e-05  decay  1  train accuracy:  0.11679591836734694  val accuracy:  0.121\n",
      "59  hs  1000  lr  0.0022844843241050868  reg  5.775055448749693e-05  decay  0.95  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "59  hs  1000  lr  0.0022844843241050868  reg  5.775055448749693e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "60  hs  1000  lr  0.13666711739525603  reg  0.41679898162008105  decay  1  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "60  hs  1000  lr  0.13666711739525603  reg  0.41679898162008105  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "60  hs  1000  lr  0.13666711739525603  reg  0.41679898162008105  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "61  hs  1000  lr  0.9124914842661644  reg  3.2215972711180445  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "61  hs  1000  lr  0.9124914842661644  reg  3.2215972711180445  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "61  hs  1000  lr  0.9124914842661644  reg  3.2215972711180445  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "62  hs  1000  lr  0.020415125967472768  reg  0.002970600804352411  decay  1  train accuracy:  0.4762448979591837  val accuracy:  0.461\n",
      "62  hs  1000  lr  0.020415125967472768  reg  0.002970600804352411  decay  0.95  train accuracy:  0.4346530612244898  val accuracy:  0.414\n",
      "62  hs  1000  lr  0.020415125967472768  reg  0.002970600804352411  decay  0.99  train accuracy:  0.47346938775510206  val accuracy:  0.46\n",
      "63  hs  1000  lr  1.025061985023058  reg  0.06824204695203068  decay  1  train accuracy:  0.3239183673469388  val accuracy:  0.329\n",
      "63  hs  1000  lr  1.025061985023058  reg  0.06824204695203068  decay  0.95  train accuracy:  0.3310612244897959  val accuracy:  0.32\n",
      "63  hs  1000  lr  1.025061985023058  reg  0.06824204695203068  decay  0.99  train accuracy:  0.36542857142857144  val accuracy:  0.368\n",
      "64  hs  1000  lr  0.002753781327567106  reg  1.6340573129755076  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "64  hs  1000  lr  0.002753781327567106  reg  1.6340573129755076  decay  0.95  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "64  hs  1000  lr  0.002753781327567106  reg  1.6340573129755076  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "65  hs  1000  lr  0.003565651079057632  reg  0.0025827456446038104  decay  1  train accuracy:  0.10840816326530613  val accuracy:  0.082\n",
      "65  hs  1000  lr  0.003565651079057632  reg  0.0025827456446038104  decay  0.95  train accuracy:  0.10102040816326531  val accuracy:  0.079\n",
      "65  hs  1000  lr  0.003565651079057632  reg  0.0025827456446038104  decay  0.99  train accuracy:  0.16626530612244897  val accuracy:  0.139\n",
      "66  hs  1000  lr  2.2784269254050606  reg  2.5087326776009e-05  decay  1  train accuracy:  0.7685306122448979  val accuracy:  0.543\n",
      "66  hs  1000  lr  2.2784269254050606  reg  2.5087326776009e-05  decay  0.95  train accuracy:  0.8695510204081632  val accuracy:  0.563\n",
      "66  hs  1000  lr  2.2784269254050606  reg  2.5087326776009e-05  decay  0.99  train accuracy:  0.7914897959183673  val accuracy:  0.557\n",
      "67  hs  1000  lr  0.06986698445398748  reg  0.00122842018560195  decay  1  train accuracy:  0.5588775510204081  val accuracy:  0.534\n",
      "67  hs  1000  lr  0.06986698445398748  reg  0.00122842018560195  decay  0.95  train accuracy:  0.542734693877551  val accuracy:  0.527\n",
      "67  hs  1000  lr  0.06986698445398748  reg  0.00122842018560195  decay  0.99  train accuracy:  0.5541836734693878  val accuracy:  0.541\n",
      "68  hs  1000  lr  0.022762644173120544  reg  2.929237859556793e-05  decay  1  train accuracy:  0.49228571428571427  val accuracy:  0.484\n",
      "68  hs  1000  lr  0.022762644173120544  reg  2.929237859556793e-05  decay  0.95  train accuracy:  0.4605102040816327  val accuracy:  0.444\n",
      "68  hs  1000  lr  0.022762644173120544  reg  2.929237859556793e-05  decay  0.99  train accuracy:  0.4889387755102041  val accuracy:  0.476\n",
      "69  hs  1000  lr  0.004781503930018446  reg  0.0035898535338227083  decay  1  train accuracy:  0.20779591836734693  val accuracy:  0.19\n",
      "69  hs  1000  lr  0.004781503930018446  reg  0.0035898535338227083  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "69  hs  1000  lr  0.004781503930018446  reg  0.0035898535338227083  decay  0.99  train accuracy:  0.17738775510204083  val accuracy:  0.171\n",
      "computed in  5045.860218524933 s\n",
      "0  hs  500  lr  0.019504671103657636  reg  0.0027040345695656786  decay  1  train accuracy:  0.466265306122449  val accuracy:  0.458\n",
      "0  hs  500  lr  0.019504671103657636  reg  0.0027040345695656786  decay  0.95  train accuracy:  0.4136734693877551  val accuracy:  0.4\n",
      "0  hs  500  lr  0.019504671103657636  reg  0.0027040345695656786  decay  0.99  train accuracy:  0.4572040816326531  val accuracy:  0.439\n",
      "1  hs  500  lr  0.07221427220768337  reg  7.134839134374121  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "1  hs  500  lr  0.07221427220768337  reg  7.134839134374121  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "1  hs  500  lr  0.07221427220768337  reg  7.134839134374121  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "2  hs  500  lr  0.09418164070939758  reg  0.00041985822267637675  decay  1  train accuracy:  0.5886530612244898  val accuracy:  0.56\n",
      "2  hs  500  lr  0.09418164070939758  reg  0.00041985822267637675  decay  0.95  train accuracy:  0.5668571428571428  val accuracy:  0.543\n",
      "2  hs  500  lr  0.09418164070939758  reg  0.00041985822267637675  decay  0.99  train accuracy:  0.5825714285714285  val accuracy:  0.552\n",
      "3  hs  500  lr  0.021307267527706838  reg  4.6154619420457965e-05  decay  1  train accuracy:  0.48281632653061224  val accuracy:  0.476\n",
      "3  hs  500  lr  0.021307267527706838  reg  4.6154619420457965e-05  decay  0.95  train accuracy:  0.43885714285714283  val accuracy:  0.42\n",
      "3  hs  500  lr  0.021307267527706838  reg  4.6154619420457965e-05  decay  0.99  train accuracy:  0.47653061224489796  val accuracy:  0.466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  hs  500  lr  0.9407595497661215  reg  0.0038548224421823298  decay  1  train accuracy:  0.5676530612244898  val accuracy:  0.526\n",
      "4  hs  500  lr  0.9407595497661215  reg  0.0038548224421823298  decay  0.95  train accuracy:  0.5819387755102041  val accuracy:  0.543\n",
      "4  hs  500  lr  0.9407595497661215  reg  0.0038548224421823298  decay  0.99  train accuracy:  0.5620816326530612  val accuracy:  0.539\n",
      "5  hs  500  lr  0.004307843123178778  reg  2.626705125221743e-05  decay  1  train accuracy:  0.16308163265306122  val accuracy:  0.134\n",
      "5  hs  500  lr  0.004307843123178778  reg  2.626705125221743e-05  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "5  hs  500  lr  0.004307843123178778  reg  2.626705125221743e-05  decay  0.99  train accuracy:  0.1893265306122449  val accuracy:  0.229\n",
      "6  hs  500  lr  0.9501927887269441  reg  0.009148136204611402  decay  1  train accuracy:  0.4625102040816326  val accuracy:  0.458\n",
      "6  hs  500  lr  0.9501927887269441  reg  0.009148136204611402  decay  0.95  train accuracy:  0.5249795918367347  val accuracy:  0.523\n",
      "6  hs  500  lr  0.9501927887269441  reg  0.009148136204611402  decay  0.99  train accuracy:  0.5005306122448979  val accuracy:  0.49\n",
      "7  hs  500  lr  5.29526518311461  reg  0.9423543478613049  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "7  hs  500  lr  5.29526518311461  reg  0.9423543478613049  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "7  hs  500  lr  5.29526518311461  reg  0.9423543478613049  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "8  hs  500  lr  0.024111506957618385  reg  0.0027663052744991146  decay  1  train accuracy:  0.491469387755102  val accuracy:  0.488\n",
      "8  hs  500  lr  0.024111506957618385  reg  0.0027663052744991146  decay  0.95  train accuracy:  0.45793877551020407  val accuracy:  0.443\n",
      "8  hs  500  lr  0.024111506957618385  reg  0.0027663052744991146  decay  0.99  train accuracy:  0.4856938775510204  val accuracy:  0.489\n",
      "9  hs  500  lr  0.0022805575371961087  reg  0.0004720743988379975  decay  1  train accuracy:  0.10575510204081633  val accuracy:  0.082\n",
      "9  hs  500  lr  0.0022805575371961087  reg  0.0004720743988379975  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "9  hs  500  lr  0.0022805575371961087  reg  0.0004720743988379975  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "10  hs  500  lr  0.015828910357177626  reg  0.000855138302849198  decay  1  train accuracy:  0.43559183673469387  val accuracy:  0.429\n",
      "10  hs  500  lr  0.015828910357177626  reg  0.000855138302849198  decay  0.95  train accuracy:  0.3493673469387755  val accuracy:  0.338\n",
      "10  hs  500  lr  0.015828910357177626  reg  0.000855138302849198  decay  0.99  train accuracy:  0.42018367346938773  val accuracy:  0.414\n",
      "11  hs  500  lr  0.0024035416555103126  reg  0.23000228116968127  decay  1  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "11  hs  500  lr  0.0024035416555103126  reg  0.23000228116968127  decay  0.95  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "11  hs  500  lr  0.0024035416555103126  reg  0.23000228116968127  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "12  hs  500  lr  4.149958188535209  reg  0.2634586614742711  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "12  hs  500  lr  4.149958188535209  reg  0.2634586614742711  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "12  hs  500  lr  4.149958188535209  reg  0.2634586614742711  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "13  hs  500  lr  0.05536754477528787  reg  0.0011031381959266183  decay  1  train accuracy:  0.5452244897959184  val accuracy:  0.531\n",
      "13  hs  500  lr  0.05536754477528787  reg  0.0011031381959266183  decay  0.95  train accuracy:  0.5313877551020408  val accuracy:  0.519\n",
      "13  hs  500  lr  0.05536754477528787  reg  0.0011031381959266183  decay  0.99  train accuracy:  0.5411836734693878  val accuracy:  0.512\n",
      "14  hs  500  lr  1.0463609037141304  reg  0.08046544110076821  decay  1  train accuracy:  0.3062244897959184  val accuracy:  0.309\n",
      "14  hs  500  lr  1.0463609037141304  reg  0.08046544110076821  decay  0.95  train accuracy:  0.32355102040816325  val accuracy:  0.288\n",
      "14  hs  500  lr  1.0463609037141304  reg  0.08046544110076821  decay  0.99  train accuracy:  0.3217551020408163  val accuracy:  0.311\n",
      "15  hs  500  lr  5.164997731997435  reg  9.262604835783412  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "15  hs  500  lr  5.164997731997435  reg  9.262604835783412  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "15  hs  500  lr  5.164997731997435  reg  9.262604835783412  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "16  hs  500  lr  9.870097762064658  reg  1.2696717207979961e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "16  hs  500  lr  9.870097762064658  reg  1.2696717207979961e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "16  hs  500  lr  9.870097762064658  reg  1.2696717207979961e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "17  hs  500  lr  0.015092916919057606  reg  7.114407763294452e-05  decay  1  train accuracy:  0.42251020408163265  val accuracy:  0.413\n",
      "17  hs  500  lr  0.015092916919057606  reg  7.114407763294452e-05  decay  0.95  train accuracy:  0.3306530612244898  val accuracy:  0.328\n",
      "17  hs  500  lr  0.015092916919057606  reg  7.114407763294452e-05  decay  0.99  train accuracy:  0.41338775510204084  val accuracy:  0.402\n",
      "18  hs  500  lr  7.087208480032183  reg  0.0024678262183024866  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "18  hs  500  lr  7.087208480032183  reg  0.0024678262183024866  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "18  hs  500  lr  7.087208480032183  reg  0.0024678262183024866  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "19  hs  500  lr  4.590187769217507  reg  0.043125825619843766  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "19  hs  500  lr  4.590187769217507  reg  0.043125825619843766  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "19  hs  500  lr  4.590187769217507  reg  0.043125825619843766  decay  0.99  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "20  hs  500  lr  0.0018178532562750614  reg  0.004374297355819556  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "20  hs  500  lr  0.0018178532562750614  reg  0.004374297355819556  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "20  hs  500  lr  0.0018178532562750614  reg  0.004374297355819556  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  500  lr  0.09673083897685911  reg  0.012338322038747244  decay  1  train accuracy:  0.5168979591836734  val accuracy:  0.504\n",
      "21  hs  500  lr  0.09673083897685911  reg  0.012338322038747244  decay  0.95  train accuracy:  0.5186326530612245  val accuracy:  0.51\n",
      "21  hs  500  lr  0.09673083897685911  reg  0.012338322038747244  decay  0.99  train accuracy:  0.5178979591836734  val accuracy:  0.502\n",
      "22  hs  500  lr  0.6362357903537762  reg  0.00018262914251670473  decay  1  train accuracy:  0.7611020408163265  val accuracy:  0.579\n",
      "22  hs  500  lr  0.6362357903537762  reg  0.00018262914251670473  decay  0.95  train accuracy:  0.7729387755102041  val accuracy:  0.589\n",
      "22  hs  500  lr  0.6362357903537762  reg  0.00018262914251670473  decay  0.99  train accuracy:  0.7643061224489796  val accuracy:  0.567\n",
      "23  hs  500  lr  0.0014979788485475337  reg  0.001531123486994107  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "23  hs  500  lr  0.0014979788485475337  reg  0.001531123486994107  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "23  hs  500  lr  0.0014979788485475337  reg  0.001531123486994107  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "24  hs  500  lr  2.972239392085604  reg  0.025738605309855396  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  hs  500  lr  2.972239392085604  reg  0.025738605309855396  decay  0.95  train accuracy:  0.4189591836734694  val accuracy:  0.423\n",
      "24  hs  500  lr  2.972239392085604  reg  0.025738605309855396  decay  0.99  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "25  hs  500  lr  5.6065560710978  reg  0.9781485754077788  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "25  hs  500  lr  5.6065560710978  reg  0.9781485754077788  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "25  hs  500  lr  5.6065560710978  reg  0.9781485754077788  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "26  hs  500  lr  0.002516172896094573  reg  0.5781519438365467  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "26  hs  500  lr  0.002516172896094573  reg  0.5781519438365467  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "26  hs  500  lr  0.002516172896094573  reg  0.5781519438365467  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "27  hs  500  lr  0.1329237482339928  reg  0.039965732526876616  decay  1  train accuracy:  0.46546938775510205  val accuracy:  0.457\n",
      "27  hs  500  lr  0.1329237482339928  reg  0.039965732526876616  decay  0.95  train accuracy:  0.4573061224489796  val accuracy:  0.451\n",
      "27  hs  500  lr  0.1329237482339928  reg  0.039965732526876616  decay  0.99  train accuracy:  0.46755102040816326  val accuracy:  0.469\n",
      "28  hs  500  lr  0.014091783367419963  reg  0.00017639250049079178  decay  1  train accuracy:  0.4070612244897959  val accuracy:  0.398\n",
      "28  hs  500  lr  0.014091783367419963  reg  0.00017639250049079178  decay  0.95  train accuracy:  0.30604081632653063  val accuracy:  0.319\n",
      "28  hs  500  lr  0.014091783367419963  reg  0.00017639250049079178  decay  0.99  train accuracy:  0.39316326530612244  val accuracy:  0.385\n",
      "29  hs  500  lr  0.005938527300775049  reg  0.24486904879618304  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "29  hs  500  lr  0.005938527300775049  reg  0.24486904879618304  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "29  hs  500  lr  0.005938527300775049  reg  0.24486904879618304  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "30  hs  500  lr  0.0017698824771768549  reg  0.4025468807082838  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "30  hs  500  lr  0.0017698824771768549  reg  0.4025468807082838  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "30  hs  500  lr  0.0017698824771768549  reg  0.4025468807082838  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "31  hs  500  lr  0.1960310060711563  reg  2.2322446667635923e-05  decay  1  train accuracy:  0.6724081632653062  val accuracy:  0.582\n",
      "31  hs  500  lr  0.1960310060711563  reg  2.2322446667635923e-05  decay  0.95  train accuracy:  0.6489387755102041  val accuracy:  0.589\n",
      "31  hs  500  lr  0.1960310060711563  reg  2.2322446667635923e-05  decay  0.99  train accuracy:  0.6739387755102041  val accuracy:  0.584\n",
      "32  hs  500  lr  0.0010109325088790305  reg  0.00012376606710255036  decay  1  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "32  hs  500  lr  0.0010109325088790305  reg  0.00012376606710255036  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "32  hs  500  lr  0.0010109325088790305  reg  0.00012376606710255036  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "33  hs  500  lr  0.27285871917609894  reg  5.265773391832784  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "33  hs  500  lr  0.27285871917609894  reg  5.265773391832784  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "33  hs  500  lr  0.27285871917609894  reg  5.265773391832784  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "34  hs  500  lr  0.03148881166553005  reg  0.0006522562975648128  decay  1  train accuracy:  0.5176530612244898  val accuracy:  0.505\n",
      "34  hs  500  lr  0.03148881166553005  reg  0.0006522562975648128  decay  0.95  train accuracy:  0.49481632653061225  val accuracy:  0.477\n",
      "34  hs  500  lr  0.03148881166553005  reg  0.0006522562975648128  decay  0.99  train accuracy:  0.5131020408163265  val accuracy:  0.509\n",
      "35  hs  500  lr  0.6353653386661282  reg  0.0005889608376318263  decay  1  train accuracy:  0.7165714285714285  val accuracy:  0.57\n",
      "35  hs  500  lr  0.6353653386661282  reg  0.0005889608376318263  decay  0.95  train accuracy:  0.7383877551020408  val accuracy:  0.585\n",
      "35  hs  500  lr  0.6353653386661282  reg  0.0005889608376318263  decay  0.99  train accuracy:  0.727530612244898  val accuracy:  0.582\n",
      "36  hs  500  lr  0.007048552355725019  reg  0.00015877601110202787  decay  1  train accuracy:  0.20995918367346939  val accuracy:  0.215\n",
      "36  hs  500  lr  0.007048552355725019  reg  0.00015877601110202787  decay  0.95  train accuracy:  0.20361224489795918  val accuracy:  0.209\n",
      "36  hs  500  lr  0.007048552355725019  reg  0.00015877601110202787  decay  0.99  train accuracy:  0.21422448979591838  val accuracy:  0.221\n",
      "37  hs  500  lr  6.0605189026386945  reg  3.174011130129319  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "37  hs  500  lr  6.0605189026386945  reg  3.174011130129319  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "37  hs  500  lr  6.0605189026386945  reg  3.174011130129319  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "38  hs  500  lr  0.14696392007416823  reg  0.6026971761986492  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "38  hs  500  lr  0.14696392007416823  reg  0.6026971761986492  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "38  hs  500  lr  0.14696392007416823  reg  0.6026971761986492  decay  0.99  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "39  hs  500  lr  0.061287426449408364  reg  0.012102220186137653  decay  1  train accuracy:  0.5191632653061224  val accuracy:  0.521\n",
      "39  hs  500  lr  0.061287426449408364  reg  0.012102220186137653  decay  0.95  train accuracy:  0.5148979591836734  val accuracy:  0.512\n",
      "39  hs  500  lr  0.061287426449408364  reg  0.012102220186137653  decay  0.99  train accuracy:  0.519673469387755  val accuracy:  0.514\n",
      "40  hs  500  lr  0.0012642755922747451  reg  0.0003581245314259414  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "40  hs  500  lr  0.0012642755922747451  reg  0.0003581245314259414  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "40  hs  500  lr  0.0012642755922747451  reg  0.0003581245314259414  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "41  hs  500  lr  0.044681843677884754  reg  4.46657691079962e-05  decay  1  train accuracy:  0.5363061224489796  val accuracy:  0.516\n",
      "41  hs  500  lr  0.044681843677884754  reg  4.46657691079962e-05  decay  0.95  train accuracy:  0.5231224489795918  val accuracy:  0.503\n",
      "41  hs  500  lr  0.044681843677884754  reg  4.46657691079962e-05  decay  0.99  train accuracy:  0.5336938775510204  val accuracy:  0.519\n",
      "42  hs  500  lr  0.8670355786984867  reg  0.0007841409293198928  decay  1  train accuracy:  0.6888979591836735  val accuracy:  0.598\n",
      "42  hs  500  lr  0.8670355786984867  reg  0.0007841409293198928  decay  0.95  train accuracy:  0.7172857142857143  val accuracy:  0.588\n",
      "42  hs  500  lr  0.8670355786984867  reg  0.0007841409293198928  decay  0.99  train accuracy:  0.709204081632653  val accuracy:  0.601\n",
      "43  hs  500  lr  1.0372824400315117  reg  0.08084887115927568  decay  1  train accuracy:  0.32618367346938776  val accuracy:  0.323\n",
      "43  hs  500  lr  1.0372824400315117  reg  0.08084887115927568  decay  0.95  train accuracy:  0.35989795918367345  val accuracy:  0.355\n",
      "43  hs  500  lr  1.0372824400315117  reg  0.08084887115927568  decay  0.99  train accuracy:  0.3020816326530612  val accuracy:  0.331\n",
      "44  hs  500  lr  0.6238008049828077  reg  0.15156391482067094  decay  1  train accuracy:  0.2440204081632653  val accuracy:  0.267\n",
      "44  hs  500  lr  0.6238008049828077  reg  0.15156391482067094  decay  0.95  train accuracy:  0.2513877551020408  val accuracy:  0.239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44  hs  500  lr  0.6238008049828077  reg  0.15156391482067094  decay  0.99  train accuracy:  0.23575510204081632  val accuracy:  0.218\n",
      "45  hs  500  lr  0.7222934971211761  reg  0.020752310660042933  decay  1  train accuracy:  0.46775510204081633  val accuracy:  0.466\n",
      "45  hs  500  lr  0.7222934971211761  reg  0.020752310660042933  decay  0.95  train accuracy:  0.4669387755102041  val accuracy:  0.463\n",
      "45  hs  500  lr  0.7222934971211761  reg  0.020752310660042933  decay  0.99  train accuracy:  0.45985714285714285  val accuracy:  0.443\n",
      "46  hs  500  lr  0.34246996399760904  reg  0.0020837116296155383  decay  1  train accuracy:  0.6376530612244898  val accuracy:  0.592\n",
      "46  hs  500  lr  0.34246996399760904  reg  0.0020837116296155383  decay  0.95  train accuracy:  0.6418163265306123  val accuracy:  0.602\n",
      "46  hs  500  lr  0.34246996399760904  reg  0.0020837116296155383  decay  0.99  train accuracy:  0.6393061224489796  val accuracy:  0.588\n",
      "47  hs  500  lr  0.01603126852596898  reg  4.597065309711222  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "47  hs  500  lr  0.01603126852596898  reg  4.597065309711222  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "47  hs  500  lr  0.01603126852596898  reg  4.597065309711222  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "48  hs  500  lr  0.10026095667136328  reg  0.9664675801486998  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "48  hs  500  lr  0.10026095667136328  reg  0.9664675801486998  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "48  hs  500  lr  0.10026095667136328  reg  0.9664675801486998  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "49  hs  500  lr  0.16435393378108304  reg  0.004391777311621132  decay  1  train accuracy:  0.5703673469387756  val accuracy:  0.545\n",
      "49  hs  500  lr  0.16435393378108304  reg  0.004391777311621132  decay  0.95  train accuracy:  0.5632857142857143  val accuracy:  0.531\n",
      "49  hs  500  lr  0.16435393378108304  reg  0.004391777311621132  decay  0.99  train accuracy:  0.5693673469387756  val accuracy:  0.536\n",
      "50  hs  500  lr  0.10440231355574849  reg  0.0023900003528902676  decay  1  train accuracy:  0.574734693877551  val accuracy:  0.56\n",
      "50  hs  500  lr  0.10440231355574849  reg  0.0023900003528902676  decay  0.95  train accuracy:  0.5568367346938775  val accuracy:  0.537\n",
      "50  hs  500  lr  0.10440231355574849  reg  0.0023900003528902676  decay  0.99  train accuracy:  0.5691428571428572  val accuracy:  0.554\n",
      "51  hs  500  lr  5.603111832392474  reg  3.567905175965524e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "51  hs  500  lr  5.603111832392474  reg  3.567905175965524e-05  decay  0.95  train accuracy:  0.14087755102040816  val accuracy:  0.102\n",
      "51  hs  500  lr  5.603111832392474  reg  3.567905175965524e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  500  lr  7.070079190747301  reg  8.969446729345767e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  500  lr  7.070079190747301  reg  8.969446729345767e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  500  lr  7.070079190747301  reg  8.969446729345767e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "53  hs  500  lr  0.8155750059536209  reg  0.00014571770474161385  decay  1  train accuracy:  0.7701836734693878  val accuracy:  0.565\n",
      "53  hs  500  lr  0.8155750059536209  reg  0.00014571770474161385  decay  0.95  train accuracy:  0.7898367346938775  val accuracy:  0.591\n",
      "53  hs  500  lr  0.8155750059536209  reg  0.00014571770474161385  decay  0.99  train accuracy:  0.7697551020408163  val accuracy:  0.568\n",
      "54  hs  500  lr  0.002291433506489123  reg  3.981057339236299e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "54  hs  500  lr  0.002291433506489123  reg  3.981057339236299e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "54  hs  500  lr  0.002291433506489123  reg  3.981057339236299e-05  decay  0.99  train accuracy:  0.1463061224489796  val accuracy:  0.142\n",
      "55  hs  500  lr  0.51942856487462  reg  0.0003706214501733281  decay  1  train accuracy:  0.7335918367346939  val accuracy:  0.585\n",
      "55  hs  500  lr  0.51942856487462  reg  0.0003706214501733281  decay  0.95  train accuracy:  0.7415306122448979  val accuracy:  0.58\n",
      "55  hs  500  lr  0.51942856487462  reg  0.0003706214501733281  decay  0.99  train accuracy:  0.7396734693877551  val accuracy:  0.574\n",
      "56  hs  500  lr  0.01742656698016413  reg  0.0010548921708943581  decay  1  train accuracy:  0.45277551020408163  val accuracy:  0.432\n",
      "56  hs  500  lr  0.01742656698016413  reg  0.0010548921708943581  decay  0.95  train accuracy:  0.39148979591836736  val accuracy:  0.387\n",
      "56  hs  500  lr  0.01742656698016413  reg  0.0010548921708943581  decay  0.99  train accuracy:  0.4396122448979592  val accuracy:  0.414\n",
      "57  hs  500  lr  0.010106389434186102  reg  0.029601975068747847  decay  1  train accuracy:  0.24918367346938775  val accuracy:  0.261\n",
      "57  hs  500  lr  0.010106389434186102  reg  0.029601975068747847  decay  0.95  train accuracy:  0.18108163265306124  val accuracy:  0.18\n",
      "57  hs  500  lr  0.010106389434186102  reg  0.029601975068747847  decay  0.99  train accuracy:  0.23530612244897958  val accuracy:  0.251\n",
      "58  hs  500  lr  0.05732857230073649  reg  1.0176700210780983e-05  decay  1  train accuracy:  0.5507142857142857  val accuracy:  0.537\n",
      "58  hs  500  lr  0.05732857230073649  reg  1.0176700210780983e-05  decay  0.95  train accuracy:  0.5363061224489796  val accuracy:  0.524\n",
      "58  hs  500  lr  0.05732857230073649  reg  1.0176700210780983e-05  decay  0.99  train accuracy:  0.547265306122449  val accuracy:  0.518\n",
      "59  hs  500  lr  7.089589144849596  reg  0.0018673515127469403  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "59  hs  500  lr  7.089589144849596  reg  0.0018673515127469403  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "59  hs  500  lr  7.089589144849596  reg  0.0018673515127469403  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "60  hs  500  lr  0.39691009781955694  reg  2.6992020128158453e-05  decay  1  train accuracy:  0.7475714285714286  val accuracy:  0.569\n",
      "60  hs  500  lr  0.39691009781955694  reg  2.6992020128158453e-05  decay  0.95  train accuracy:  0.7257142857142858  val accuracy:  0.58\n",
      "60  hs  500  lr  0.39691009781955694  reg  2.6992020128158453e-05  decay  0.99  train accuracy:  0.754734693877551  val accuracy:  0.597\n",
      "61  hs  500  lr  0.0539117439664561  reg  0.006049100356915261  decay  1  train accuracy:  0.5277142857142857  val accuracy:  0.511\n",
      "61  hs  500  lr  0.0539117439664561  reg  0.006049100356915261  decay  0.95  train accuracy:  0.5224897959183673  val accuracy:  0.516\n",
      "61  hs  500  lr  0.0539117439664561  reg  0.006049100356915261  decay  0.99  train accuracy:  0.5282448979591837  val accuracy:  0.506\n",
      "62  hs  500  lr  0.565663723607975  reg  0.0001276182538000678  decay  1  train accuracy:  0.7628775510204082  val accuracy:  0.579\n",
      "62  hs  500  lr  0.565663723607975  reg  0.0001276182538000678  decay  0.95  train accuracy:  0.7736530612244898  val accuracy:  0.586\n",
      "62  hs  500  lr  0.565663723607975  reg  0.0001276182538000678  decay  0.99  train accuracy:  0.7690204081632653  val accuracy:  0.582\n",
      "63  hs  500  lr  0.023844700816405714  reg  0.0009949367201414398  decay  1  train accuracy:  0.4919591836734694  val accuracy:  0.48\n",
      "63  hs  500  lr  0.023844700816405714  reg  0.0009949367201414398  decay  0.95  train accuracy:  0.4586122448979592  val accuracy:  0.453\n",
      "63  hs  500  lr  0.023844700816405714  reg  0.0009949367201414398  decay  0.99  train accuracy:  0.4863265306122449  val accuracy:  0.489\n",
      "64  hs  500  lr  7.160892383613022  reg  0.035687456121171086  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "64  hs  500  lr  7.160892383613022  reg  0.035687456121171086  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "64  hs  500  lr  7.160892383613022  reg  0.035687456121171086  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65  hs  500  lr  1.3277129168292077  reg  0.21150854562830596  decay  1  train accuracy:  0.18593877551020407  val accuracy:  0.193\n",
      "65  hs  500  lr  1.3277129168292077  reg  0.21150854562830596  decay  0.95  train accuracy:  0.17204081632653062  val accuracy:  0.198\n",
      "65  hs  500  lr  1.3277129168292077  reg  0.21150854562830596  decay  0.99  train accuracy:  0.16391836734693876  val accuracy:  0.187\n",
      "66  hs  500  lr  0.00120465068290059  reg  7.498450733828451e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "66  hs  500  lr  0.00120465068290059  reg  7.498450733828451e-05  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "66  hs  500  lr  0.00120465068290059  reg  7.498450733828451e-05  decay  0.99  train accuracy:  0.10171428571428572  val accuracy:  0.099\n",
      "67  hs  500  lr  8.532998817208616  reg  0.0006533726198501587  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "67  hs  500  lr  8.532998817208616  reg  0.0006533726198501587  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "67  hs  500  lr  8.532998817208616  reg  0.0006533726198501587  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "68  hs  500  lr  1.3648998685822935  reg  0.0002639382359684233  decay  1  train accuracy:  0.7415306122448979  val accuracy:  0.558\n",
      "68  hs  500  lr  1.3648998685822935  reg  0.0002639382359684233  decay  0.95  train accuracy:  0.7916734693877551  val accuracy:  0.58\n",
      "68  hs  500  lr  1.3648998685822935  reg  0.0002639382359684233  decay  0.99  train accuracy:  0.7406122448979592  val accuracy:  0.542\n",
      "69  hs  500  lr  0.022638373013045162  reg  1.9366678979999503  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "69  hs  500  lr  0.022638373013045162  reg  1.9366678979999503  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "69  hs  500  lr  0.022638373013045162  reg  1.9366678979999503  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "computed in  3225.1064381599426 s\n",
      "0  hs  100  lr  0.015353025573602554  reg  2.604029597489973  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "0  hs  100  lr  0.015353025573602554  reg  2.604029597489973  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "0  hs  100  lr  0.015353025573602554  reg  2.604029597489973  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "1  hs  100  lr  0.002216679570818753  reg  0.08786598674703895  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "1  hs  100  lr  0.002216679570818753  reg  0.08786598674703895  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "1  hs  100  lr  0.002216679570818753  reg  0.08786598674703895  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "2  hs  100  lr  0.025314049456150216  reg  0.0003936727009907331  decay  1  train accuracy:  0.4890408163265306  val accuracy:  0.478\n",
      "2  hs  100  lr  0.025314049456150216  reg  0.0003936727009907331  decay  0.95  train accuracy:  0.44846938775510203  val accuracy:  0.434\n",
      "2  hs  100  lr  0.025314049456150216  reg  0.0003936727009907331  decay  0.99  train accuracy:  0.485265306122449  val accuracy:  0.484\n",
      "3  hs  100  lr  0.002561609531440905  reg  0.012748581046769765  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  100  lr  0.002561609531440905  reg  0.012748581046769765  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "3  hs  100  lr  0.002561609531440905  reg  0.012748581046769765  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "4  hs  100  lr  0.22422186928815963  reg  5.784855637508358e-05  decay  1  train accuracy:  0.638734693877551  val accuracy:  0.581\n",
      "4  hs  100  lr  0.22422186928815963  reg  5.784855637508358e-05  decay  0.95  train accuracy:  0.6261836734693877  val accuracy:  0.578\n",
      "4  hs  100  lr  0.22422186928815963  reg  5.784855637508358e-05  decay  0.99  train accuracy:  0.6366326530612245  val accuracy:  0.582\n",
      "5  hs  100  lr  4.116828393483612  reg  0.0011889722609219058  decay  1  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "5  hs  100  lr  4.116828393483612  reg  0.0011889722609219058  decay  0.95  train accuracy:  0.5152448979591837  val accuracy:  0.501\n",
      "5  hs  100  lr  4.116828393483612  reg  0.0011889722609219058  decay  0.99  train accuracy:  0.1446530612244898  val accuracy:  0.151\n",
      "6  hs  100  lr  1.8669550857960546  reg  0.0551131974985263  decay  1  train accuracy:  0.3315714285714286  val accuracy:  0.311\n",
      "6  hs  100  lr  1.8669550857960546  reg  0.0551131974985263  decay  0.95  train accuracy:  0.3422857142857143  val accuracy:  0.311\n",
      "6  hs  100  lr  1.8669550857960546  reg  0.0551131974985263  decay  0.99  train accuracy:  0.3106122448979592  val accuracy:  0.308\n",
      "7  hs  100  lr  0.0010410499761116915  reg  0.2766197594221993  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "7  hs  100  lr  0.0010410499761116915  reg  0.2766197594221993  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "7  hs  100  lr  0.0010410499761116915  reg  0.2766197594221993  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "8  hs  100  lr  0.0012449911711705716  reg  0.0068442858614916734  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "8  hs  100  lr  0.0012449911711705716  reg  0.0068442858614916734  decay  0.95  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "8  hs  100  lr  0.0012449911711705716  reg  0.0068442858614916734  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "9  hs  100  lr  0.002266287511705804  reg  0.011503947099465034  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "9  hs  100  lr  0.002266287511705804  reg  0.011503947099465034  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "9  hs  100  lr  0.002266287511705804  reg  0.011503947099465034  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "10  hs  100  lr  0.6826502397105519  reg  0.030297799974403003  decay  1  train accuracy:  0.42906122448979594  val accuracy:  0.448\n",
      "10  hs  100  lr  0.6826502397105519  reg  0.030297799974403003  decay  0.95  train accuracy:  0.4636530612244898  val accuracy:  0.477\n",
      "10  hs  100  lr  0.6826502397105519  reg  0.030297799974403003  decay  0.99  train accuracy:  0.4190816326530612  val accuracy:  0.407\n",
      "11  hs  100  lr  0.18141407468507725  reg  0.0014845849614881254  decay  1  train accuracy:  0.6046938775510204  val accuracy:  0.561\n",
      "11  hs  100  lr  0.18141407468507725  reg  0.0014845849614881254  decay  0.95  train accuracy:  0.5921020408163266  val accuracy:  0.565\n",
      "11  hs  100  lr  0.18141407468507725  reg  0.0014845849614881254  decay  0.99  train accuracy:  0.6064081632653061  val accuracy:  0.567\n",
      "12  hs  100  lr  0.06299574704368685  reg  0.0004557476080090961  decay  1  train accuracy:  0.5492244897959183  val accuracy:  0.53\n",
      "12  hs  100  lr  0.06299574704368685  reg  0.0004557476080090961  decay  0.95  train accuracy:  0.5372857142857143  val accuracy:  0.524\n",
      "12  hs  100  lr  0.06299574704368685  reg  0.0004557476080090961  decay  0.99  train accuracy:  0.5463877551020409  val accuracy:  0.529\n",
      "13  hs  100  lr  0.002446554541015612  reg  1.012087506633911e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "13  hs  100  lr  0.002446554541015612  reg  1.012087506633911e-05  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "13  hs  100  lr  0.002446554541015612  reg  1.012087506633911e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "14  hs  100  lr  3.5916400209306523  reg  6.335853999338237  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "14  hs  100  lr  3.5916400209306523  reg  6.335853999338237  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "14  hs  100  lr  3.5916400209306523  reg  6.335853999338237  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "15  hs  100  lr  0.9677260216858142  reg  0.09239240433792081  decay  1  train accuracy:  0.2659183673469388  val accuracy:  0.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15  hs  100  lr  0.9677260216858142  reg  0.09239240433792081  decay  0.95  train accuracy:  0.31416326530612243  val accuracy:  0.298\n",
      "15  hs  100  lr  0.9677260216858142  reg  0.09239240433792081  decay  0.99  train accuracy:  0.24514285714285713  val accuracy:  0.272\n",
      "16  hs  100  lr  0.0016050800611224912  reg  0.21584903969847913  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "16  hs  100  lr  0.0016050800611224912  reg  0.21584903969847913  decay  0.95  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "16  hs  100  lr  0.0016050800611224912  reg  0.21584903969847913  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "17  hs  100  lr  5.649015614855718  reg  0.00409761771789801  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "17  hs  100  lr  5.649015614855718  reg  0.00409761771789801  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "17  hs  100  lr  5.649015614855718  reg  0.00409761771789801  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "18  hs  100  lr  0.010290550997279902  reg  0.000580270127372596  decay  1  train accuracy:  0.2692040816326531  val accuracy:  0.284\n",
      "18  hs  100  lr  0.010290550997279902  reg  0.000580270127372596  decay  0.95  train accuracy:  0.20191836734693877  val accuracy:  0.208\n",
      "18  hs  100  lr  0.010290550997279902  reg  0.000580270127372596  decay  0.99  train accuracy:  0.25757142857142856  val accuracy:  0.273\n",
      "19  hs  100  lr  0.022828213715318808  reg  2.1342740805389204  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "19  hs  100  lr  0.022828213715318808  reg  2.1342740805389204  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "19  hs  100  lr  0.022828213715318808  reg  2.1342740805389204  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "20  hs  100  lr  0.22044213658260262  reg  0.008826393082408505  decay  1  train accuracy:  0.524795918367347  val accuracy:  0.511\n",
      "20  hs  100  lr  0.22044213658260262  reg  0.008826393082408505  decay  0.95  train accuracy:  0.532469387755102  val accuracy:  0.514\n",
      "20  hs  100  lr  0.22044213658260262  reg  0.008826393082408505  decay  0.99  train accuracy:  0.526734693877551  val accuracy:  0.509\n",
      "21  hs  100  lr  8.310551396924343  reg  0.002231779291031178  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  100  lr  8.310551396924343  reg  0.002231779291031178  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "21  hs  100  lr  8.310551396924343  reg  0.002231779291031178  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  100  lr  0.48171750388238227  reg  1.6433179865388583  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "22  hs  100  lr  0.48171750388238227  reg  1.6433179865388583  decay  0.95  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "22  hs  100  lr  0.48171750388238227  reg  1.6433179865388583  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "23  hs  100  lr  0.09120008881306702  reg  0.02773534824954677  decay  1  train accuracy:  0.4926530612244898  val accuracy:  0.48\n",
      "23  hs  100  lr  0.09120008881306702  reg  0.02773534824954677  decay  0.95  train accuracy:  0.4888571428571429  val accuracy:  0.495\n",
      "23  hs  100  lr  0.09120008881306702  reg  0.02773534824954677  decay  0.99  train accuracy:  0.4942857142857143  val accuracy:  0.501\n",
      "24  hs  100  lr  0.040934652111836715  reg  0.13997525221184198  decay  1  train accuracy:  0.2602040816326531  val accuracy:  0.283\n",
      "24  hs  100  lr  0.040934652111836715  reg  0.13997525221184198  decay  0.95  train accuracy:  0.19846938775510203  val accuracy:  0.203\n",
      "24  hs  100  lr  0.040934652111836715  reg  0.13997525221184198  decay  0.99  train accuracy:  0.24112244897959184  val accuracy:  0.263\n",
      "25  hs  100  lr  0.01877828573385249  reg  0.006435491809841174  decay  1  train accuracy:  0.43051020408163265  val accuracy:  0.409\n",
      "25  hs  100  lr  0.01877828573385249  reg  0.006435491809841174  decay  0.95  train accuracy:  0.3403673469387755  val accuracy:  0.34\n",
      "25  hs  100  lr  0.01877828573385249  reg  0.006435491809841174  decay  0.99  train accuracy:  0.4173061224489796  val accuracy:  0.407\n",
      "26  hs  100  lr  0.0035758466863024508  reg  0.014955833345709832  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "26  hs  100  lr  0.0035758466863024508  reg  0.014955833345709832  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "26  hs  100  lr  0.0035758466863024508  reg  0.014955833345709832  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.105\n",
      "27  hs  100  lr  4.757751884945164  reg  4.726357486944309e-05  decay  1  train accuracy:  0.10022448979591837  val accuracy:  0.107\n",
      "27  hs  100  lr  4.757751884945164  reg  4.726357486944309e-05  decay  0.95  train accuracy:  0.10085714285714285  val accuracy:  0.087\n",
      "27  hs  100  lr  4.757751884945164  reg  4.726357486944309e-05  decay  0.99  train accuracy:  0.10048979591836735  val accuracy:  0.087\n",
      "28  hs  100  lr  0.07121033148993766  reg  8.197510169893755  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "28  hs  100  lr  0.07121033148993766  reg  8.197510169893755  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "28  hs  100  lr  0.07121033148993766  reg  8.197510169893755  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "29  hs  100  lr  0.013619911984978098  reg  0.010511814855645755  decay  1  train accuracy:  0.31083673469387757  val accuracy:  0.319\n",
      "29  hs  100  lr  0.013619911984978098  reg  0.010511814855645755  decay  0.95  train accuracy:  0.2587551020408163  val accuracy:  0.274\n",
      "29  hs  100  lr  0.013619911984978098  reg  0.010511814855645755  decay  0.99  train accuracy:  0.3029591836734694  val accuracy:  0.305\n",
      "30  hs  100  lr  1.384709538574241  reg  2.2073276523296147e-05  decay  1  train accuracy:  0.6355714285714286  val accuracy:  0.53\n",
      "30  hs  100  lr  1.384709538574241  reg  2.2073276523296147e-05  decay  0.95  train accuracy:  0.6608775510204081  val accuracy:  0.558\n",
      "30  hs  100  lr  1.384709538574241  reg  2.2073276523296147e-05  decay  0.99  train accuracy:  0.6415306122448979  val accuracy:  0.533\n",
      "31  hs  100  lr  0.2999805658149426  reg  8.12157676329313  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "31  hs  100  lr  0.2999805658149426  reg  8.12157676329313  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "31  hs  100  lr  0.2999805658149426  reg  8.12157676329313  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "32  hs  100  lr  8.809160540080738  reg  1.2322168410636409e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "32  hs  100  lr  8.809160540080738  reg  1.2322168410636409e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "32  hs  100  lr  8.809160540080738  reg  1.2322168410636409e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "33  hs  100  lr  0.037163642004087345  reg  7.487259399536257  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "33  hs  100  lr  0.037163642004087345  reg  7.487259399536257  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "33  hs  100  lr  0.037163642004087345  reg  7.487259399536257  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "34  hs  100  lr  0.07644004578146524  reg  3.492409996864069e-05  decay  1  train accuracy:  0.5657142857142857  val accuracy:  0.542\n",
      "34  hs  100  lr  0.07644004578146524  reg  3.492409996864069e-05  decay  0.95  train accuracy:  0.5474489795918367  val accuracy:  0.529\n",
      "34  hs  100  lr  0.07644004578146524  reg  3.492409996864069e-05  decay  0.99  train accuracy:  0.5615918367346939  val accuracy:  0.536\n",
      "35  hs  100  lr  0.021520069668090575  reg  1.996948072890096e-05  decay  1  train accuracy:  0.4687142857142857  val accuracy:  0.447\n",
      "35  hs  100  lr  0.021520069668090575  reg  1.996948072890096e-05  decay  0.95  train accuracy:  0.4203877551020408  val accuracy:  0.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35  hs  100  lr  0.021520069668090575  reg  1.996948072890096e-05  decay  0.99  train accuracy:  0.4618163265306122  val accuracy:  0.448\n",
      "36  hs  100  lr  0.0011869549531955976  reg  2.6159767691621042e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "36  hs  100  lr  0.0011869549531955976  reg  2.6159767691621042e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "36  hs  100  lr  0.0011869549531955976  reg  2.6159767691621042e-05  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "37  hs  100  lr  0.009229861356256917  reg  0.002011442496384156  decay  1  train accuracy:  0.2433265306122449  val accuracy:  0.259\n",
      "37  hs  100  lr  0.009229861356256917  reg  0.002011442496384156  decay  0.95  train accuracy:  0.2136326530612245  val accuracy:  0.22\n",
      "37  hs  100  lr  0.009229861356256917  reg  0.002011442496384156  decay  0.99  train accuracy:  0.227  val accuracy:  0.24\n",
      "38  hs  100  lr  0.025392654563754263  reg  1.0082744403306458  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "38  hs  100  lr  0.025392654563754263  reg  1.0082744403306458  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "38  hs  100  lr  0.025392654563754263  reg  1.0082744403306458  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "39  hs  100  lr  0.25339282029294313  reg  0.0002747080640334967  decay  1  train accuracy:  0.6389387755102041  val accuracy:  0.578\n",
      "39  hs  100  lr  0.25339282029294313  reg  0.0002747080640334967  decay  0.95  train accuracy:  0.6288163265306123  val accuracy:  0.568\n",
      "39  hs  100  lr  0.25339282029294313  reg  0.0002747080640334967  decay  0.99  train accuracy:  0.6427142857142857  val accuracy:  0.573\n",
      "40  hs  100  lr  0.001705971952003148  reg  2.9602737557627524e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "40  hs  100  lr  0.001705971952003148  reg  2.9602737557627524e-05  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "40  hs  100  lr  0.001705971952003148  reg  2.9602737557627524e-05  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "41  hs  100  lr  0.24895265222892268  reg  1.094235047953816  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "41  hs  100  lr  0.24895265222892268  reg  1.094235047953816  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "41  hs  100  lr  0.24895265222892268  reg  1.094235047953816  decay  0.99  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "42  hs  100  lr  0.3929973664429782  reg  8.447612779113935e-05  decay  1  train accuracy:  0.6545102040816326  val accuracy:  0.565\n",
      "42  hs  100  lr  0.3929973664429782  reg  8.447612779113935e-05  decay  0.95  train accuracy:  0.6624081632653062  val accuracy:  0.582\n",
      "42  hs  100  lr  0.3929973664429782  reg  8.447612779113935e-05  decay  0.99  train accuracy:  0.6546122448979592  val accuracy:  0.562\n",
      "43  hs  100  lr  1.1663590213477535  reg  0.0004501132516660652  decay  1  train accuracy:  0.6181632653061224  val accuracy:  0.54\n",
      "43  hs  100  lr  1.1663590213477535  reg  0.0004501132516660652  decay  0.95  train accuracy:  0.647  val accuracy:  0.564\n",
      "43  hs  100  lr  1.1663590213477535  reg  0.0004501132516660652  decay  0.99  train accuracy:  0.627734693877551  val accuracy:  0.535\n",
      "44  hs  100  lr  1.4016455324854218  reg  0.0008884851413265759  decay  1  train accuracy:  0.5956938775510204  val accuracy:  0.55\n",
      "44  hs  100  lr  1.4016455324854218  reg  0.0008884851413265759  decay  0.95  train accuracy:  0.6256530612244898  val accuracy:  0.553\n",
      "44  hs  100  lr  1.4016455324854218  reg  0.0008884851413265759  decay  0.99  train accuracy:  0.594204081632653  val accuracy:  0.54\n",
      "45  hs  100  lr  0.015334703136324726  reg  0.14267729915711444  decay  1  train accuracy:  0.15712244897959185  val accuracy:  0.124\n",
      "45  hs  100  lr  0.015334703136324726  reg  0.14267729915711444  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "45  hs  100  lr  0.015334703136324726  reg  0.14267729915711444  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "46  hs  100  lr  0.008689446901195884  reg  1.777502416642836  decay  1  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "46  hs  100  lr  0.008689446901195884  reg  1.777502416642836  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "46  hs  100  lr  0.008689446901195884  reg  1.777502416642836  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "47  hs  100  lr  1.899161175515341  reg  3.2691421518091395  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "47  hs  100  lr  1.899161175515341  reg  3.2691421518091395  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "47  hs  100  lr  1.899161175515341  reg  3.2691421518091395  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "48  hs  100  lr  0.12052103469991178  reg  0.0001909096341657129  decay  1  train accuracy:  0.5998367346938775  val accuracy:  0.573\n",
      "48  hs  100  lr  0.12052103469991178  reg  0.0001909096341657129  decay  0.95  train accuracy:  0.5760612244897959  val accuracy:  0.553\n",
      "48  hs  100  lr  0.12052103469991178  reg  0.0001909096341657129  decay  0.99  train accuracy:  0.5932244897959184  val accuracy:  0.547\n",
      "49  hs  100  lr  0.17393564992893348  reg  0.24193485912070448  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "49  hs  100  lr  0.17393564992893348  reg  0.24193485912070448  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "49  hs  100  lr  0.17393564992893348  reg  0.24193485912070448  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "50  hs  100  lr  0.015110337106638148  reg  0.05604949088904376  decay  1  train accuracy:  0.26787755102040817  val accuracy:  0.289\n",
      "50  hs  100  lr  0.015110337106638148  reg  0.05604949088904376  decay  0.95  train accuracy:  0.19587755102040816  val accuracy:  0.195\n",
      "50  hs  100  lr  0.015110337106638148  reg  0.05604949088904376  decay  0.99  train accuracy:  0.25740816326530613  val accuracy:  0.277\n",
      "51  hs  100  lr  0.0010785115511830728  reg  0.0006636279520651309  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "51  hs  100  lr  0.0010785115511830728  reg  0.0006636279520651309  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "51  hs  100  lr  0.0010785115511830728  reg  0.0006636279520651309  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "52  hs  100  lr  2.0732033167738506  reg  0.0018652456203027688  decay  1  train accuracy:  0.5369183673469388  val accuracy:  0.506\n",
      "52  hs  100  lr  2.0732033167738506  reg  0.0018652456203027688  decay  0.95  train accuracy:  0.5691020408163265  val accuracy:  0.539\n",
      "52  hs  100  lr  2.0732033167738506  reg  0.0018652456203027688  decay  0.99  train accuracy:  0.5346734693877551  val accuracy:  0.502\n",
      "53  hs  100  lr  0.11645320827316523  reg  0.12314592537866588  decay  1  train accuracy:  0.2800612244897959  val accuracy:  0.255\n",
      "53  hs  100  lr  0.11645320827316523  reg  0.12314592537866588  decay  0.95  train accuracy:  0.29320408163265305  val accuracy:  0.284\n",
      "53  hs  100  lr  0.11645320827316523  reg  0.12314592537866588  decay  0.99  train accuracy:  0.2785714285714286  val accuracy:  0.261\n",
      "54  hs  100  lr  0.0013104069963114013  reg  0.017649338838609967  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "54  hs  100  lr  0.0013104069963114013  reg  0.017649338838609967  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "54  hs  100  lr  0.0013104069963114013  reg  0.017649338838609967  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "55  hs  100  lr  6.0623646798794235  reg  0.004525440576700588  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "55  hs  100  lr  6.0623646798794235  reg  0.004525440576700588  decay  0.95  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "55  hs  100  lr  6.0623646798794235  reg  0.004525440576700588  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56  hs  100  lr  0.0017164047275489674  reg  2.3177698699245533e-05  decay  1  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "56  hs  100  lr  0.0017164047275489674  reg  2.3177698699245533e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "56  hs  100  lr  0.0017164047275489674  reg  2.3177698699245533e-05  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "57  hs  100  lr  0.009575525276911375  reg  8.663998020155966e-05  decay  1  train accuracy:  0.2600408163265306  val accuracy:  0.279\n",
      "57  hs  100  lr  0.009575525276911375  reg  8.663998020155966e-05  decay  0.95  train accuracy:  0.21581632653061225  val accuracy:  0.211\n",
      "57  hs  100  lr  0.009575525276911375  reg  8.663998020155966e-05  decay  0.99  train accuracy:  0.23822448979591837  val accuracy:  0.253\n",
      "58  hs  100  lr  0.02762176031827995  reg  1.2052743395791663  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "58  hs  100  lr  0.02762176031827995  reg  1.2052743395791663  decay  0.95  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "58  hs  100  lr  0.02762176031827995  reg  1.2052743395791663  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "59  hs  100  lr  0.006231959411895092  reg  0.0031603986953739776  decay  1  train accuracy:  0.1696530612244898  val accuracy:  0.16\n",
      "59  hs  100  lr  0.006231959411895092  reg  0.0031603986953739776  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "59  hs  100  lr  0.006231959411895092  reg  0.0031603986953739776  decay  0.99  train accuracy:  0.16353061224489795  val accuracy:  0.143\n",
      "60  hs  100  lr  0.05798187570321085  reg  6.22354102609775e-05  decay  1  train accuracy:  0.5483877551020409  val accuracy:  0.52\n",
      "60  hs  100  lr  0.05798187570321085  reg  6.22354102609775e-05  decay  0.95  train accuracy:  0.5342448979591837  val accuracy:  0.515\n",
      "60  hs  100  lr  0.05798187570321085  reg  6.22354102609775e-05  decay  0.99  train accuracy:  0.5426530612244898  val accuracy:  0.528\n",
      "61  hs  100  lr  0.2923644233747433  reg  1.295602429993769e-05  decay  1  train accuracy:  0.6497142857142857  val accuracy:  0.56\n",
      "61  hs  100  lr  0.2923644233747433  reg  1.295602429993769e-05  decay  0.95  train accuracy:  0.6488571428571429  val accuracy:  0.569\n",
      "61  hs  100  lr  0.2923644233747433  reg  1.295602429993769e-05  decay  0.99  train accuracy:  0.6517755102040816  val accuracy:  0.58\n",
      "62  hs  100  lr  0.031671797985219845  reg  0.0026075152937924777  decay  1  train accuracy:  0.5077142857142857  val accuracy:  0.509\n",
      "62  hs  100  lr  0.031671797985219845  reg  0.0026075152937924777  decay  0.95  train accuracy:  0.479265306122449  val accuracy:  0.476\n",
      "62  hs  100  lr  0.031671797985219845  reg  0.0026075152937924777  decay  0.99  train accuracy:  0.5011836734693877  val accuracy:  0.484\n",
      "63  hs  100  lr  0.010721220026838934  reg  2.3527117683221896  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "63  hs  100  lr  0.010721220026838934  reg  2.3527117683221896  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "63  hs  100  lr  0.010721220026838934  reg  2.3527117683221896  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "64  hs  100  lr  1.48213340227804  reg  9.277631093267863e-05  decay  1  train accuracy:  0.6334489795918368  val accuracy:  0.541\n",
      "64  hs  100  lr  1.48213340227804  reg  9.277631093267863e-05  decay  0.95  train accuracy:  0.6584897959183673  val accuracy:  0.54\n",
      "64  hs  100  lr  1.48213340227804  reg  9.277631093267863e-05  decay  0.99  train accuracy:  0.6321224489795918  val accuracy:  0.532\n",
      "65  hs  100  lr  0.5896258639033146  reg  0.04743652500206928  decay  1  train accuracy:  0.36448979591836733  val accuracy:  0.387\n",
      "65  hs  100  lr  0.5896258639033146  reg  0.04743652500206928  decay  0.95  train accuracy:  0.4226530612244898  val accuracy:  0.441\n",
      "65  hs  100  lr  0.5896258639033146  reg  0.04743652500206928  decay  0.99  train accuracy:  0.40891836734693876  val accuracy:  0.402\n",
      "66  hs  100  lr  1.8455742115294655  reg  0.005008578049877955  decay  1  train accuracy:  0.4940612244897959  val accuracy:  0.469\n",
      "66  hs  100  lr  1.8455742115294655  reg  0.005008578049877955  decay  0.95  train accuracy:  0.5155510204081633  val accuracy:  0.496\n",
      "66  hs  100  lr  1.8455742115294655  reg  0.005008578049877955  decay  0.99  train accuracy:  0.5028775510204082  val accuracy:  0.478\n",
      "67  hs  100  lr  0.0015101515109737776  reg  0.00012712481162330263  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "67  hs  100  lr  0.0015101515109737776  reg  0.00012712481162330263  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "67  hs  100  lr  0.0015101515109737776  reg  0.00012712481162330263  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "68  hs  100  lr  0.01770644958616927  reg  0.5549043368714345  decay  1  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "68  hs  100  lr  0.01770644958616927  reg  0.5549043368714345  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "68  hs  100  lr  0.01770644958616927  reg  0.5549043368714345  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "69  hs  100  lr  0.7513546983714796  reg  0.0076134523460544825  decay  1  train accuracy:  0.5037142857142857  val accuracy:  0.496\n",
      "69  hs  100  lr  0.7513546983714796  reg  0.0076134523460544825  decay  0.95  train accuracy:  0.5278979591836734  val accuracy:  0.497\n",
      "69  hs  100  lr  0.7513546983714796  reg  0.0076134523460544825  decay  0.99  train accuracy:  0.5280816326530612  val accuracy:  0.519\n",
      "computed in  843.4399900436401 s\n",
      "0  hs  50  lr  0.16661806633713686  reg  0.10739839482931798  decay  1  train accuracy:  0.3094081632653061  val accuracy:  0.317\n",
      "0  hs  50  lr  0.16661806633713686  reg  0.10739839482931798  decay  0.95  train accuracy:  0.3237551020408163  val accuracy:  0.329\n",
      "0  hs  50  lr  0.16661806633713686  reg  0.10739839482931798  decay  0.99  train accuracy:  0.3110612244897959  val accuracy:  0.305\n",
      "1  hs  50  lr  0.011017165655270491  reg  0.015466474938076583  decay  1  train accuracy:  0.25720408163265307  val accuracy:  0.278\n",
      "1  hs  50  lr  0.011017165655270491  reg  0.015466474938076583  decay  0.95  train accuracy:  0.21340816326530612  val accuracy:  0.214\n",
      "1  hs  50  lr  0.011017165655270491  reg  0.015466474938076583  decay  0.99  train accuracy:  0.23820408163265305  val accuracy:  0.253\n",
      "2  hs  50  lr  0.7072860897569168  reg  2.623140629996379  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "2  hs  50  lr  0.7072860897569168  reg  2.623140629996379  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "2  hs  50  lr  0.7072860897569168  reg  2.623140629996379  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  50  lr  0.002950581382031508  reg  5.564366627729354e-05  decay  1  train accuracy:  0.10069387755102041  val accuracy:  0.078\n",
      "3  hs  50  lr  0.002950581382031508  reg  5.564366627729354e-05  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "3  hs  50  lr  0.002950581382031508  reg  5.564366627729354e-05  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "4  hs  50  lr  0.22793144437686313  reg  0.00029330560267470446  decay  1  train accuracy:  0.603938775510204  val accuracy:  0.552\n",
      "4  hs  50  lr  0.22793144437686313  reg  0.00029330560267470446  decay  0.95  train accuracy:  0.5998775510204082  val accuracy:  0.575\n",
      "4  hs  50  lr  0.22793144437686313  reg  0.00029330560267470446  decay  0.99  train accuracy:  0.6044285714285714  val accuracy:  0.56\n",
      "5  hs  50  lr  0.010365538967781201  reg  1.4824796789677785e-05  decay  1  train accuracy:  0.25648979591836735  val accuracy:  0.272\n",
      "5  hs  50  lr  0.010365538967781201  reg  1.4824796789677785e-05  decay  0.95  train accuracy:  0.21736734693877552  val accuracy:  0.211\n",
      "5  hs  50  lr  0.010365538967781201  reg  1.4824796789677785e-05  decay  0.99  train accuracy:  0.2543469387755102  val accuracy:  0.265\n",
      "6  hs  50  lr  0.00612606053825892  reg  0.040219130937153104  decay  1  train accuracy:  0.1543469387755102  val accuracy:  0.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  hs  50  lr  0.00612606053825892  reg  0.040219130937153104  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "6  hs  50  lr  0.00612606053825892  reg  0.040219130937153104  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "7  hs  50  lr  0.37081821347521715  reg  0.0002625043238480751  decay  1  train accuracy:  0.612734693877551  val accuracy:  0.561\n",
      "7  hs  50  lr  0.37081821347521715  reg  0.0002625043238480751  decay  0.95  train accuracy:  0.6132857142857143  val accuracy:  0.556\n",
      "7  hs  50  lr  0.37081821347521715  reg  0.0002625043238480751  decay  0.99  train accuracy:  0.6086938775510204  val accuracy:  0.562\n",
      "8  hs  50  lr  0.20226233705868643  reg  1.4522316618382574  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "8  hs  50  lr  0.20226233705868643  reg  1.4522316618382574  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "8  hs  50  lr  0.20226233705868643  reg  1.4522316618382574  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "9  hs  50  lr  1.4153407949677657  reg  0.0010486775270960582  decay  1  train accuracy:  0.5511428571428572  val accuracy:  0.516\n",
      "9  hs  50  lr  1.4153407949677657  reg  0.0010486775270960582  decay  0.95  train accuracy:  0.5716530612244898  val accuracy:  0.519\n",
      "9  hs  50  lr  1.4153407949677657  reg  0.0010486775270960582  decay  0.99  train accuracy:  0.554734693877551  val accuracy:  0.504\n",
      "10  hs  50  lr  0.07142166573709448  reg  5.8312319878472655e-05  decay  1  train accuracy:  0.5558775510204081  val accuracy:  0.528\n",
      "10  hs  50  lr  0.07142166573709448  reg  5.8312319878472655e-05  decay  0.95  train accuracy:  0.5393469387755102  val accuracy:  0.532\n",
      "10  hs  50  lr  0.07142166573709448  reg  5.8312319878472655e-05  decay  0.99  train accuracy:  0.5500204081632653  val accuracy:  0.524\n",
      "11  hs  50  lr  0.0078081560006188514  reg  0.0001111017413848468  decay  1  train accuracy:  0.20589795918367346  val accuracy:  0.2\n",
      "11  hs  50  lr  0.0078081560006188514  reg  0.0001111017413848468  decay  0.95  train accuracy:  0.16138775510204081  val accuracy:  0.14\n",
      "11  hs  50  lr  0.0078081560006188514  reg  0.0001111017413848468  decay  0.99  train accuracy:  0.21983673469387754  val accuracy:  0.225\n",
      "12  hs  50  lr  1.3691453498474648  reg  0.000224313393043745  decay  1  train accuracy:  0.5733673469387756  val accuracy:  0.512\n",
      "12  hs  50  lr  1.3691453498474648  reg  0.000224313393043745  decay  0.95  train accuracy:  0.6013673469387755  val accuracy:  0.543\n",
      "12  hs  50  lr  1.3691453498474648  reg  0.000224313393043745  decay  0.99  train accuracy:  0.571265306122449  val accuracy:  0.517\n",
      "13  hs  50  lr  0.0030891652813905047  reg  8.121988846731126  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "13  hs  50  lr  0.0030891652813905047  reg  8.121988846731126  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "13  hs  50  lr  0.0030891652813905047  reg  8.121988846731126  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "14  hs  50  lr  0.7667926121831526  reg  0.00012450773269390375  decay  1  train accuracy:  0.5937142857142857  val accuracy:  0.517\n",
      "14  hs  50  lr  0.7667926121831526  reg  0.00012450773269390375  decay  0.95  train accuracy:  0.6157755102040816  val accuracy:  0.549\n",
      "14  hs  50  lr  0.7667926121831526  reg  0.00012450773269390375  decay  0.99  train accuracy:  0.6044897959183674  val accuracy:  0.537\n",
      "15  hs  50  lr  1.2331713417268568  reg  0.002509219405619726  decay  1  train accuracy:  0.5435714285714286  val accuracy:  0.523\n",
      "15  hs  50  lr  1.2331713417268568  reg  0.002509219405619726  decay  0.95  train accuracy:  0.5660612244897959  val accuracy:  0.542\n",
      "15  hs  50  lr  1.2331713417268568  reg  0.002509219405619726  decay  0.99  train accuracy:  0.5217755102040816  val accuracy:  0.483\n",
      "16  hs  50  lr  0.0019130225768215212  reg  3.431342805356511  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "16  hs  50  lr  0.0019130225768215212  reg  3.431342805356511  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "16  hs  50  lr  0.0019130225768215212  reg  3.431342805356511  decay  0.99  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "17  hs  50  lr  5.754121415548054  reg  1.3330490912962366e-05  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "17  hs  50  lr  5.754121415548054  reg  1.3330490912962366e-05  decay  0.95  train accuracy:  0.10079591836734694  val accuracy:  0.112\n",
      "17  hs  50  lr  5.754121415548054  reg  1.3330490912962366e-05  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "18  hs  50  lr  0.23589305559471868  reg  0.00010348397237793514  decay  1  train accuracy:  0.6116326530612245  val accuracy:  0.557\n",
      "18  hs  50  lr  0.23589305559471868  reg  0.00010348397237793514  decay  0.95  train accuracy:  0.6041224489795919  val accuracy:  0.556\n",
      "18  hs  50  lr  0.23589305559471868  reg  0.00010348397237793514  decay  0.99  train accuracy:  0.6057142857142858  val accuracy:  0.56\n",
      "19  hs  50  lr  0.018463083866117818  reg  0.001431216511566166  decay  1  train accuracy:  0.43642857142857144  val accuracy:  0.418\n",
      "19  hs  50  lr  0.018463083866117818  reg  0.001431216511566166  decay  0.95  train accuracy:  0.34579591836734697  val accuracy:  0.348\n",
      "19  hs  50  lr  0.018463083866117818  reg  0.001431216511566166  decay  0.99  train accuracy:  0.4114897959183674  val accuracy:  0.4\n",
      "20  hs  50  lr  0.3075150873734145  reg  0.0038128490574426363  decay  1  train accuracy:  0.5690612244897959  val accuracy:  0.548\n",
      "20  hs  50  lr  0.3075150873734145  reg  0.0038128490574426363  decay  0.95  train accuracy:  0.5693265306122449  val accuracy:  0.553\n",
      "20  hs  50  lr  0.3075150873734145  reg  0.0038128490574426363  decay  0.99  train accuracy:  0.572469387755102  val accuracy:  0.546\n",
      "21  hs  50  lr  0.28386962877605976  reg  0.8343164953719338  decay  1  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "21  hs  50  lr  0.28386962877605976  reg  0.8343164953719338  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "21  hs  50  lr  0.28386962877605976  reg  0.8343164953719338  decay  0.99  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "22  hs  50  lr  1.8783029461827536  reg  1.1097724969029532  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  50  lr  1.8783029461827536  reg  1.1097724969029532  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "22  hs  50  lr  1.8783029461827536  reg  1.1097724969029532  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "23  hs  50  lr  0.0012753463122299343  reg  0.7632760613936298  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "23  hs  50  lr  0.0012753463122299343  reg  0.7632760613936298  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "23  hs  50  lr  0.0012753463122299343  reg  0.7632760613936298  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "24  hs  50  lr  0.0021030247841218328  reg  0.00046151479299805573  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "24  hs  50  lr  0.0021030247841218328  reg  0.00046151479299805573  decay  0.95  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "24  hs  50  lr  0.0021030247841218328  reg  0.00046151479299805573  decay  0.99  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "25  hs  50  lr  0.09512433249037022  reg  0.060319403521865565  decay  1  train accuracy:  0.422734693877551  val accuracy:  0.395\n",
      "25  hs  50  lr  0.09512433249037022  reg  0.060319403521865565  decay  0.95  train accuracy:  0.42153061224489796  val accuracy:  0.409\n",
      "25  hs  50  lr  0.09512433249037022  reg  0.060319403521865565  decay  0.99  train accuracy:  0.42187755102040814  val accuracy:  0.409\n",
      "26  hs  50  lr  0.0016242311579754273  reg  1.1273593659356485e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "26  hs  50  lr  0.0016242311579754273  reg  1.1273593659356485e-05  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26  hs  50  lr  0.0016242311579754273  reg  1.1273593659356485e-05  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "27  hs  50  lr  0.1771824572885097  reg  5.6610294231839795e-05  decay  1  train accuracy:  0.5986938775510204  val accuracy:  0.544\n",
      "27  hs  50  lr  0.1771824572885097  reg  5.6610294231839795e-05  decay  0.95  train accuracy:  0.5886122448979592  val accuracy:  0.563\n",
      "27  hs  50  lr  0.1771824572885097  reg  5.6610294231839795e-05  decay  0.99  train accuracy:  0.5982448979591837  val accuracy:  0.569\n",
      "28  hs  50  lr  4.8223249367665355  reg  0.003606510966118163  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "28  hs  50  lr  4.8223249367665355  reg  0.003606510966118163  decay  0.95  train accuracy:  0.09985714285714285  val accuracy:  0.107\n",
      "28  hs  50  lr  4.8223249367665355  reg  0.003606510966118163  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "29  hs  50  lr  0.11537418374883007  reg  2.1096434198108316  decay  1  train accuracy:  0.09975510204081632  val accuracy:  0.112\n",
      "29  hs  50  lr  0.11537418374883007  reg  2.1096434198108316  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "29  hs  50  lr  0.11537418374883007  reg  2.1096434198108316  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "30  hs  50  lr  0.04449179679539479  reg  5.7723593727437714e-05  decay  1  train accuracy:  0.5309387755102041  val accuracy:  0.509\n",
      "30  hs  50  lr  0.04449179679539479  reg  5.7723593727437714e-05  decay  0.95  train accuracy:  0.5153877551020408  val accuracy:  0.508\n",
      "30  hs  50  lr  0.04449179679539479  reg  5.7723593727437714e-05  decay  0.99  train accuracy:  0.5303469387755102  val accuracy:  0.528\n",
      "31  hs  50  lr  0.026361751005929773  reg  0.2515753412960079  decay  1  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "31  hs  50  lr  0.026361751005929773  reg  0.2515753412960079  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "31  hs  50  lr  0.026361751005929773  reg  0.2515753412960079  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "32  hs  50  lr  0.0365396877384005  reg  4.814108115322259  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "32  hs  50  lr  0.0365396877384005  reg  4.814108115322259  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "32  hs  50  lr  0.0365396877384005  reg  4.814108115322259  decay  0.99  train accuracy:  0.09989795918367347  val accuracy:  0.105\n",
      "33  hs  50  lr  0.0019828434006954826  reg  0.058969463221202674  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "33  hs  50  lr  0.0019828434006954826  reg  0.058969463221202674  decay  0.95  train accuracy:  0.09961224489795918  val accuracy:  0.119\n",
      "33  hs  50  lr  0.0019828434006954826  reg  0.058969463221202674  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "34  hs  50  lr  6.509934314504261  reg  0.9921493850698375  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "34  hs  50  lr  6.509934314504261  reg  0.9921493850698375  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "34  hs  50  lr  6.509934314504261  reg  0.9921493850698375  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "35  hs  50  lr  3.169347470310946  reg  0.15119010912494832  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "35  hs  50  lr  3.169347470310946  reg  0.15119010912494832  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "35  hs  50  lr  3.169347470310946  reg  0.15119010912494832  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "36  hs  50  lr  0.16438246136959775  reg  0.20686942469381783  decay  1  train accuracy:  0.20569387755102042  val accuracy:  0.208\n",
      "36  hs  50  lr  0.16438246136959775  reg  0.20686942469381783  decay  0.95  train accuracy:  0.19055102040816327  val accuracy:  0.195\n",
      "36  hs  50  lr  0.16438246136959775  reg  0.20686942469381783  decay  0.99  train accuracy:  0.19918367346938776  val accuracy:  0.193\n",
      "37  hs  50  lr  0.05415221940121746  reg  4.654305635655713  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "37  hs  50  lr  0.05415221940121746  reg  4.654305635655713  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "37  hs  50  lr  0.05415221940121746  reg  4.654305635655713  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "38  hs  50  lr  0.019516244008469113  reg  0.0630990033362677  decay  1  train accuracy:  0.2769795918367347  val accuracy:  0.29\n",
      "38  hs  50  lr  0.019516244008469113  reg  0.0630990033362677  decay  0.95  train accuracy:  0.2406530612244898  val accuracy:  0.264\n",
      "38  hs  50  lr  0.019516244008469113  reg  0.0630990033362677  decay  0.99  train accuracy:  0.27410204081632655  val accuracy:  0.284\n",
      "39  hs  50  lr  1.2302836632080385  reg  7.697657754652096e-05  decay  1  train accuracy:  0.5917142857142857  val accuracy:  0.535\n",
      "39  hs  50  lr  1.2302836632080385  reg  7.697657754652096e-05  decay  0.95  train accuracy:  0.6043673469387755  val accuracy:  0.52\n",
      "39  hs  50  lr  1.2302836632080385  reg  7.697657754652096e-05  decay  0.99  train accuracy:  0.5957346938775511  val accuracy:  0.537\n",
      "40  hs  50  lr  0.6276706766359328  reg  1.3118967628869458e-05  decay  1  train accuracy:  0.6069795918367347  val accuracy:  0.54\n",
      "40  hs  50  lr  0.6276706766359328  reg  1.3118967628869458e-05  decay  0.95  train accuracy:  0.6172857142857143  val accuracy:  0.568\n",
      "40  hs  50  lr  0.6276706766359328  reg  1.3118967628869458e-05  decay  0.99  train accuracy:  0.6095102040816327  val accuracy:  0.546\n",
      "41  hs  50  lr  0.0040086012301320546  reg  0.00016423497296644206  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "41  hs  50  lr  0.0040086012301320546  reg  0.00016423497296644206  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "41  hs  50  lr  0.0040086012301320546  reg  0.00016423497296644206  decay  0.99  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "42  hs  50  lr  4.828665579317632  reg  9.08609456921643  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "42  hs  50  lr  4.828665579317632  reg  9.08609456921643  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "42  hs  50  lr  4.828665579317632  reg  9.08609456921643  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "43  hs  50  lr  2.466205996326483  reg  0.10948134549147108  decay  1  train accuracy:  0.21010204081632652  val accuracy:  0.214\n",
      "43  hs  50  lr  2.466205996326483  reg  0.10948134549147108  decay  0.95  train accuracy:  0.24846938775510205  val accuracy:  0.273\n",
      "43  hs  50  lr  2.466205996326483  reg  0.10948134549147108  decay  0.99  train accuracy:  0.13838775510204082  val accuracy:  0.127\n",
      "44  hs  50  lr  0.3390258260801768  reg  0.0001213290262028417  decay  1  train accuracy:  0.6117142857142858  val accuracy:  0.559\n",
      "44  hs  50  lr  0.3390258260801768  reg  0.0001213290262028417  decay  0.95  train accuracy:  0.6118979591836735  val accuracy:  0.576\n",
      "44  hs  50  lr  0.3390258260801768  reg  0.0001213290262028417  decay  0.99  train accuracy:  0.6101632653061224  val accuracy:  0.569\n",
      "45  hs  50  lr  0.014308255679345575  reg  0.5303795337722712  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "45  hs  50  lr  0.014308255679345575  reg  0.5303795337722712  decay  0.95  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "45  hs  50  lr  0.014308255679345575  reg  0.5303795337722712  decay  0.99  train accuracy:  0.09995918367346938  val accuracy:  0.102\n",
      "46  hs  50  lr  0.22039882472464972  reg  4.596473401916538e-05  decay  1  train accuracy:  0.6034897959183674  val accuracy:  0.563\n",
      "46  hs  50  lr  0.22039882472464972  reg  4.596473401916538e-05  decay  0.95  train accuracy:  0.5986122448979592  val accuracy:  0.572\n",
      "46  hs  50  lr  0.22039882472464972  reg  4.596473401916538e-05  decay  0.99  train accuracy:  0.6032448979591837  val accuracy:  0.563\n",
      "47  hs  50  lr  0.04718154700868447  reg  2.1214702750030393e-05  decay  1  train accuracy:  0.5336122448979592  val accuracy:  0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47  hs  50  lr  0.04718154700868447  reg  2.1214702750030393e-05  decay  0.95  train accuracy:  0.5187755102040816  val accuracy:  0.503\n",
      "47  hs  50  lr  0.04718154700868447  reg  2.1214702750030393e-05  decay  0.99  train accuracy:  0.5302857142857142  val accuracy:  0.517\n",
      "48  hs  50  lr  1.8858519172127473  reg  8.748140038335581  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "48  hs  50  lr  1.8858519172127473  reg  8.748140038335581  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "48  hs  50  lr  1.8858519172127473  reg  8.748140038335581  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "49  hs  50  lr  0.008810567528415804  reg  0.02318826228755936  decay  1  train accuracy:  0.21075510204081632  val accuracy:  0.221\n",
      "49  hs  50  lr  0.008810567528415804  reg  0.02318826228755936  decay  0.95  train accuracy:  0.16961224489795917  val accuracy:  0.185\n",
      "49  hs  50  lr  0.008810567528415804  reg  0.02318826228755936  decay  0.99  train accuracy:  0.1923265306122449  val accuracy:  0.204\n",
      "50  hs  50  lr  0.06790152223544597  reg  0.00021126899145232678  decay  1  train accuracy:  0.5434285714285715  val accuracy:  0.525\n",
      "50  hs  50  lr  0.06790152223544597  reg  0.00021126899145232678  decay  0.95  train accuracy:  0.5376326530612245  val accuracy:  0.521\n",
      "50  hs  50  lr  0.06790152223544597  reg  0.00021126899145232678  decay  0.99  train accuracy:  0.5491224489795918  val accuracy:  0.539\n",
      "51  hs  50  lr  0.33651387100267754  reg  1.280190933579991e-05  decay  1  train accuracy:  0.6093061224489796  val accuracy:  0.553\n",
      "51  hs  50  lr  0.33651387100267754  reg  1.280190933579991e-05  decay  0.95  train accuracy:  0.6133061224489796  val accuracy:  0.568\n",
      "51  hs  50  lr  0.33651387100267754  reg  1.280190933579991e-05  decay  0.99  train accuracy:  0.6099591836734694  val accuracy:  0.542\n",
      "52  hs  50  lr  0.41272022728062646  reg  8.613721607617812  decay  1  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  50  lr  0.41272022728062646  reg  8.613721607617812  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "52  hs  50  lr  0.41272022728062646  reg  8.613721607617812  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "53  hs  50  lr  0.3269348680787404  reg  0.0013792885097792798  decay  1  train accuracy:  0.5919387755102041  val accuracy:  0.554\n",
      "53  hs  50  lr  0.3269348680787404  reg  0.0013792885097792798  decay  0.95  train accuracy:  0.6015102040816327  val accuracy:  0.561\n",
      "53  hs  50  lr  0.3269348680787404  reg  0.0013792885097792798  decay  0.99  train accuracy:  0.5950816326530612  val accuracy:  0.561\n",
      "54  hs  50  lr  0.045905605889092115  reg  0.0007799408431742573  decay  1  train accuracy:  0.5298163265306123  val accuracy:  0.524\n",
      "54  hs  50  lr  0.045905605889092115  reg  0.0007799408431742573  decay  0.95  train accuracy:  0.5108775510204082  val accuracy:  0.505\n",
      "54  hs  50  lr  0.045905605889092115  reg  0.0007799408431742573  decay  0.99  train accuracy:  0.5267755102040816  val accuracy:  0.511\n",
      "55  hs  50  lr  0.015655429529242634  reg  0.06254325428562033  decay  1  train accuracy:  0.2493469387755102  val accuracy:  0.273\n",
      "55  hs  50  lr  0.015655429529242634  reg  0.06254325428562033  decay  0.95  train accuracy:  0.19677551020408163  val accuracy:  0.199\n",
      "55  hs  50  lr  0.015655429529242634  reg  0.06254325428562033  decay  0.99  train accuracy:  0.23151020408163264  val accuracy:  0.247\n",
      "56  hs  50  lr  0.05303917135587153  reg  0.0005872073135957952  decay  1  train accuracy:  0.5340816326530612  val accuracy:  0.514\n",
      "56  hs  50  lr  0.05303917135587153  reg  0.0005872073135957952  decay  0.95  train accuracy:  0.5262653061224489  val accuracy:  0.51\n",
      "56  hs  50  lr  0.05303917135587153  reg  0.0005872073135957952  decay  0.99  train accuracy:  0.5339183673469388  val accuracy:  0.521\n",
      "57  hs  50  lr  1.0443606047173788  reg  8.29751734000636e-05  decay  1  train accuracy:  0.5931224489795919  val accuracy:  0.541\n",
      "57  hs  50  lr  1.0443606047173788  reg  8.29751734000636e-05  decay  0.95  train accuracy:  0.6164489795918368  val accuracy:  0.549\n",
      "57  hs  50  lr  1.0443606047173788  reg  8.29751734000636e-05  decay  0.99  train accuracy:  0.5967755102040816  val accuracy:  0.535\n",
      "58  hs  50  lr  0.03322234669062026  reg  0.005159596952718018  decay  1  train accuracy:  0.4996938775510204  val accuracy:  0.495\n",
      "58  hs  50  lr  0.03322234669062026  reg  0.005159596952718018  decay  0.95  train accuracy:  0.476734693877551  val accuracy:  0.456\n",
      "58  hs  50  lr  0.03322234669062026  reg  0.005159596952718018  decay  0.99  train accuracy:  0.49714285714285716  val accuracy:  0.491\n",
      "59  hs  50  lr  2.02392869756896  reg  0.00015535318586610268  decay  1  train accuracy:  0.5461224489795918  val accuracy:  0.503\n",
      "59  hs  50  lr  2.02392869756896  reg  0.00015535318586610268  decay  0.95  train accuracy:  0.572530612244898  val accuracy:  0.528\n",
      "59  hs  50  lr  2.02392869756896  reg  0.00015535318586610268  decay  0.99  train accuracy:  0.5696530612244898  val accuracy:  0.519\n",
      "60  hs  50  lr  3.6476245799400777  reg  0.08497273933338331  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "60  hs  50  lr  3.6476245799400777  reg  0.08497273933338331  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "60  hs  50  lr  3.6476245799400777  reg  0.08497273933338331  decay  0.99  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "61  hs  50  lr  8.049129406577325  reg  0.058600581534707215  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "61  hs  50  lr  8.049129406577325  reg  0.058600581534707215  decay  0.95  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "61  hs  50  lr  8.049129406577325  reg  0.058600581534707215  decay  0.99  train accuracy:  0.10026530612244898  val accuracy:  0.087\n",
      "62  hs  50  lr  0.11245182005441806  reg  0.0054346597888110075  decay  1  train accuracy:  0.5399795918367347  val accuracy:  0.535\n",
      "62  hs  50  lr  0.11245182005441806  reg  0.0054346597888110075  decay  0.95  train accuracy:  0.5333469387755102  val accuracy:  0.522\n",
      "62  hs  50  lr  0.11245182005441806  reg  0.0054346597888110075  decay  0.99  train accuracy:  0.5372653061224489  val accuracy:  0.515\n",
      "63  hs  50  lr  0.24353865273876013  reg  1.7774838229840793  decay  1  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "63  hs  50  lr  0.24353865273876013  reg  1.7774838229840793  decay  0.95  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "63  hs  50  lr  0.24353865273876013  reg  1.7774838229840793  decay  0.99  train accuracy:  0.09973469387755102  val accuracy:  0.113\n",
      "64  hs  50  lr  0.0021526909288905904  reg  2.8793259236060187e-05  decay  1  train accuracy:  0.10044897959183674  val accuracy:  0.078\n",
      "64  hs  50  lr  0.0021526909288905904  reg  2.8793259236060187e-05  decay  0.95  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "64  hs  50  lr  0.0021526909288905904  reg  2.8793259236060187e-05  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "65  hs  50  lr  0.017333880147346138  reg  0.006568764479890367  decay  1  train accuracy:  0.4019591836734694  val accuracy:  0.404\n",
      "65  hs  50  lr  0.017333880147346138  reg  0.006568764479890367  decay  0.95  train accuracy:  0.3008571428571429  val accuracy:  0.308\n",
      "65  hs  50  lr  0.017333880147346138  reg  0.006568764479890367  decay  0.99  train accuracy:  0.386734693877551  val accuracy:  0.383\n",
      "66  hs  50  lr  0.09786691501376567  reg  0.04976491634533824  decay  1  train accuracy:  0.41914285714285715  val accuracy:  0.408\n",
      "66  hs  50  lr  0.09786691501376567  reg  0.04976491634533824  decay  0.95  train accuracy:  0.4433061224489796  val accuracy:  0.441\n",
      "66  hs  50  lr  0.09786691501376567  reg  0.04976491634533824  decay  0.99  train accuracy:  0.4320816326530612  val accuracy:  0.441\n",
      "67  hs  50  lr  1.1798234042320437  reg  0.018404115312878964  decay  1  train accuracy:  0.44751020408163267  val accuracy:  0.443\n",
      "67  hs  50  lr  1.1798234042320437  reg  0.018404115312878964  decay  0.95  train accuracy:  0.4720612244897959  val accuracy:  0.494\n",
      "67  hs  50  lr  1.1798234042320437  reg  0.018404115312878964  decay  0.99  train accuracy:  0.4367551020408163  val accuracy:  0.416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68  hs  50  lr  0.16215076253454594  reg  0.004159200897941676  decay  1  train accuracy:  0.5607551020408164  val accuracy:  0.547\n",
      "68  hs  50  lr  0.16215076253454594  reg  0.004159200897941676  decay  0.95  train accuracy:  0.5556734693877551  val accuracy:  0.542\n",
      "68  hs  50  lr  0.16215076253454594  reg  0.004159200897941676  decay  0.99  train accuracy:  0.5562857142857143  val accuracy:  0.534\n",
      "69  hs  50  lr  0.014769953785523563  reg  4.411497356110896  decay  1  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "69  hs  50  lr  0.014769953785523563  reg  4.411497356110896  decay  0.95  train accuracy:  0.10042857142857142  val accuracy:  0.079\n",
      "69  hs  50  lr  0.014769953785523563  reg  4.411497356110896  decay  0.99  train accuracy:  0.10004081632653061  val accuracy:  0.098\n",
      "computed in  876.4539384841919 s\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "import time\n",
    "\n",
    "input_dim = X_train_feats.shape[1]\n",
    "hidden_dim = 500\n",
    "num_classes = 10\n",
    "\n",
    "#net = TwoLayerNet(input_dim, hidden_dim, num_classes)\n",
    "best_net = None\n",
    "best_val = -1\n",
    "results = {}\n",
    "\n",
    "################################################################################\n",
    "# TODO: Train a two-layer neural network on image features. You may want to    #\n",
    "# cross-validate various parameters as in previous sections. Store your best   #\n",
    "# model in the best_net variable.                                              #\n",
    "################################################################################\n",
    "rate_decays = [1, 0.95,0.99] #[0.99, 0.95, 0.9, 0.8, 0.7, 0.6]\n",
    "hidden_sizes = [1500, 1000, 500, 100, 50] # [10, 50, 100, 150, 500]\n",
    "num_iters = 2500 # tmp for development\n",
    "max_count = 70\n",
    "\n",
    "for ind, hidden_size in enumerate(hidden_sizes):\n",
    "    tic = time.time()\n",
    "    for count in range(max_count):\n",
    "        rate = 10**np.random.uniform(-3, 1)\n",
    "        strength = 10**np.random.uniform(-5, 1)\n",
    "        for decay in rate_decays:\n",
    "            myNet = TwoLayerNet(input_dim, hidden_size, num_classes)\n",
    "            myNet.train(X_train_feats, y_train, X_val_feats, y_val, learning_rate=rate, reg=strength,\n",
    "                      learning_rate_decay=decay, num_iters=num_iters, verbose=False)\n",
    "            y_train_pred = myNet.predict(X_train_feats)\n",
    "            training_accuracy = np.mean(y_train == y_train_pred)\n",
    "            y_val_pred = myNet.predict(X_val_feats)\n",
    "            validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "            results[(hidden_size, rate, strength, decay)] = (training_accuracy,validation_accuracy)\n",
    "            if validation_accuracy > best_val:\n",
    "                best_val = validation_accuracy\n",
    "                best_net = myNet\n",
    "            print(count,' hs ',hidden_size,' lr ',rate,' reg ',strength,' decay ',decay,' train accuracy: ',training_accuracy,' val accuracy: ',validation_accuracy)\n",
    "    toc = time.time()\n",
    "    print('computed in ',( toc - tic),'s')\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_val 0.611\n",
      "<cs231n.classifiers.neural_net.TwoLayerNet object at 0x7f0560a3a518>\n"
     ]
    }
   ],
   "source": [
    "print(\"best_val\", best_val)\n",
    "print(best_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577\n"
     ]
    }
   ],
   "source": [
    "# Run your neural net classifier on the test set. You should be able to\n",
    "# get more than 55% accuracy.\n",
    "\n",
    "test_acc = (best_net.predict(X_test_feats) == y_test).mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Design your own features!\n",
    "\n",
    "You have seen that simple image features can improve classification performance. So far we have tried HOG and color histograms, but other types of features may be able to achieve even better classification performance.\n",
    "\n",
    "For bonus points, design and implement a new type of feature and use it for image classification on CIFAR-10. Explain how your feature works and why you expect it to be useful for image classification. Implement it in this notebook, cross-validate any hyperparameters, and compare its performance to the HOG + Color histogram baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Do something extra!\n",
    "Use the material and code we have presented in this assignment to do something interesting. Was there another question we should have asked? Did any cool ideas pop into your head as you were working on the assignment? This is your chance to show off!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
